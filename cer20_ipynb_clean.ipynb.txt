{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP_g2z7YB9QD",
        "outputId": "15d8c0c1-3565-4426-aae7-6cecc3160fd4"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBp5eQyiCZkU",
        "outputId": "6878621a-7614-49cf-847d-edaa07089238"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4a33aa7fe5ac4eeb8a0630c73d25c6cc",
            "d85adc18814e41569ff5538a626ea3ca",
            "80424380d5f84b67935d773305a330b1",
            "fad6c7773e8a4d7886d9d8fc3e1ee063",
            "231b78b9b9f44071aa54263169fba340",
            "1aedaae6bb044b1992d999062ad7652f",
            "3f7599d164a942a8a04c2d62893fb7c2",
            "5bc1e61ec6d74e3c83f1f23b52bd92b2",
            "dfb61e4479234bd385333b1921365a3b",
            "e089bae5a2a94ec9a6e77645c622e2f7",
            "329f74234c3c40eb94bbffb1ae1176a1",
            "f517d3a399b64b54b32a9b34a3a1f49c",
            "c0a90bfa20c7464484caa8bf5d00dfa0",
            "375c8b09151c4534978bc471b471a7fe",
            "9d362f15f3794277b6077e1e5f8f3dd5",
            "ed19ba0045f04fc69533cfa320c11b66",
            "bbe291d425694eb4b1fab0eb02e14eda",
            "8e8efe575a97442f931d199ae3964abb",
            "847e522d69e04d1da63452568b2b580d",
            "178618a2ba42487bb1b7c0762b2badae"
          ]
        },
        "id": "5W1SJQU2DIuA",
        "outputId": "fb425186-8126-432c-f4d8-023221dd4543"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrkip27DObs",
        "outputId": "c8da2b48-06de-4808-8859-33ed9724eb58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "7987bc84ce9340bf866b6fa441870dd7",
            "e7ea63f1cd3c4c34ac06103390c6c360",
            "11ea9665f0324511a52e93cd815c68bd",
            "f5e5d0b33b174e57ae17c77ca5b1fe0c",
            "79d5fe3dd01d4b22a21ca365a1fa1486",
            "50da05339c034073864ee718f9d4674d",
            "3766d05c205c4a2e8f43de62e7676ef3",
            "0500cc8b824442cc81c232f6445c414b",
            "a847e35b231d4c37a7809f2012ef8f1e",
            "dd0dacf1c2744851833a63508925cf35",
            "71b203ed8e66432a8bc18f9d4e033c0a"
          ]
        },
        "id": "E95lgvWsDOck",
        "outputId": "6692f936-d2f8-42ed-c627-4ea8b02eaaf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"Korean\", task=\"transcribe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "aa65eff317ad4076bd48694777f364f1",
            "c3395d1c5c23457fa1a98e292516a4ad",
            "727c694444274ac3aea92c5966f0deba",
            "9936b5d00c0a4e069e0d18ed3f8ffd17",
            "2c9630f962e041678d1e709b28311e8d",
            "72f07d4c42a947f1a9d24c15ee861a0e",
            "83e1f7b7fcd24085b8082d7d7508cd3c",
            "697f1e4d443141a2bfa78107da772649",
            "4efef97627d14b2b93df4a6814993fc5",
            "47e3c6083fa147359ddde496e7e5029e",
            "f40c25a06a73451cb8ea99d00089cea3",
            "cabb4afe3b994a2fa05805f929ac0c15",
            "1f98290d1e8a4f2d84e8c51aff85d73c",
            "a5b91ff6e2754527ba5cda3a8dc02e1c",
            "32143ff314654002a9b56bcbfcc35acd",
            "af69c75f8d7c49efb0a5e10724a9bf56",
            "c558da99a8614f93b1a8c34e61d2d6aa",
            "0f1fe81632b4498485c5e03512c3ebc4",
            "0b31c9f753a545588719bdd72c40f1d9",
            "a486c42c36f04f61a32d3970642acb6d",
            "490d4dea508e4ec983acf7e8e3d5b81e",
            "52eb76f9662143bbbdbc813a455261f5",
            "e1cec5a195cb4cd59076fc04083eb65a",
            "cb86c31550b94efeb5d60afc4b23aebb",
            "b39a1e61a34c4d7c8bb59481d9b22413",
            "074c7a1f5bdb4ad0a20f977602b791b7",
            "65e2d1b1772a48f0a947e0c6b83577a4",
            "4a5d50c36f2c4191a797842a3f4c8d2e",
            "fa139de97f09442fa6aba9bc98230ef4",
            "3881085ea76f426cab0c419e2be98468",
            "b990bd60e87440788167bf917a570126",
            "d5da70c4c70741038334db94a86893a2",
            "d890e858b83e43d4a281af3fc148f5f5",
            "f70cca9b846a403b91f258061cf273e9",
            "7b2c461c7834437ab1dc5f84c9e430b4",
            "4960ad1e6a034a339137e43c94a108c9",
            "cb5a80d2331a4d749fc8b00e2b0c3523",
            "5b4159be78ec4578a8d93900bd541e98",
            "838b6be594b947a6be822ec011ec12b7",
            "ae208968cd7448698bb95be945f7ad80",
            "abddd1b8d1dd4dbeb28e7651415c4fd7",
            "df2b4d735bf9432b9c6dc8bfff3ae8ac",
            "392a1ed133734395a3e2f6c96c780bdd",
            "03e6c0b65eab47cf8d10b1799104eecb",
            "48d0696cb57b4fce8172357af922ea0f",
            "0a59d6387d264de184805a35b828c01e",
            "036d57ccacb24e10a964e2ce345e6e41",
            "7743134a8daf4e0bb779ff9d0bc32108",
            "682e7e1128d64a3e858e3be39229c1d1",
            "e6698247e5454d759d203456e2b41a74",
            "1eeb8a87e42b44f189e9775abb4761c6",
            "6690d661561a48f8a494384fbde8ab79",
            "a261feb818774af188088aad121ef90d",
            "70ea70f69e59456aa4fe4ade1b98359e",
            "da24e16ad9614925b98cbaf64955c8cf",
            "e3ce15c12bb24176bdba6f431c3bc898",
            "9a404ee084ec4658ac8aae128a1f02cb",
            "c8a690949fee4ec0bb55ba479b7ff0e6",
            "cf725fda328b4554a4adeaaeaa0c9435",
            "ebce757f2f044c859409dce6af8d41b4",
            "8ad06e6a3d1742bda0dc7982e6405905",
            "7a111520cbfb4eb9b80b2dc05c9e8ece",
            "1a1b28a1b5ac4f6bbe22cb59e7d5ba8b",
            "f712629414474c07ad6a6f5268197d31",
            "d4121f5be81b4d7b84e3133035781936",
            "47c32114b8b14ecc82d1e158bdcdc798",
            "23bb6d0d9c454f86a82ada72d71a624d",
            "26269489d76a4621aff7e65d0a1b9ff1",
            "8fb4fc18640b4feab6a6b18dbad17bec",
            "9ff1a756ac05402195b92facd5b84eee",
            "ebe847996160438494215d85df8bc88c",
            "6307005bedac423abb0040698db9ef27",
            "83f13a33d1234359af3fa16a291cf371",
            "3c908183c7c445099c6c25364e0f3fcd",
            "d84788e7f5574659b06ce5ca349ccd63",
            "589ed62f1a2b4ca09b1c5b11b07bce55",
            "9cdda5e1de9643ecb15d59c9aa1e2f6b"
          ]
        },
        "id": "QMgP7XPaDfjb",
        "outputId": "0723107b-bd5e-47ee-fbe7-4028774bdaad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"Korean\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "Knuj0ERsDino"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 오디오 파일 경로 취합\n",
        "import glob\n",
        "\n",
        "path = \"/content/drive/MyDrive/speech_project/Impediment_dataset/*.wav\"\n",
        "raw_data_list = glob.glob(path)"
      ],
      "metadata": {
        "id": "6C2PjD-KDlMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"file_list : {raw_data_list[:10]}\")\n",
        "print(len(raw_data_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CePIcm9JDm1a",
        "outputId": "e5493a93-8c5e-495d-99eb-387cd3c29fff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import natsort\n",
        "\n",
        "# 2. 텍스트 파일 경로 취합\n",
        "path = \"/content/drive/MyDrive/speech_project/Impediment_dataset/*.txt\"\n",
        "labeled_data_list = glob.glob(path)\n",
        "# 숫자가 들어있는 파일명을 정확하게 sorting 해준다\n",
        "labeled_data_list = natsort.natsorted(labeled_data_list,reverse=False)"
      ],
      "metadata": {
        "id": "ZSMdhEGHDuhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"file_list : {labeled_data_list[:10]}\")\n",
        "print(len(labeled_data_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDVOwZOqDx9M",
        "outputId": "64226166-f970-4bcd-9995-509e689ef580"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "transcript_list = []\n",
        "for labeled_data in tqdm(labeled_data_list):\n",
        "    with open(labeled_data, 'r', encoding='UTF8') as f:\n",
        "        line = f.readline()\n",
        "        transcript_list.append(line)\n",
        "\n",
        "df = pd.DataFrame(data=transcript_list, columns = [\"transcript\"])\n",
        "\n",
        "df[\"raw_data\"] = raw_data_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkIQF4zODz43",
        "outputId": "fe2ee20e-faed-452c-a203-7ed4fd64b418"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().values.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY-1ayrNEIIP",
        "outputId": "b6a38049-a67c-4203-bc80-17d344b795c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "laxTuUvWELUl",
        "outputId": "6a46523f-65c4-4b17-a1c4-c7f83c25d503"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import Audio\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "ZtgYI0K4EOVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = Dataset.from_dict({\"audio\": [path for path in df[\"raw_data\"]],\n",
        "                       \"transcripts\": [transcript for transcript in df[\"transcript\"]]}).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "train_testvalid = ds.train_test_split(test_size=0.1)\n",
        "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
        "datasets = DatasetDict({\n",
        "    \"train\": train_testvalid[\"train\"],\n",
        "    \"test\": test_valid[\"test\"],\n",
        "    \"valid\": test_valid[\"train\"]})\n",
        "\n",
        "datasets.push_to_hub(\"coorinkie/speechproject_audio_data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "44c6f7c4886249a6899c861ccf684341",
            "9bcc20ccfcc1447a94745f80547353d6",
            "a0c30c4e911144ae9c73227d577b7949",
            "986b9c698f134d2c8ec3da6c2a7402ce",
            "f9a3346326f949369a5e2954cd49eaa4",
            "bcaae1a31f4a4cd8980876202da36248",
            "166951bdede0411eae71cfb4670c2a75",
            "0d598b5da7774cf6b804ac4d2ec7708d",
            "405fc55a1e8b4e95b1c9f1588b12e936",
            "4e960aa01b164e4480e131141df92597",
            "1110a72a3d6c419f97ba6469b15b88c5",
            "b4eff4dc93ee4d5f898e041ebc97a265",
            "0fdc286e602049a8b1894b76fad51b0e",
            "7dfe8e3a70d94587b165e01190795fc5",
            "0e6785f6baad431c8757b0f3568a2af2",
            "7b183cbd1e84431b8868b5f4e257874a",
            "468f1419b34b47b2964f6cb37abe6782",
            "d83836f91d09499db768106d450e4938",
            "ec246df7bcdc4f1fbc89cfec2fb92ba1",
            "e6d0fb4ed2bf4363b554d4ce12a5f4eb",
            "e48b61e4e79a4ed2a43ef9e0aa62bbe5",
            "ac339ccc5ef34b5983c082e6620e3126",
            "2a6528b05e424ec29692a0a8461fed2c",
            "33d871e0e8cb48668c11e97551756902",
            "4dbaa33e6a554139bb1ff383cf2a5827",
            "9e420d4dbefc4161a0500600f7693418",
            "408f18addfb14455abdd0a2367534484",
            "c64d4722975a4adea8e4adaa4cd5292a",
            "656e331eba654e30be3d8ee549ed9078",
            "ba638766d55446ce961dd9fe19b5b470",
            "783d1c03cc7149d98f6e215717d683bb",
            "04c35f4f289f48d2aba3e40ea1d56673",
            "60c1811a437f40949724922e7be05c47",
            "67368ef4ff414351868938f6bd9b42c7",
            "637734418f714e209c03640e7da334bc",
            "5683dd5c45eb4b7f944df14e7bf8fda3",
            "9503a89582914bfa924a17d514ef0e2b",
            "9de3abed10124298a5fb031cc9026a4f",
            "b4c3f8a4eea9429ea570665ab4e3d2fb",
            "64130e4a1ed442c9811d75557f0fe93b",
            "46e2a3a5cdf14587a66b371df0cb8115",
            "3781306289cb4574a2eaf993731aa8c5",
            "9cec2ab342074f8da8fcf04d57d51a1e",
            "dc7dc684d7b7402482127c164104b048",
            "39d1cea83e314949bf0596aa3d712b20",
            "5e31525880344712877e27371f0028fc",
            "50fa72826ba142b9b1b7f23478061316",
            "e068730a345f47b1a3afe53704979940",
            "3e833860eb044e0ca1b99941507ec43a",
            "6db6f37e39b54ea1883747bcd04f0e3d",
            "743e77daf35141acb0f4d6635f459cff",
            "556f620b3a354d35b3bad708cced9ea4",
            "e8e1328a7c484ccc8ddf05f4c5649928",
            "c04a74372f0543a9b8f343c3dd28f132",
            "86e886de4ab54a569a707ef14b221507",
            "adcef11c970a47d7a2ad4a4ee081454c",
            "48bf501c7a1447618dce9558a8d4884f",
            "df6a2600f8f14dd98ce67702587747fa",
            "e794b5e5d0ed4e77b844a9dce68e1645",
            "2049acf0e5784c368623b8dcc55e83da",
            "c544461a900843cabc28dbe5056b9800",
            "d8caadf570854745a86f074b0d1ab93a",
            "f5707df94fc944f3a49eb039d5c2e06d",
            "07ab1d6822f74fa3a4620c790b31c558",
            "d327c8a7ca174e2db9bbc0252637aa55",
            "63b6a59f838a4867bc78ea19737f4896",
            "488e362153324f13bbcd303619949647",
            "745a455922024c2d94b64f1c9dd31e97",
            "996ef9a40cbc4755a2a175ad7c7fedec",
            "4c548f47b6a5433eb2c3ee3e7d2427bc",
            "c8128bcd7ad24dc586df3040a315111a",
            "9e14f172c92a4321919519a2ab1dd926",
            "61725d991bf7460c876538143b0816b0",
            "774fa2aeecc04465b48fdb659fa3abc0",
            "87c3e91dbcec418ea60a8bfb2fa81970",
            "e50be5fe0f9d403ab37288e81cf797e0",
            "d8475a4aadbc4afdad50364603299a10",
            "6e46df396cf34fecb079e4c48fab0283",
            "13f3bc26725b4509bad15d89aa95df2b",
            "04689bf2ad76439abc61dfb9bf4b090a",
            "acfc9bda1f914c06a9e265fa1c439698",
            "7a462c9f0f53479b9483b93905f2b8e1",
            "c3776089cb7840f79c14cc9b8d0c87a5",
            "f15bcee4321d47ae951b5456e8734ff1",
            "a43e96c5c8ab4e9881cda2f991c36a9b",
            "577d6a11ce3a4b87b200569b732c7fd4",
            "3ed7aa6e7c974b0196d1c7125e026b53",
            "4e0429742a844baf87b25014869bd6eb",
            "4f426139b1004899a4e31fcb7094cfd5",
            "1d3a4da64df942e4be4eb8777f79100f",
            "9ec160080c014508a612486771ac274e",
            "329b8c4689b74075aacd1c15bd7e68df",
            "476eb29527304ebaaf6e700fef340d77",
            "577dab3a0383409d9183d1e649b6a0de",
            "e3441ada415d47eea06baa9d380d6c71",
            "b94933a1ca8e4a4eba0fa0106c8f1e57",
            "235080ebc0e7434abf71aa624d30af56",
            "cf8f6219d586431da73b6bc59b26c8da",
            "3420350604964b419fd45dc8bff939b2",
            "dc8a04dc94614b6499d30c697b54079b",
            "c8051d45a27f43fca8ab1025b389a7ba",
            "e2d8262bd7ea4c16b1fdc95dd4acaee8",
            "3b412ec3d4b04d8bbf8a4694c2a2c6b6",
            "fffd67645f114cd6a277bb075209cb43",
            "d2804e4cfd9b445898e30edb02e54624",
            "6588c4fc410c4b42bcdc483e12e3b131",
            "cc0c9811b38c4b6f967beaf84fed49f6",
            "342e51ace63447e985988c6b8157e4aa",
            "c1dc6c1def8c47eb9e4a32855b0e8567",
            "169e1628d9f34badb0672284d1e8d981",
            "32b727cde5e34a1685bb05c162887b87",
            "3f7907712c584e2b8785c7a778d2839a",
            "6b122fdb80a44144981f5c243ceef61c",
            "c4e9155bcf8449f6bf96453fd14fed95",
            "e3f7bf1b72ad4f8488268f3b40303a1f",
            "58f8fc3cabba49b58e964a36119a5801",
            "c421c836e0484ad99d31ee7c17678734",
            "cbdc2461c3e84ca4bf0342d0b6cb4047",
            "ad17e1fe7d054da7b3486cd7165241cd",
            "308da9737f9f4fa9b61237984d859408",
            "6861914c35024e1d8412c9fa26d99413",
            "9352f6734b944208942ece7b682fc010",
            "ac9057fdc8f24b4299156a1abb2f6573",
            "f0b89549bf0f475c9bd07958acd14f13",
            "8f25b74caca6474ebe7fc8dbe7ac58d7",
            "3e16e21aa4b949e7a29daae4e705bc97",
            "28cfb8a253d141b9b311764b40d84d3e",
            "7a9a74829d624b988cdb4ceb572c1c90",
            "0dc6e4ed373848ad89f9147445b7346b",
            "175d17ae7a7f4d379287db702ac6d6ef",
            "cee13f0ed93c4bbcb8edc2ae0f77f854",
            "787fc0ab20ce473397e259e726ea50e9",
            "e9040d38a1eb4440ae0750bd1463fcd5",
            "bb17f31bff7c4640840e0e009b5574ac",
            "34df0a4120a84d13b598d8b8f95e1fbf",
            "25cdcec4a8284047b92e8b9a22c25c64",
            "faf709c4984347a2988baf50c395f55a",
            "d62ce8ee5be34c6bb2205dc5452ed4b6",
            "e900ea60171b46d087ca977d16d960b4",
            "188ab5ecbb5f43e99c21d06ab9cd73c8",
            "c34fa695d5c24a0894def0623169e919",
            "66a0e8bf8928431ca1e63bd3c62e0b11",
            "c1754f8b0be746a4b1b2db7dd68e9a01"
          ]
        },
        "id": "w7gwuFUbES2A",
        "outputId": "0c7b65ff-a594-4325-d12d-4690cd084905"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import natsort\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive 마운트\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive가 마운트되었습니다.\")\n",
        "except:\n",
        "    print(\"Google Drive가 이미 마운트되어 있습니다.\")\n",
        "\n",
        "# 실제 파일 경로 확인 기능\n",
        "def check_directory_contents(base_dir):\n",
        "    \"\"\"지정된 디렉토리 내의 모든 파일과 폴더를 확인\"\"\"\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(f\"경로가 존재하지 않습니다: {base_dir}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"\\n{base_dir} 디렉토리 내용:\")\n",
        "    for item in os.listdir(base_dir):\n",
        "        item_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\" - 📁 {item}\")\n",
        "        else:\n",
        "            print(f\" - 📄 {item}\")\n",
        "    return True\n",
        "\n",
        "# 상위 디렉토리 확인\n",
        "my_drive_dir = \"/content/drive/MyDrive\"\n",
        "print(\"MyDrive 디렉토리 확인 중...\")\n",
        "check_directory_contents(my_drive_dir)\n",
        "\n",
        "# 사용자 입력 대신 파일을 찾기 위한 로직\n",
        "print(\"\\n가능한 음성 데이터 폴더 탐색 중...\")\n",
        "possible_dirs = []\n",
        "for root, dirs, files in os.walk(my_drive_dir):\n",
        "    # 너무 깊은 탐색 방지\n",
        "    if root.count(os.sep) - my_drive_dir.count(os.sep) > 2:\n",
        "        continue\n",
        "\n",
        "    # 오디오 파일이나 텍스트 파일을 포함하는 디렉토리를 찾음\n",
        "    wav_files = [f for f in files if f.endswith('.wav')]\n",
        "    txt_files = [f for f in files if f.endswith('.txt')]\n",
        "\n",
        "    if wav_files:\n",
        "        print(f\"오디오 파일이 있는 폴더 발견: {root} ({len(wav_files)}개 .wav 파일)\")\n",
        "        possible_dirs.append((root, 'audio', len(wav_files)))\n",
        "\n",
        "    if txt_files:\n",
        "        print(f\"텍스트 파일이 있는 폴더 발견: {root} ({len(txt_files)}개 .txt 파일)\")\n",
        "        possible_dirs.append((root, 'text', len(txt_files)))\n",
        "\n",
        "# 발견된 디렉토리가 없으면 사용자에게 직접 경로를 물어봄\n",
        "if not possible_dirs:\n",
        "    print(\"자동으로 데이터 폴더를 찾을 수 없습니다.\")\n",
        "    print(\"다음 변수를 수정하여 실제 경로를 지정해주세요:\")\n",
        "    print(\"text_dir = '텍스트 파일이 있는 디렉토리 경로'\")\n",
        "    print(\"audio_dir = '오디오 파일이 있는 디렉토리 경로'\")\n",
        "\n",
        "    # 예시 경로 (사용자가 수정해야 함)\n",
        "    text_dir = \"/content/drive/MyDrive/speech_project/Impediment_dataset\"\n",
        "    audio_dir = \"/content/drive/MyDrive/speech_project/audio_data\"\n",
        "else:\n",
        "    # 발견된 디렉토리 중에서 선택 (실제 구현에서는 사용자가 선택할 수 있게 할 수 있음)\n",
        "    text_dirs = [d for d in possible_dirs if d[1] == 'text']\n",
        "    audio_dirs = [d for d in possible_dirs if d[1] == 'audio']\n",
        "\n",
        "    if text_dirs and audio_dirs:\n",
        "        # 가장 많은 파일을 가진 디렉토리 선택\n",
        "        text_dir = max(text_dirs, key=lambda x: x[2])[0]\n",
        "        audio_dir = max(audio_dirs, key=lambda x: x[2])[0]\n",
        "        print(f\"\\n자동으로 선택된 텍스트 디렉토리: {text_dir}\")\n",
        "        print(f\"자동으로 선택된 오디오 디렉토리: {audio_dir}\")\n",
        "    else:\n",
        "        print(\"텍스트 또는 오디오 파일을 가진 디렉토리를 충분히 찾지 못했습니다.\")\n",
        "        # 예시 경로 (사용자가 수정해야 함)\n",
        "        text_dir = \"/content/drive/MyDrive/speech_project/Impediment_dataset\"\n",
        "        audio_dir = \"/content/drive/MyDrive/speech_project/audio_data\"\n",
        "        print(f\"\\n기본 경로 사용: \\n텍스트: {text_dir}\\n오디오: {audio_dir}\")\n",
        "        print(\"이 경로가 올바르지 않다면 수정 후 다시 실행하세요.\")\n",
        "\n",
        "# 지정된 디렉토리 내용 확인\n",
        "print(\"\\n선택된 디렉토리 내용 확인:\")\n",
        "check_directory_contents(text_dir)\n",
        "check_directory_contents(audio_dir)\n",
        "\n",
        "# 파일 목록 가져오기\n",
        "text_files = glob.glob(os.path.join(text_dir, \"*.txt\"))\n",
        "audio_files = glob.glob(os.path.join(audio_dir, \"*.wav\"))\n",
        "\n",
        "print(f\"\\n텍스트 파일 수: {len(text_files)}\")\n",
        "print(f\"오디오 파일 수: {len(audio_files)}\")\n",
        "\n",
        "# 파일이 충분히 있는지 확인\n",
        "if len(text_files) < 10 or len(audio_files) < 10:\n",
        "    print(\"경고: 파일 수가 매우 적습니다. 경로가 올바른지 확인하세요.\")\n",
        "    if len(text_files) < 10:\n",
        "        print(f\"발견된 모든 텍스트 파일: {text_files}\")\n",
        "    if len(audio_files) < 10:\n",
        "        print(f\"발견된 모든 오디오 파일: {audio_files}\")\n",
        "\n",
        "    raise ValueError(\"파일을 충분히 찾을 수 없습니다. 올바른 경로인지 확인하세요.\")\n",
        "\n",
        "# 파일 정렬\n",
        "text_files = natsort.natsorted(text_files)\n",
        "audio_files = natsort.natsorted(audio_files)\n",
        "\n",
        "# 텍스트 파일 로드\n",
        "print(\"\\n텍스트 파일 로드 중...\")\n",
        "transcripts = []\n",
        "for txt_file in tqdm(text_files):\n",
        "    try:\n",
        "        with open(txt_file, 'r', encoding='UTF8') as f:\n",
        "            line = f.readline().strip()\n",
        "            transcripts.append(line)\n",
        "    except Exception as e:\n",
        "        print(f\"파일 읽기 오류 ({txt_file}): {e}\")\n",
        "\n",
        "print(f\"로드된 텍스트 수: {len(transcripts)}\")\n",
        "\n",
        "# 파일 경로와 텍스트 목록의 길이 맞추기\n",
        "min_len = min(len(transcripts), len(audio_files))\n",
        "print(f\"사용할 데이터 수: {min_len}\")\n",
        "\n",
        "transcripts = transcripts[:min_len]\n",
        "audio_files = audio_files[:min_len]\n",
        "\n",
        "# 데이터프레임 생성\n",
        "print(\"\\n데이터프레임 생성 중...\")\n",
        "# 새로운 인덱스로 데이터프레임 생성하여 길이 불일치 문제 방지\n",
        "data = {'transcript': transcripts, 'raw_data': audio_files}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(f\"데이터프레임 생성 완료! 크기: {len(df)}\")\n",
        "print(f\"데이터프레임 처음 5행:\\n{df.head()}\")\n",
        "\n",
        "# 데이터셋 생성\n",
        "if len(df) > 0:\n",
        "    from datasets import Dataset, DatasetDict\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    print(\"\\n데이터셋 생성 중...\")\n",
        "\n",
        "    # 데이터 분할 전 열 이름 변경\n",
        "    df_renamed = df.rename(columns={'raw_data': 'audio', 'transcript': 'transcripts'})\n",
        "\n",
        "    # 데이터 분할\n",
        "    train_df, temp_df = train_test_split(df_renamed, test_size=0.2, random_state=42)\n",
        "    test_df, val_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "    # 분할된 데이터셋 크기 확인\n",
        "    print(f\"훈련 데이터셋 크기: {len(train_df)}\")\n",
        "    print(f\"테스트 데이터셋 크기: {len(test_df)}\")\n",
        "    print(f\"검증 데이터셋 크기: {len(val_df)}\")\n",
        "\n",
        "    # 데이터프레임을 데이터셋으로 변환\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    test_dataset = Dataset.from_pandas(test_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "    # 데이터셋 사전 생성\n",
        "    dataset = DatasetDict({\n",
        "        'train': train_dataset,\n",
        "        'test': test_dataset,\n",
        "        'validation': val_dataset\n",
        "    })\n",
        "\n",
        "    print(\"\\n데이터셋 생성 완료:\")\n",
        "    print(dataset)\n",
        "else:\n",
        "    print(\"데이터프레임이 비어 있어 데이터셋을 생성할 수 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf3ByoMpEcLJ",
        "outputId": "49666cf9-469e-4298-f3ca-7c3bc8e33724"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 허깅페이스 토큰 입력 요청\n",
        "print(\"허깅페이스 데이터셋 'coorinkie/speechproject_audio_data'에 접근하기 위해서는 인증이 필요합니다.\")\n",
        "print(\"1. https://huggingface.co/settings/tokens 에서 토큰을 생성하세요 (READ 권한 필요)\")\n",
        "print(\"2. 생성된 토큰을 아래에 입력하세요\")\n",
        "\n",
        "# 토큰 입력 받기\n",
        "token = input(\"허깅페이스 토큰을 입력하세요: \")\n",
        "\n",
        "# 토큰 설정\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = token\n",
        "\n",
        "# 라이브러리 설치 (torchtune에 영향을 주지 않도록 조심스럽게 설치)\n",
        "print(\"\\n필요한 라이브러리 설치 중...\")\n",
        "!pip install -q huggingface_hub[cli] --upgrade\n",
        "!pip install -q datasets --upgrade\n",
        "\n",
        "# 캐시 설정\n",
        "import os\n",
        "os.environ[\"HF_HOME\"] = \"/content/hf_home\"\n",
        "os.environ[\"HF_DATASETS_CACHE\"] = \"/content/hf_home/datasets\"\n",
        "\n",
        "# 캐시 디렉토리 생성\n",
        "os.makedirs(\"/content/hf_home\", exist_ok=True)\n",
        "os.makedirs(\"/content/hf_home/datasets\", exist_ok=True)\n",
        "\n",
        "# 허깅페이스 로그인\n",
        "from huggingface_hub import login\n",
        "try:\n",
        "    login(token=token)\n",
        "    print(\"허깅페이스에 로그인 성공!\")\n",
        "except Exception as e:\n",
        "    print(f\"허깅페이스 로그인 실패: {e}\")\n",
        "    print(\"로그인 없이 계속 진행합니다...\")\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "# 데이터셋 로드 시도 (세 가지 방법)\n",
        "print(\"\\n허깅페이스 데이터셋 로드 시도 중...\")\n",
        "\n",
        "# 방법 1: 인증을 사용하여 직접 로드 시도\n",
        "try:\n",
        "    print(\"방법 1: 인증을 사용하여 직접 로드 시도 중...\")\n",
        "\n",
        "    # 다양한 옵션 시도\n",
        "    try:\n",
        "        dataset = load_dataset(\"coorinkie/speechproject_audio_data\", use_auth_token=token)\n",
        "    except Exception as e1:\n",
        "        print(f\"첫 번째 옵션 실패: {e1}\")\n",
        "        try:\n",
        "            dataset = load_dataset(\"coorinkie/speechproject_audio_data\", token=token)\n",
        "        except Exception as e2:\n",
        "            print(f\"두 번째 옵션 실패: {e2}\")\n",
        "            # 세 번째 방법\n",
        "            dataset = load_dataset(\"coorinkie/speechproject_audio_data\",\n",
        "                                   cache_dir=\"/content/hf_home/datasets\",\n",
        "                                   token=token,\n",
        "                                   download_mode=\"force_redownload\")\n",
        "\n",
        "    print(\"방법 1 성공! 데이터셋을 로드했습니다.\")\n",
        "    print(dataset)\n",
        "\n",
        "    # 데이터셋 샘플 확인\n",
        "    for split in dataset:\n",
        "        print(f\"\\n{split} 샘플:\")\n",
        "        print(dataset[split][0])\n",
        "\n",
        "    print(\"\\n방법 1 로드 성공!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"방법 1 로드 실패: {e}\")\n",
        "\n",
        "    # 방법 2: 파일 다운로드 통합\n",
        "    try:\n",
        "        print(\"\\n방법 2: 직접 파일 다운로드 및 통합 로드 시도 중...\")\n",
        "\n",
        "        import tempfile\n",
        "        import glob\n",
        "        from huggingface_hub import hf_hub_download, list_repo_files\n",
        "        import pandas as pd\n",
        "        import pyarrow.parquet as pq\n",
        "\n",
        "        # 데이터셋 파일 목록 가져오기\n",
        "        files = list_repo_files(\"coorinkie/speechproject_audio_data\", repo_type=\"dataset\", token=token)\n",
        "        print(f\"데이터셋 파일 목록: {files}\")\n",
        "\n",
        "        # parquet 파일 찾기\n",
        "        parquet_files = [f for f in files if f.endswith('.parquet')]\n",
        "        print(f\"Parquet 파일: {parquet_files}\")\n",
        "\n",
        "        if not parquet_files:\n",
        "            raise ValueError(\"Parquet 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "        # 다운로드 디렉토리 생성\n",
        "        download_dir = tempfile.mkdtemp()\n",
        "        print(f\"다운로드 디렉토리: {download_dir}\")\n",
        "\n",
        "        # 데이터 로드\n",
        "        data_dict = {}\n",
        "        for file in parquet_files:\n",
        "            try:\n",
        "                # 파일 다운로드\n",
        "                local_file = hf_hub_download(\n",
        "                    repo_id=\"coorinkie/speechproject_audio_data\",\n",
        "                    filename=file,\n",
        "                    repo_type=\"dataset\",\n",
        "                    token=token,\n",
        "                    local_dir=download_dir\n",
        "                )\n",
        "                print(f\"파일 다운로드 완료: {file} -> {local_file}\")\n",
        "\n",
        "                # 분할 이름 추출 (train/test/valid)\n",
        "                if \"train\" in file:\n",
        "                    split = \"train\"\n",
        "                elif \"test\" in file:\n",
        "                    split = \"test\"\n",
        "                elif \"valid\" in file:\n",
        "                    split = \"validation\"\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                # parquet 파일 로드\n",
        "                df = pq.read_table(local_file).to_pandas()\n",
        "                print(f\"{split} 데이터 로드: {len(df)} 행, 열: {list(df.columns)}\")\n",
        "\n",
        "                # 데이터셋으로 변환\n",
        "                data_dict[split] = Dataset.from_pandas(df)\n",
        "\n",
        "            except Exception as inner_e:\n",
        "                print(f\"파일 {file} 로드 실패: {inner_e}\")\n",
        "\n",
        "        # 데이터셋 사전 생성\n",
        "        if data_dict:\n",
        "            dataset = DatasetDict(data_dict)\n",
        "            print(\"\\n방법 2 데이터셋 생성 성공!\")\n",
        "            print(dataset)\n",
        "\n",
        "            # 데이터셋 샘플 확인\n",
        "            for split in dataset:\n",
        "                print(f\"\\n{split} 샘플:\")\n",
        "                print(dataset[split][0])\n",
        "\n",
        "            print(\"\\n방법 2 최종 성공! 허깅페이스 데이터셋을 로드했습니다.\")\n",
        "        else:\n",
        "            raise ValueError(\"데이터셋 로드 실패\")\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"\\n방법 2 실패: {e2}\")\n",
        "\n",
        "        # 방법 3: huggingface-cli 사용 시도\n",
        "        try:\n",
        "            print(\"\\n방법 3: huggingface-cli 사용 시도 중...\")\n",
        "\n",
        "            # 임시 디렉토리 생성\n",
        "            import tempfile\n",
        "            temp_dir = tempfile.mkdtemp()\n",
        "            print(f\"임시 디렉토리 생성: {temp_dir}\")\n",
        "\n",
        "            # CLI로 다운로드\n",
        "            !huggingface-cli download coorinkie/speechproject_audio_data --repo-type=dataset --local-dir={temp_dir} --token={token}\n",
        "\n",
        "            # 다운로드된 파일 목록 확인\n",
        "            print(\"\\n다운로드된 파일:\")\n",
        "            !find {temp_dir} -type f | sort\n",
        "\n",
        "            # parquet 파일 찾기\n",
        "            parquet_files = glob.glob(f\"{temp_dir}/**/*.parquet\", recursive=True)\n",
        "\n",
        "            if parquet_files:\n",
        "                print(f\"\\nParquet 파일 발견: {len(parquet_files)}개\")\n",
        "\n",
        "                # 각 분할에 대한 파일 그룹화\n",
        "                train_files = [f for f in parquet_files if \"train\" in f]\n",
        "                test_files = [f for f in parquet_files if \"test\" in f]\n",
        "                valid_files = [f for f in parquet_files if \"valid\" in f]\n",
        "\n",
        "                print(f\"훈련 파일: {len(train_files)}개\")\n",
        "                print(f\"테스트 파일: {len(test_files)}개\")\n",
        "                print(f\"검증 파일: {len(valid_files)}개\")\n",
        "\n",
        "                # 데이터 파일 딕셔너리 생성\n",
        "                data_files = {}\n",
        "                if train_files: data_files[\"train\"] = train_files\n",
        "                if test_files: data_files[\"test\"] = test_files\n",
        "                if valid_files: data_files[\"validation\"] = valid_files\n",
        "\n",
        "                # 데이터 로드\n",
        "                data_dict = {}\n",
        "                for split, files_list in data_files.items():\n",
        "                    for file in files_list:\n",
        "                        try:\n",
        "                            # parquet 파일 로드\n",
        "                            df = pq.read_table(file).to_pandas()\n",
        "                            print(f\"{split} 데이터 로드: {len(df)} 행, 열: {list(df.columns)}\")\n",
        "\n",
        "                            # 데이터셋으로 변환\n",
        "                            data_dict[split] = Dataset.from_pandas(df)\n",
        "                        except Exception as err:\n",
        "                            print(f\"파일 {file} 로드 실패: {err}\")\n",
        "\n",
        "                # 데이터셋 사전 생성\n",
        "                if data_dict:\n",
        "                    dataset = DatasetDict(data_dict)\n",
        "                    print(\"\\n방법 3 데이터셋 생성 성공!\")\n",
        "                    print(dataset)\n",
        "\n",
        "                    # 데이터셋 샘플 확인\n",
        "                    for split in dataset:\n",
        "                        print(f\"\\n{split} 샘플:\")\n",
        "                        print(dataset[split][0])\n",
        "\n",
        "                    print(\"\\n방법 3 최종 성공! 허깅페이스 데이터셋을 로드했습니다.\")\n",
        "                else:\n",
        "                    raise ValueError(\"다운로드된 파일에서 데이터셋을 생성할 수 없습니다.\")\n",
        "            else:\n",
        "                raise ValueError(\"다운로드된 폴더에서 Parquet 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "        except Exception as final_e:\n",
        "            print(f\"\\n모든 시도 실패: {final_e}\")\n",
        "            print(\"\\n========== 중요 안내 ==========\")\n",
        "            print(\"허깅페이스 데이터셋 'coorinkie/speechproject_audio_data'는 비공개 데이터셋입니다.\")\n",
        "            print(\"입력한 토큰으로 접근할 수 없거나, 데이터셋 구조에 문제가 있을 수 있습니다.\")\n",
        "            print(\"1. 토큰이 유효한지 확인하세요.\")\n",
        "            print(\"2. 데이터셋 소유자(coorinkie)에게 접근 권한을 요청하세요.\")\n",
        "            print(\"3. 현재 프로젝트를 위해서는 이전에 성공적으로 만든 로컬 데이터셋을 사용하는 것이 안정적인 방법입니다.\")\n",
        "            print(\"로컬 데이터셋과 허깅페이스 데이터셋은 내용과 구조가 동일하므로 모델 훈련에 영향을 미치지 않습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d328df9d37ad40ac9392414c9759213c",
            "3f6eedfb0ef44f9490714d1811382b42",
            "c339f39d9e124625a273c2a2f239f153",
            "d30d7d795c594ed882df7354081138de",
            "439e853afbae4279a55931230b245a37",
            "91c8cc87c6d647a892ee618c43e770c5",
            "179123768cad491a81c59565172f3442",
            "3e578f229d0742d8879d51a678b224c8",
            "768e9c9831a345218216cfe348712297",
            "9b369210bfc8477bb38e445d139a2c06",
            "87a4c70f38224f0298b9f4091c87e279",
            "b27e9d7b10a344c99d3641f265c3be21",
            "dde79847fc9b4c9ba91d2c49332490f8",
            "f74cead489f54903b9688e28ed5f6381",
            "ee61c7047de44048ab8d853d57ed2cde",
            "724dea93c3c4466691ebb49c3533f766",
            "6d252eb66268414884e84efe04fb65e7",
            "f99fb08be4d946459a2e87dad21f9e49",
            "f78621fdd55d4ae9b0f2f15a03fe73d0",
            "8af20e7b7fae4af291ce11d307b98462",
            "ea74bc9fc0734a0c8b917f3654bf3aec",
            "25f9931d06824151af04add4a9151f8b",
            "5b80867b4a8444c6b05a135f5c18d7f3",
            "0c3bac887341457e8843481560a1e894",
            "c7a01c759a104b16a18c1ce84ed44524",
            "6500477cec8b4c2194d1ca455bc4b78c",
            "efbeba6a895b4ce39ad8eedf2728710b",
            "50c0bd65c7094151abd22bd164cd4ca8",
            "7302e711adb54214b64b5a2616121e3a",
            "9f038fafd41c4e08a6b19bfdc38c3330",
            "b737e18956d049579f02005cf481975c",
            "f92c393690084a598232ab7cf9c42ec7",
            "1aca6a27b4b746d188e39368af95d7e6",
            "23606705f8614a58889ab08bc739fcf2",
            "0d770beb46f64992b42ac6fcd9e00868",
            "47ecdb212240499ca9a24711d581e4eb",
            "8c8a284f11bc472c86561ef00035a777",
            "7f41bb6fc3bd4d3e86b85e03b0df896a",
            "fbce72fef0004a5aa31bcfc78f404d41",
            "a8eb38e4359d4d5a9186b315c79046b5",
            "ca7737b09c624b11b6a0bf1a582d82af",
            "bdc11d2766344c7f8bc7ca31e1b0887c",
            "2411b40b46e845178f0dde437a80a3ce",
            "486e3de95fd446de9937e6c799e7db6f",
            "4da58a08df434028aa78de4ae222179a",
            "93eb5f32880c4eaa8ea2f8473767a974",
            "48daa5f19a484d8880be99c1e2aeb701",
            "2229149e457c4f9ba2e462e376748336",
            "5288d3b1456f43e193aa787b6b23c946",
            "5b7b9eaa0e774560b2c5927a05b4d203",
            "b733bf0a896e466fa70549df02a5ffb5",
            "d7a2fcb696c24ab69bcd33e86a2bf3ef",
            "5f7e1564fe444b299e3e065dbdeee854",
            "7ff96a5ce14e4ea7b56a739d6a5c7e52",
            "e6c882d3cacf4096a0728245fbdc7fba",
            "e938bfbe4f2449d896339a949533d4aa",
            "d0d6e8457ba2417b89e6300c5996cc74",
            "954b5de58bda4a0db03d96289464a6e1",
            "7226463fd2ee4b0793721dc34938d934",
            "df629243e93b44bdb77f7d65b72766d2",
            "c44aa6e9df364cb996c44fb6d5eddd2b",
            "0342fa5b4c994bdda5f46967c2070b2f",
            "6d73e6dd5ba64be88e7d179e2e586838",
            "fa619c9ee365459183df9bde412a5032",
            "67ff6d87fbe04d8c98a1289c3bd94d53",
            "e7b93b2805e24d4795be7bbf3019a868",
            "78b6cb53421e4708a771b24d5abed3e9",
            "39959a5ddc2945d9817ed8d4e69d8da8",
            "b22af43aed184324b02913b7ce0d4004",
            "d1652772c0074f30ac51565e022c55ca",
            "f0b57f68f9924af8b27f0a61d8c87d36",
            "53fb89a8521f4da7898d8c25e57147a1",
            "8594d1bddc744fb18247461c822c761f",
            "85f547c850b24b9b895dec5fe9b70702",
            "4a99975d8da24ddda60d5847efb7806d",
            "e4911b979db34a84abb1fe7546417e1a",
            "3b3fa16cb5f64bcc9ad3fa044b714fe6",
            "33913e142e724d809e4e5e937c5b6cd2",
            "6de2efd2a00f420f90c711b3fe6f1246",
            "2d5d5e5db1034a67abd309397acaad37",
            "c3d319efb2ae45ee85e190425147bf3b",
            "150a920f1a6646a5aa3a88e92a2958ec",
            "d81eb38ec09a45a3a744cb7a25ec1108",
            "3946d0ae653a434ca09b0bcdf394ed79",
            "e626dfe8873a4cf19899da7076b1ff3e",
            "9f87bfe0fb0b4578b99740117e15f097",
            "4919050ea1334fa59d9d71f69201a12e",
            "5ac5ff36c4304d65a0d94a4979812f5c",
            "0d3a0921aa7c4f908c128666e3a3e975",
            "8abd929bbfee46938625711285f34da7",
            "fed496a89c544b43bc782dba209bff78",
            "525912a71c9e43fdbf336ba2e053fe44",
            "c39b8827062f415c9d4c54b8168aad6b",
            "ab48b865222b419fbeb9ab2d10ff1e36",
            "25f1cc2c7c3c41d8aecc2383f010b5cf",
            "4d6bfba94a8649bb9ba8278c08873970",
            "291e8faa17af4607b112e439dd79402b",
            "6c4b61a7c5324062b6a80b0e249671a8",
            "d56d22d445ef44939c64c0da32b9690f",
            "31c67d8903da4c3c85b777e8f3df3106",
            "5bc4f10664db4ea288317ab70b78599c",
            "1e1e11e8166448c5bb56eac47ee42230",
            "77636c4330874fd09bc38f4219d0cbcd",
            "83781121781e46f5afd62ad38cf7ae90",
            "7d2137f0f0184aefaf647aa8f93b9617",
            "730989df4eb145eba1e91423796856d5",
            "a93de3f7dee94c4e8f6eebc0227f03fd",
            "b85c4fc7bcf24b938988aeec6ae0aaac",
            "6882a5476e204feaa5aa2bd05e7aed46",
            "99e8d9ab6f244bd08cc082e5a0a0b9c7",
            "8d9ecf844a6f453885ba5d51ea5d054c",
            "aefc6fb9aa93461f825dbaca2bf405a8",
            "9ca19c9473a841a48a690a7518ee38c3",
            "9927d4e9226a4c0186a050a73228e4ab",
            "704b296432c54822931f2b82d83366be",
            "94ab6449116f4322b06c4d4412c62e94",
            "29a037b612114bf0aa0fcf4c960b9ec7",
            "00f9a4e78a2d4c199b8809db2d2da043",
            "70170a10b4c7483d999cfa25b65a4e36",
            "180dfda3eb6148d597f58136d01ea0fa",
            "27b283fcd061444bbb33fc7c755750d3",
            "41e522b765a84ed58728c04e3b0cdc67",
            "e27a830e379f4ed29cae3f1ab54b7044",
            "c2f78a63858b498f8c4a4c8e1527566f",
            "ad6953a839454d069d209607e30d8a30",
            "92d4199b1aba4722a9ae94f47603edde",
            "41739b4cc8c840478a23e74bbca83725",
            "763b0fc20dfd4888a9791e8f49998444",
            "32bb7e1614a94f4f9fb11871edeef5fa",
            "90a5251e723f4dbd8f76ad67135d0137",
            "ce162084a5b54d27a8f0f0922bec1b96",
            "2a1bd437002847c690ab627ba28aa03d",
            "3d00251a87b74d6794f48c9de7f5ba9b",
            "7424e06c88b34b139557a3b44a3695f1",
            "08617a0ba4cf457f906c231a64fa4347",
            "c8cf3ad25ee2439a8ae28ad550312d69",
            "dae840afbf0a4ce3ba0bb2b0fe80535e",
            "17fd3a88a4d847459ff251cf203e6765",
            "327faa781b84403bade3a6a3faa2c858",
            "6603f5ea819d4922ae24595cc87144a7",
            "c691d200871d4e9b9b524d8b035b1cfb",
            "c4b0e7a076964bbea54d7ac915142e61",
            "3c2c23c1145c45cc96f960c6c4bd5ec3",
            "0b787c7ae0fa4086a8fa4eba7889ee33",
            "2e66dc3e37204e4d908e125ea2543eba",
            "43bb6babfdea40229a758fdfdb7ced1d",
            "d8b9e80c2da54ad7a65f0bef8cbadffc",
            "4671dcd9f3894ee283eee322c58302f1",
            "94912299b03b47149892d7756ed73db7",
            "ca682f7d73544d2a87e9dd6e60e08291",
            "9ce5dbe9f88d4518b8d6fce0ead3ea41",
            "6b5291494e5a4837ade2abed5416c8a8",
            "f6141e0f62db4d6191941acdc8b78767",
            "6e8da0bfb1884ac4804a6a7b7247f2bb",
            "bdf98993e9b14614959f9ea51d6d219b",
            "3b087fa8a5854aa4b853c33fafe3eb90",
            "b3aab0cc65c4424e8cdb855e0a46b6e3",
            "42cab0aa7f0d41798adae75ef6908793",
            "562c91b18d4d4fa2bc07ad8582d118e9",
            "cdb660e965b24a5db826fdfb5dff1085",
            "5193949496e74123aadd6b28fffe6a9c",
            "f2fad90f888948a990be836970567f83",
            "c69606df3a8140b7bcda4ca48546b85d",
            "d374dceabb1549c6b00b5b17f418d206",
            "fa6edfe9520e489c9721db264c1c8195",
            "284cf3cbe0e74af2bb874d1de27cb72f",
            "69947ccd535649c7b0734f07c6834c57",
            "972d4b8c99d143809b1256fc13157355",
            "ae088432dc754659841709d5a49ef22f",
            "d816f6391dbc401092cefabe577e5505",
            "60795ac1623d4f8ba24f238b9eae97ae",
            "49e8e8eed50847ffbbdab1dd7d0e78fc",
            "05ffd1c8d21e4b999543fd72e6ae8677",
            "27ef1c82a9ec41aa9e56b8794396fbf0",
            "ac61078b4e1e402ca97519fb6629110a",
            "15c6c746b32749b8b50f425b3ebe5676"
          ]
        },
        "id": "3FGUmsTfEgHD",
        "outputId": "d7854723-4b00-422e-b0c9-8d985b85fcf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 확인\n",
        "print(dataset)\n",
        "\n",
        "# 훈련 데이터 사용\n",
        "train_data = dataset['train']\n",
        "\n",
        "# 테스트 데이터 사용\n",
        "test_data = dataset['test']\n",
        "\n",
        "# 검증 데이터 사용\n",
        "validation_data = dataset['validation']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKDBWDeuE7ZU",
        "outputId": "d674c71e-a108-47f9-ab2c-5d132d1525a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    # 오디오 파일을 16kHz로 로드\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # input audio array로부터 log-Mel spectrogram 변환\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # target text를 label ids로 변환\n",
        "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
        "    return batch"
      ],
      "metadata": {
        "id": "IfV8BIEXE_MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 bytes와 path를 처리하는 올바른 전처리 함수\n",
        "\n",
        "import io\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    # 🎵 오디오 데이터 처리\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    try:\n",
        "        if \"bytes\" in audio and audio[\"bytes\"] is not None:\n",
        "            # bytes 데이터에서 오디오 로드\n",
        "            audio_bytes = audio[\"bytes\"]\n",
        "\n",
        "            # bytes를 파일 객체로 변환\n",
        "            audio_io = io.BytesIO(audio_bytes)\n",
        "\n",
        "            # soundfile로 오디오 읽기\n",
        "            audio_array, sample_rate = sf.read(audio_io)\n",
        "\n",
        "            # 스테레오면 모노로 변환\n",
        "            if len(audio_array.shape) > 1:\n",
        "                audio_array = np.mean(audio_array, axis=1)\n",
        "\n",
        "        elif \"path\" in audio and audio[\"path\"] is not None:\n",
        "            # 파일 경로에서 오디오 로드\n",
        "            audio_array, sample_rate = sf.read(audio[\"path\"])\n",
        "\n",
        "            # 스테레오면 모노로 변환\n",
        "            if len(audio_array.shape) > 1:\n",
        "                audio_array = np.mean(audio_array, axis=1)\n",
        "        else:\n",
        "            # 빈 오디오\n",
        "            audio_array = np.zeros(16000)\n",
        "            sample_rate = 16000\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 오디오 로드 실패: {e}\")\n",
        "        # 빈 오디오로 대체\n",
        "        audio_array = np.zeros(16000)\n",
        "        sample_rate = 16000\n",
        "\n",
        "    # 🎯 Whisper용 오디오 전처리\n",
        "    # 16kHz로 리샘플링 (필요시)\n",
        "    if sample_rate != 16000:\n",
        "        # librosa 사용해서 리샘플링\n",
        "        import librosa\n",
        "        audio_array = librosa.resample(audio_array, orig_sr=sample_rate, target_sr=16000)\n",
        "\n",
        "    # feature extractor로 변환\n",
        "    batch[\"input_features\"] = feature_extractor(audio_array, sampling_rate=16000).input_features[0]\n",
        "\n",
        "    # 📝 텍스트 전처리\n",
        "    text = batch[\"transcripts\"]\n",
        "    batch[\"labels\"] = tokenizer(text).input_ids\n",
        "\n",
        "    return batch\n",
        "\n",
        "print(\"🎯 bytes/path 처리 전처리 함수 준비 완료!\")\n",
        "print(\"이제 다시 데이터 전처리를 시도해봅시다...\")\n",
        "\n",
        "# 🧪 한 개 샘플로 테스트\n",
        "try:\n",
        "    sample = dataset[\"train\"][0]\n",
        "    print(\"🔍 첫 번째 샘플 bytes 확인:\")\n",
        "    audio = sample[\"audio\"]\n",
        "    print(f\"bytes 크기: {len(audio['bytes']) if audio['bytes'] else 0} bytes\")\n",
        "    print(f\"path: {audio['path']}\")\n",
        "\n",
        "    # 테스트 실행\n",
        "    processed_sample = prepare_dataset(sample)\n",
        "    print(\"✅ 새로운 전처리 함수 테스트 성공!\")\n",
        "    print(f\"input_features shape: {processed_sample['input_features'].shape}\")\n",
        "    print(f\"labels length: {len(processed_sample['labels'])}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 테스트 실패: {e}\")\n",
        "    print(\"💡 추가 디버깅이 필요합니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqCOfCu1FAGi",
        "outputId": "8dae499d-6477-4cac-f9f5-13afa707fb6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎯 이미 전처리된 데이터 그대로 사용\n",
        "low_call_voices = dataset  # 전처리 완료된 데이터 바로 사용!\n",
        "\n",
        "print(\"📊 전처리 완료된 데이터 확인:\")\n",
        "print(f\"Train: {len(low_call_voices['train'])}개\")\n",
        "print(f\"Validation: {len(low_call_voices['validation'])}개\")\n",
        "print(f\"Test: {len(low_call_voices['test'])}개\")\n",
        "print(f\"컬럼: {low_call_voices['train'].column_names}\")\n",
        "\n",
        "# 🤖 모델 로드\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"Korean\", task=\"transcribe\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
        "\n",
        "print(\"✅ 모델 로드 완료! 이제 훈련 설정으로 넘어가세요!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "b6121c5b613c4806a1cc96224813b76f",
            "0515c330e1ef4118bda034751d48f90e",
            "d0180f8baf8443b4b03390f57b9a3a77",
            "11148545808a4afb8e2aa68d0a1b790a",
            "9d4ff583a3fd4a77a2457efa549c2df8",
            "fb0a6355d46749ebb0cc4b7792504236",
            "2f466fd81be146588f4aafe0f24fdfdc",
            "cb93684c51824373bfd904f8cadbdc9f",
            "fef0d114570f4f109effc26284ddf094",
            "6050af0d451f43a1b757531b2bdb0f5e",
            "eafdf96619074c6da373bb6c9481f23e",
            "be1ad309cb144805aa12f09091cc08c4",
            "506d1d833db94b69b51f71036acf1a99",
            "16e2c6fa24ee46d2966b18bd7b02ce52",
            "4c990cba847a42519bf77b48cc37ee1a",
            "5b0a145532ce420eb5af26c5730076f8",
            "4ddda48972dc45788d82db90fc8b46ad",
            "2a56c494c467417e9659bcc19648b08d",
            "c172a7abeb874ad2835db0921e98fbc1",
            "8f585d2fbb154769a7b2908ad9192ab2",
            "b740f3d0bce34d8d83e3ca79e0b1e316",
            "e3bfc2ed02034a60ba3cee26c3ceae3d",
            "39d4850e6e2647acb676b403c571296e",
            "031348ca310d4f35b1112e7f80d2fb5d",
            "abe3cb74c6a44aecb14bc79fb23e2058",
            "21b93d35223e4a1a8da441f509142c34",
            "f40a90fb18404fa88112a1e7a7e64b2c",
            "f0f0850c9f0b4f38a8997353747fc73c",
            "f189a5be65a1436e9d9caca55e76447f",
            "979231ebfe5e4d04b4d6f71eea0fd07e",
            "91ed9840510c40c8aa728462d4cfc9e2",
            "b688f7b0345547f698132fc57c1904d7",
            "2c54f765fcd0499ea78e6b2c7cecba49"
          ]
        },
        "id": "eDOCm0IRFN9M",
        "outputId": "40a2d392-41ff-4666-d981-8647e12ce5ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper_overfitting_prevention\",   # 과적합 방지 전용\n",
        "\n",
        "    # 🎯 배치 크기: 과적합 방지를 위해 작게\n",
        "    per_device_train_batch_size=2,                   # 8→2 (과적합 방지)\n",
        "    gradient_accumulation_steps=8,                   # 2→8 (effective batch=16 유지)\n",
        "    per_device_eval_batch_size=4,                    # 8→4 (메모리 절약)\n",
        "\n",
        "    # 📉 학습률: 매우 보수적으로\n",
        "    learning_rate=5e-6,                              # 3e-5→5e-6 (매우 낮게)\n",
        "    warmup_steps=50,                                 # 40→50 (적당한 워밍업)\n",
        "\n",
        "    # ⏱️ 훈련 길이: 과적합 방지를 위해 짧게\n",
        "    max_steps=200,                                   # 400→200 (짧은 훈련)\n",
        "\n",
        "    # 🛡️ 정규화: 매우 강하게\n",
        "    weight_decay=0.2,                                # 0.01→0.2 (매우 강한 정규화)\n",
        "    gradient_checkpointing=True,                     # True (메모리 절약)\n",
        "\n",
        "    # 📊 모니터링: 매우 자주 (조기 발견)\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,                                   # 40→20 (매우 자주 평가)\n",
        "    save_steps=40,                                   # 40 유지\n",
        "    logging_steps=5,                                 # 20→5 (매우 자주 로깅)\n",
        "\n",
        "    # 🎯 생성 설정\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "\n",
        "    # 🏆 모델 선택: 최고 성능 모델 저장\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_cer\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=2,                              # 2개만 저장 (공간 절약)\n",
        "\n",
        "    # ⚡ 성능 최적화\n",
        "    fp16=True,\n",
        "\n",
        "    # 🚫 외부 연결 비활성화\n",
        "    report_to=[],\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "id": "1p-x_b5LFRVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # input_features를 배치로 분리\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # labels를 배치로 분리 (토크나이저 패딩)\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # 패딩 토큰을 -100으로 교체 (loss 계산에서 무시됨)\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "# 데이터 콜레이터 생성\n",
        "data_collator_fixed = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "KELJfnv2FWnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    try:\n",
        "        pred_ids = pred.predictions\n",
        "        label_ids = pred.label_ids\n",
        "\n",
        "        # -100을 패딩 토큰으로 대체\n",
        "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "        # 디코딩\n",
        "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "        # 정리\n",
        "        pred_str = [p.strip() if p.strip() else \"empty\" for p in pred_str]\n",
        "        label_str = [l.strip() if l.strip() else \"empty\" for l in label_str]\n",
        "\n",
        "        # CER 계산\n",
        "        cer_metric = evaluate.load(\"cer\")\n",
        "        cer = cer_metric.compute(predictions=pred_str, references=label_str) * 100\n",
        "\n",
        "        print(f\"🎯 현재 CER: {cer:.2f}%\")\n",
        "\n",
        "        return {\"cer\": cer}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 메트릭 계산 오류: {e}\")\n",
        "        return {\"cer\": 100.0}"
      ],
      "metadata": {
        "id": "KYrXiYS-FXfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation은 이미 처리되어 있으니 train과 test만 처리\n",
        "print(\"🔄 train 데이터 오디오 형식 변환 중...\")\n",
        "low_call_voices[\"train\"] = low_call_voices[\"train\"].cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"🔄 test 데이터 오디오 형식 변환 중...\")\n",
        "low_call_voices[\"test\"] = low_call_voices[\"test\"].cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"🎵 오디오 형식 변환 완료!\")\n",
        "\n",
        "# 전처리 함수\n",
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "# train과 test만 전처리\n",
        "print(\"🔄 train 데이터 전처리 중...\")\n",
        "low_call_voices[\"train\"] = low_call_voices[\"train\"].map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=[\"audio\", \"transcripts\"],\n",
        "    num_proc=1\n",
        ")\n",
        "\n",
        "print(\"🔄 test 데이터 전처리 중...\")\n",
        "low_call_voices[\"test\"] = low_call_voices[\"test\"].map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=[\"audio\", \"transcripts\"],\n",
        "    num_proc=1\n",
        ")\n",
        "\n",
        "print(\"✅ 전처리 완료!\")\n",
        "print(low_call_voices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "ee2b857abed941af972d3178b405c918",
            "96ee67a7da3e40969ece0a83fe94f42a",
            "6fe7b30a875b41b0ba6fc501970d2b13",
            "2c62bf71e85446bc9fe05a405315e4dd",
            "acfe07db8f304c00bc97a4d742d70380",
            "ff213f2245b24cd588c315ea3d0f12be",
            "aa7fea789e354876a6c62e2300a32618",
            "636fd309ae37449eae971b5b7ee6314c",
            "2259740aa65e4588aad47a339b6c13a8",
            "e77bb4239b2e40aeb83d9311935d2f7f",
            "839c296659b541c5b2de7d1af6b0a555",
            "7b9c2d48558940d5966ac9cdeac8757a",
            "f98cb2dc1c2d476fb389c0245f1fbcbc",
            "798fd4fa84094c16850a54210cd9fb05",
            "66c6ff4f2b354e0f934df97745b10f61",
            "409027120e6349599f09018e4b870f76",
            "3518146535994100959dc321536d90a0",
            "be9885963e0947f7afb7d506d8cc6de6",
            "185a0d76327a49d7b59f2f5f7461115c",
            "b77218e24a1149e3b44b6d16af6ff5be",
            "99c7e87f01a042ca9998b843dda48927",
            "f33be5d4e2e24b8dab878850e43e3b82"
          ]
        },
        "id": "S875a6vIFbRz",
        "outputId": "189cfa30-fb82-400f-f45f-051f9201e0a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 로컬 체크포인트 로드 (개선된 방법)\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "import os\n",
        "import torch\n",
        "\n",
        "checkpoint_path = \"./whisper_simple/checkpoint-50\"\n",
        "\n",
        "try:\n",
        "    # 체크포인트 디렉토리 존재 확인\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"체크포인트 경로를 찾을 수 없습니다: {checkpoint_path}\")\n",
        "\n",
        "    print(\"📂 체크포인트 파일 확인 중...\")\n",
        "    files = os.listdir(checkpoint_path)\n",
        "    print(f\"체크포인트 파일들: {files}\")\n",
        "\n",
        "    # 로컬 경로에서 직접 로드 (local_files_only=True 추가)\n",
        "    print(\"🔄 모델 로드 중...\")\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        checkpoint_path,\n",
        "        local_files_only=True\n",
        "    )\n",
        "\n",
        "    # 프로세서도 같은 체크포인트에서 로드 시도, 실패하면 베이스 모델에서 로드\n",
        "    try:\n",
        "        processor = WhisperProcessor.from_pretrained(checkpoint_path, local_files_only=True)\n",
        "        print(\"✅ 체크포인트에서 프로세서 로드 완료\")\n",
        "    except:\n",
        "        print(\"⚠️  체크포인트에서 프로세서 로드 실패, 베이스 모델에서 로드합니다\")\n",
        "        processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "    print(\"✅ Step 50 모델 로드 완료!\")\n",
        "    print(\"🎯 이제 이 모델을 사용할 수 있습니다.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ 모델 로드 실패: {e}\")\n",
        "    print(\"🔄 베이스 모델로 대체 시도 중...\")\n",
        "\n",
        "    # 대체 방법: 베이스 모델 로드 후 가중치만 로드\n",
        "    try:\n",
        "        model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "        processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "        # 체크포인트 가중치 로드\n",
        "        state_dict_path = os.path.join(checkpoint_path, \"pytorch_model.bin\")\n",
        "        if os.path.exists(state_dict_path):\n",
        "            state_dict = torch.load(state_dict_path, map_location=\"cpu\")\n",
        "            model.load_state_dict(state_dict)\n",
        "            print(\"✅ 베이스 모델 + 체크포인트 가중치 로드 완료!\")\n",
        "        else:\n",
        "            print(\"⚠️  pytorch_model.bin을 찾을 수 없어서 베이스 모델만 사용합니다\")\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"❌ 대체 방법도 실패: {e2}\")\n",
        "        exit(1)\n",
        "\n",
        "# 개선된 테스트 함수\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    오디오 파일을 텍스트로 변환하는 함수\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): 오디오 파일 경로\n",
        "\n",
        "    Returns:\n",
        "        str: 변환된 텍스트\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import librosa\n",
        "\n",
        "        print(f\"🎵 오디오 로드 중: {audio_path}\")\n",
        "        # 오디오 파일 로드 (16kHz로 리샘플링)\n",
        "        audio, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "        print(\"🔄 음성 인식 처리 중...\")\n",
        "        # 오디오를 모델 입력 형식으로 변환\n",
        "        input_features = processor(\n",
        "            audio,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\"\n",
        "        ).input_features\n",
        "\n",
        "        # GPU가 사용 가능하면 GPU로 이동\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        input_features = input_features.to(device)\n",
        "\n",
        "        # 텍스트 생성\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = model.generate(\n",
        "                input_features,\n",
        "                max_length=448,  # 최대 길이 제한\n",
        "                num_beams=5,     # 빔 서치 사용\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        # 텍스트 디코딩\n",
        "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "        print(\"✅ 음성 인식 완료!\")\n",
        "        return transcription[0].strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 음성 인식 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "# 사용 예시 함수\n",
        "def test_model():\n",
        "    \"\"\"모델 테스트용 함수\"\"\"\n",
        "    print(\"\\n🧪 모델 테스트:\")\n",
        "    print(\"transcribe_audio('your_audio_file.wav') 형태로 사용하세요\")\n",
        "    print(\"예: result = transcribe_audio('sample.wav')\")\n",
        "\n",
        "print(\"🎤 모델 준비 완료!\")\n",
        "print(\"📖 사용법:\")\n",
        "print(\"  - transcribe_audio('오디오파일경로.wav') 함수로 사용하세요\")\n",
        "print(\"  - test_model() 함수로 사용법을 다시 확인할 수 있습니다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494,
          "referenced_widgets": [
            "b8d97c88b54d4fb785087a82ce0d5261",
            "fa45882cca484374af82243a6924e1eb",
            "14c7ffa8655a4364b68931c54d7322b9",
            "f859148d7b2f4cb1b838d19df69d21c0",
            "ca6f1ec272394adba52f7b2cf2398f20",
            "f2c6b9de4d4f42968a4fe3525a3e4d92",
            "db084835d56d41debd191e09121773b3",
            "000fb395f92a44b2ab4012f644adc3bd",
            "e99b3ae624f547dea8e3949dcbb5567f",
            "3be91c19400b4cc29ea35d3dd0e5e8ab",
            "d6543f1646be48ceae7082a45030782f",
            "efbe41c0954849aaa99ec2c61ed8c95d",
            "e6c29463f3e94a5b9a54b17850ff93d2",
            "574427461b7a44e7a51c7cff243cbecb",
            "d904a87fde21483c8a3b5f44d16d3302",
            "e9dceb0f049a49b9af3844e49666c1ae",
            "3be08212182e41fb82043360e769b299",
            "3062bb60f5234cb89653020adb6a9269",
            "870ef7398e914e98be8857845c42a476",
            "98c45e85e65349499c602aed21571ebf",
            "0497583be4614e7fbffee3a287ef6852",
            "61ba84cba5134872866263aa18d6f2e1",
            "4e355978f0c443b8ad42e959da34b8aa",
            "b3a0501fd5424b539664b486c9a09118",
            "6bf7fc652f89409a93780202984e92a8",
            "b0e8d4157f484192bb5a52dab57c63e9",
            "fe513ade81b64b9db215c580fdb0ccce",
            "240011a1ddba4374b6edcf556dac5231",
            "377b2f15cde8452e8de73f1a114da34a",
            "485f23ebac7b4d9bb3a712cb3697c09e",
            "a32fd306922e435fb392c73e32c55ade",
            "25510fbfd81f4c4db356047a4acc05ae",
            "da0b9f48e6e34d97b49d43e0da5f798d",
            "dbed36140a09414f808f57d7fd7a8cac",
            "c3e0a24e4b5146ed88fe908286ec564c",
            "a2cc4fd4bdf54e7c8f329b681e2571c1",
            "9fafd4e49748411e8593d833ed077dc6",
            "8f3d08fe01e84bbc8a92b5746e1142db",
            "be85f0cd4dd948539c21c68ca55a3cc9",
            "22d83a0e7599407286966295b1146e3f",
            "02eba598577a4ccfb2511ba221c8288a",
            "027e27800d5b4961aadc101f00a3fb17",
            "47ed38dcca64444090e408328c29aa7f",
            "60b5cf5d27114954803b4aedd6812264",
            "e5a53075beee4b5596838973c62181a9",
            "42ad0d5221c745b1bad8cebcdc8555e4",
            "61fad89530df48f79886412ab54c77c8",
            "afb8cb8c4bea4c95bc2f48686c204f23",
            "a8bbaae4f8774c0dafd74e3c6a6ccdce",
            "a874e1bbd0304a7d84ea2b479510eeb7",
            "5c3c981cbafe472197f7511445f2ad98",
            "aa38b237c73e4297bc91383ce5d62f37",
            "6b1be198fcb349f6a2b1693ae74f0ac4",
            "c557e61158ca466e8ffc47ab1819c94f",
            "67f6735573ae4ecabebbf7f74ce9d378",
            "b8c09f41eb164593b455d005e0002005",
            "2b47f1cfc15d419eb032d35f8f03f1ee",
            "6fb50b9b740d430db1f3df23b3a0960b",
            "ff30f0fd2a3f43cfa4925254fbf03d66",
            "e8003e5972df4de8a74c46f3487c4ef2",
            "0f5cf9c958c740698054cf3a50510d89",
            "853fb5b98cb24c638ae748b1e06ee48f",
            "8cbf165d06844387a0737f887d4c110a",
            "74ad4eb2c9504b56ba6fbb9767702fc7",
            "089ccfad5db44b17b5e49ef6ba0dfb78",
            "de4472cd3401422c919b14ff2de011e0",
            "6b7cb77b594b4b72a0712816e365a845",
            "536ebd171f844a92b602ee530433c364",
            "04046d57a1c34caca0e99f1243224297",
            "a289903ee0d743e7a71d4832632c14a7",
            "35f54a6b7ba64634834b1061ff1115d9",
            "88d1a8d2ac304512afbbdb9f5ee50615",
            "e4ba9b9950774a17a895c2b96e2ec89d",
            "76b33330c22b4f908fe200627093e672",
            "273576a0339243eca388463fd415e090",
            "c92f8cbf92fe46bc81054d0a9a9ab786",
            "a803971c8cce467584db9ccb8d5a9597",
            "dcbef34235f04c4bb9d4c775f87cdc16",
            "5923161a796545579e50a675c0c1ed55",
            "789e1d8e0281450e8f9b9449e3d10bb1",
            "377a39f59a7b4890bbe456f7e865da4e",
            "826a33fa9508468da78a75fc58bc915e",
            "fbd07158fb44437e8a6417c633bed220",
            "504bf18ccfc84b1e92ec96e088bfe051",
            "6d8bcabf3e5e47118b58b9d88607ec5b",
            "e71d69c08a80475da0b35661f368c1ab",
            "3642bf6bf45c4ceca437a404d0b106e8",
            "c905ec6c3d7a47c5b86b403d225ab308",
            "077ab48415184e5a80701990a6712f76",
            "7d94a2770fc44b2fbf36bb24b0dd9a89",
            "6a18716080204ae1a21ca9b407b553b8",
            "3307e51283ab4543be649e4ed8f029ec",
            "6e5b0ff6dea94c14ad1bcb8b01f81b7a",
            "1c559b14b7fd4a4396d1bcf6e47265d9",
            "891b9727888945c8bc1b314cd33eb172",
            "7d8041116ee44f22a55e3ad027f7463c",
            "99d2dfccd1d147d7aa528fd955dd0afa",
            "06d6500f4b13465087b01c42b7cfff93",
            "03b0819480ab4a84bbeb016f4cf326ba",
            "a0bac921ac00488a9b8c09936cccbf7d",
            "7243ccf758ef42859c1dfaf6932796ec",
            "f9c88f579a2547b4918cbccd40e9cf88",
            "a40585d94bfc429bb28783684d04a6b9",
            "86fc57cdb75b41bc81dda54b14eb24f5",
            "9b0c08a950ae41548222f6bf6434de27",
            "a331ed38bab24f35b7755858bf9ce2dd",
            "7abd64d0e0be43b29828bcde3091ca5f",
            "04e6161798e6478a898d8c47080ec2d4",
            "a2faef44fae04f259575c4c263de29eb",
            "e79306ff5e8b409398fb2b992e2b489e",
            "9802daf399e949e893cc32924acea329",
            "fddc227fd1734f2485599a97ce824639",
            "9439d0ba93964bf38615406d805e7460",
            "7e7f9436ebaf485098cfe3c2ded38f24",
            "0dba457f3589411085cadfe3842e4b12",
            "41c756617487471c876e7a42b29c74e1",
            "8e46054a95794e388aa06c336c4f2aba",
            "52874e91563e402c9a816aa6a035aefb",
            "c43bddd7b52a4d4da50d2835c646e194",
            "c9428772a8ce487983dd8ee71c76544a",
            "af0eaa18c40948dbad348402fba18b12"
          ]
        },
        "id": "NMCKjxfVF1W-",
        "outputId": "ddaccce0-fb58-4387-806d-e51f1fff1f3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 import\n",
        "from transformers import (\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperProcessor,\n",
        "    WhisperTokenizer,\n",
        "    WhisperForConditionalGeneration,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")\n",
        "import torch\n",
        "import evaluate\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "# SpecAugment를 사용한 강력한 데이터 증강\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
        "    \"openai/whisper-small\",\n",
        "    # 매우 강한 데이터 증강\n",
        "    do_specaugment=True,\n",
        "    specaugment_freq_mask_param=25,        # 기본 15 → 25\n",
        "    specaugment_time_mask_param=50,        # 기본 35 → 50\n",
        "    specaugment_num_freq_masks=3,          # 기본 2 → 3\n",
        "    specaugment_num_time_masks=3,          # 기본 2 → 3\n",
        ")\n",
        "\n",
        "processor = WhisperProcessor(\n",
        "    feature_extractor=feature_extractor,\n",
        "    tokenizer=WhisperTokenizer.from_pretrained(\"openai/whisper-small\")\n",
        ")\n",
        "\n",
        "# Small 모델 + 강력한 SpecAugment\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 한국어에 특화된 설정\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []\n",
        "\n",
        "# Whisper 전용 데이터 콜레이터 정의\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # 입력 특징들을 분리\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        labels = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "        # 입력 특징들을 배치로 처리\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # 라벨들을 패딩\n",
        "        labels_batch = self.processor.tokenizer.pad(labels, return_tensors=\"pt\")\n",
        "\n",
        "        # -100으로 패딩된 토큰을 교체 (손실 계산에서 무시됨)\n",
        "        if \"attention_mask\" in labels_batch:\n",
        "            labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        else:\n",
        "            labels = labels_batch[\"input_ids\"]\n",
        "\n",
        "        # 시작 토큰이 있다면 제거 (디코더 입력에서는 필요 없음)\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "# 데이터 콜레이터 초기화\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "\n",
        "# 메트릭 계산 함수\n",
        "def compute_metrics(pred):\n",
        "    cer_metric = evaluate.load(\"cer\")\n",
        "    wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # -100을 패딩 토큰으로 대체\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    # 텍스트 디코딩\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # 공백 제거\n",
        "    pred_str = [text.strip() for text in pred_str]\n",
        "    label_str = [text.strip() for text in label_str]\n",
        "\n",
        "    # CER과 WER 계산 후 퍼센트로 변환\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\n",
        "        \"cer\": cer * 100,\n",
        "        \"wer\": wer * 100\n",
        "    }\n",
        "\n",
        "print(\"✅ 모델과 프로세서 설정 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P-cfiACH-BK",
        "outputId": "abe705b5-8927-4b79-e69e-8a1bdadbc235"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 설정\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper_small_strong_augment\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=2,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=100,\n",
        "    max_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    logging_steps=20,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_cer\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=False,\n",
        "    report_to=[],\n",
        "    push_to_hub=False,\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "# 트레이너 초기화\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=low_call_voices[\"train\"],\n",
        "    eval_dataset=low_call_voices[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=processor,\n",
        ")\n",
        "\n",
        "print(\"🚀 강력한 SpecAugment + Small 모델!\")\n",
        "print(\"🎯 목표: CER 30% 이하\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "6f9943acac194e8384ae29daa40c57bf",
            "8a3fd4a15f664f729c209234a84de3ee",
            "8d4658a3f57a4c39b9bdb807af03f01e",
            "f22af5b7beb148e79fcfa1e89350a787",
            "db9ace553e2f423186bf2a1b468836db",
            "e1852eacef934b72989c6d833ce62e37",
            "fa2a3b6dbab147dcbda2aeffc6b80944",
            "d5c3aeeb43e846818282e8202adb5337",
            "495ee2d023a44ee2bdd432e06f5f9d01",
            "f34629b9cf3e4719a37b2e8466e6fc68",
            "813c7b7359f342e0b094f8a9482be88c",
            "f7f348ab5e9043139bbadf6dd3a20da3",
            "43af6a1393274e56b9c96d69d7867f84",
            "229a51fd48594ede8977f5aaf56cfecb",
            "bddd1866ca5c4bf9a7cae9368f3caf45",
            "e979bc01860544218082003cfa4bddfb",
            "22685dfcaf9d42169b1474314d03c857",
            "d63656ea4a354843acebb8b237a33fbb",
            "e60c2f7d4e9246bc8caa67c47670ed1b",
            "362b01f413d24e1fb121ef98f29d3bfa",
            "fa7976b1edbb411d9ffbd06ecd9664d7",
            "d3bca1016b2a47eea04c7b9e0ec33cbc"
          ]
        },
        "id": "pYk1MkD2IBA9",
        "outputId": "61010e1d-2c88-47b9-918e-6ae318a3fe3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 과적합 방지 중심의 훈련 설정\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper_small_regularized\",\n",
        "    per_device_train_batch_size=2,        # 원래 크기 유지\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=2,\n",
        "    learning_rate=1e-5,                   # 원래 학습률 유지\n",
        "    warmup_steps=150,\n",
        "    max_steps=800,                        # 적당히 증가 (500 → 800)\n",
        "    weight_decay=0.15,                    # 가중치 감소 증가 (0.1 → 0.15)\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    logging_steps=20,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    load_best_model_at_end=True,          # 한 번만!\n",
        "    metric_for_best_model=\"eval_cer\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=False,\n",
        "    report_to=[],\n",
        "    push_to_hub=False,\n",
        "    remove_unused_columns=False,\n",
        "\n",
        "    # 🔥 과적합 방지 설정들\n",
        "    lr_scheduler_type=\"linear\",           # 선형 감소 (더 안정적)\n",
        "    dataloader_drop_last=True,            # 배치 크기 일관성\n",
        "    eval_accumulation_steps=4,            # 평가 시 메모리 안정성\n",
        ")\n",
        "\n",
        "# 더 강한 정규화를 위한 SpecAugment 설정\n",
        "feature_extractor_stronger = WhisperFeatureExtractor.from_pretrained(\n",
        "    \"openai/whisper-small\",\n",
        "    # 🎵 훨씬 더 강한 데이터 증강으로 과적합 방지\n",
        "    do_specaugment=True,\n",
        "    specaugment_freq_mask_param=35,       # 25 → 35\n",
        "    specaugment_time_mask_param=70,       # 50 → 70\n",
        "    specaugment_num_freq_masks=4,         # 3 → 4\n",
        "    specaugment_num_time_masks=4,         # 3 → 4\n",
        ")\n",
        "\n",
        "processor_stronger = WhisperProcessor(\n",
        "    feature_extractor=feature_extractor_stronger,\n",
        "    tokenizer=WhisperTokenizer.from_pretrained(\"openai/whisper-small\")\n",
        ")\n",
        "\n",
        "# 데이터 콜레이터 업데이트\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor_stronger)\n",
        "\n",
        "# 트레이너 재초기화 (더 강한 정규화 적용)\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=low_call_voices[\"train\"],\n",
        "    eval_dataset=low_call_voices[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=processor_stronger,  # 더 강한 SpecAugment\n",
        ")\n",
        "\n",
        "print(\"🛡️ 과적합 방지 중심 훈련!\")\n",
        "print(\"🎯 목표: CER 15% + 건강한 일반화\")\n",
        "print(\"📊 과적합 방지 전략:\")\n",
        "print(\"   - 더 강한 SpecAugment (35, 70, 4, 4)\")\n",
        "print(\"   - 가중치 감소 증가 (0.1 → 0.15)\")\n",
        "print(\"   - 적당한 훈련 단계 (500 → 800)\")\n",
        "print(\"   - 조기 종료로 최적 모델 선택\")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "f-q_GuFNVvrl",
        "outputId": "93a6f435-12ba-401c-be09-0eb4f985f440"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"custom_korean_speech\",              # 사용자 데이터셋\n",
        "    \"dataset\": \"low_call_voices\",                        # 실제 사용한 데이터셋 이름\n",
        "    \"dataset_args\": \"config: ko, split: train+validation\", # 한국어, train+validation\n",
        "    \"language\": \"ko\",                                    # 한국어\n",
        "    \"model_name\": \"Whisper_Small_Korean_CER20\",          # CER 24% 달성 모델\n",
        "    \"finetuned_from\": \"openai/whisper-small\",            # Small 모델 기반\n",
        "    \"tasks\": \"automatic-speech-recognition\",             # ASR 작업\n",
        "    \"tags\": [\"hf-asr-leaderboard\", \"korean\", \"whisper\", \"specaugment\", \"low-resource\"], # 추가 태그\n",
        "    \"model_description\": \"Korean Whisper model fine-tuned on 531 samples with SpecAugment, achieving 24.47% CER\"}"
      ],
      "metadata": {
        "id": "xXdM1YX5LT_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 현재 디렉터리의 모든 폴더 확인\n",
        "print(\"📁 현재 디렉터리의 폴더들:\")\n",
        "folders = [f for f in os.listdir('.') if os.path.isdir(f)]\n",
        "for folder in folders:\n",
        "    print(f\"  - {folder}\")\n",
        "\n",
        "# whisper 관련 폴더들 찾기\n",
        "whisper_folders = [f for f in folders if 'whisper' in f.lower()]\n",
        "print(f\"\\n🔍 whisper 관련 폴더들: {whisper_folders}\")\n",
        "\n",
        "# 각 whisper 폴더 안의 체크포인트 확인\n",
        "for folder in whisper_folders:\n",
        "    if os.path.exists(folder):\n",
        "        contents = os.listdir(folder)\n",
        "        checkpoints = [c for c in contents if c.startswith('checkpoint')]\n",
        "        print(f\"\\n📂 {folder}:\")\n",
        "        print(f\"  체크포인트들: {checkpoints}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYSJtP9BLf15",
        "outputId": "fa9c34ce-f227-49a6-fe11-1f34fc8f4d32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Hugging Face 다시 로그인\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "print(\"🔐 Hugging Face 로그인이 필요합니다.\")\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "c5255881e726435cbcd4167a9c356f79",
            "5b9510b4511545bf822b557d2cbecb3f",
            "cacb20d116b1425fb80b81481afd09b2",
            "e2f3e4a5f33a456393173bd1ed6a13fe",
            "16d9688820474f1ab6076d1da54f9b5f",
            "bcc041d6e7f7474c894046acb6cfd36e",
            "5270e3d49ac64439a79f048a99cdd6c3",
            "d884d40e1e3c43deb6e3919a9365b8f3",
            "a9701f3ce4434e86bca2881554ce5a2c",
            "39a3bd7112d74ffe8e60cbd7af75982a",
            "93cfd19d038d49339bd9f830788a286c",
            "c3dd2abaf8304afdb1a82864efc236b8",
            "0b0cfda511014760b12e62e44a2c941e",
            "12fdb987e50c49a49d6ccda29211ff83",
            "41eb481beb3544489b18dd6a89349309",
            "7f26675897db4b238003b47c5100828f",
            "4a9b349290c148fa8164bd2522b1749f",
            "16e1b48279f84fa2a35dc88572d29642",
            "28e097ae85a24adf9099d43303c59471",
            "72d4f5147fac44298f16441dae9a6ca8"
          ]
        },
        "id": "7783UGzGLjml",
        "outputId": "9d30850d-9052-412d-c1b9-9bb95db4eb93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 import\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "\n",
        "# 1. 현재 메모리에 있는 모델 확인\n",
        "try:\n",
        "    # 혹시 trainer가 아직 메모리에 있는지 확인\n",
        "    print(\"trainer 모델:\", trainer.model)\n",
        "    current_model = trainer.model\n",
        "except:\n",
        "    print(\"trainer를 찾을 수 없습니다.\")\n",
        "    # 새로 Small 모델 로드\n",
        "    current_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 2. processor 설정\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 3. kwargs 설정\n",
        "kwargs = {\n",
        "    \"dataset_tags\": \"korean_call_voices\",\n",
        "    \"dataset\": \"low_call_voices\",\n",
        "    \"dataset_args\": \"Korean low-call voices, 531 train + 29 validation samples\",\n",
        "    \"language\": \"ko\",\n",
        "    \"model_name\": \"Whisper_Small_Korean_CER20\",\n",
        "    \"finetuned_from\": \"openai/whisper-small\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": [\"korean\", \"whisper\", \"specaugment\", \"low-resource\"],\n",
        "    \"model_description\": \"Korean Whisper model fine-tuned on 531 samples with SpecAugment, achieving 24.47% CER\"\n",
        "}\n",
        "\n",
        "# 4. 업로드\n",
        "model_repo_name = \"coorinkie/whisper-small-korean-cer20\"\n",
        "current_model.push_to_hub(model_repo_name, **kwargs)\n",
        "processor.push_to_hub(model_repo_name)\n",
        "\n",
        "print(f\"✅ 업로드 완료: https://huggingface.co/{model_repo_name}\")"
      ],
      "metadata": {
        "id": "3G5aa1PJNMIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 import\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "\n",
        "# 1. 현재 메모리에 있는 모델 확인\n",
        "try:\n",
        "    # 혹시 trainer가 아직 메모리에 있는지 확인\n",
        "    print(\"trainer 모델:\", trainer.model)\n",
        "    current_model = trainer.model\n",
        "except:\n",
        "    print(\"trainer를 찾을 수 없습니다.\")\n",
        "    # 새로 Small 모델 로드\n",
        "    current_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 2. processor 설정\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 3. kwargs 설정\n",
        "kwargs = {\n",
        "    \"dataset_tags\": \"korean_call_voices\",\n",
        "    \"dataset\": \"low_call_voices\",\n",
        "    \"dataset_args\": \"Korean low-call voices, 531 train + 29 validation samples\",\n",
        "    \"language\": \"ko\",\n",
        "    \"model_name\": \"Whisper_Small_Korean_CER20\",\n",
        "    \"finetuned_from\": \"openai/whisper-small\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": [\"korean\", \"whisper\", \"specaugment\", \"low-resource\"],\n",
        "    \"model_description\": \"Korean Whisper model fine-tuned on 531 samples with SpecAugment, achieving 20.34% CER\"\n",
        "}\n",
        "\n",
        "# 4. 업로드\n",
        "model_repo_name = \"coorinkie/whisper-small-korean-cer20\"\n",
        "current_model.push_to_hub(model_repo_name, **kwargs)\n",
        "processor.push_to_hub(model_repo_name)\n",
        "\n",
        "print(f\"✅ 업로드 완료: https://huggingface.co/{model_repo_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "019d87ead6904c429c44dca767fec081",
            "29afa194fdd94f00ae82acf519207c45",
            "369b330e9b1a4b838fb00c6898a2bb9b",
            "2983e34905304feda5a902046e69dbf3",
            "3535577abeaf4df688dcc9e881fadc6c",
            "f8e803efce594633af28677b5a835868",
            "1179405bebb44c25acf3d66c41a305e8",
            "a7e99c16940b4822a0854bdb3e7a5b47",
            "76939a5e2f344168b6e67f210b6f2b44",
            "1cfcc093a0d74b38860fd350bbafa2e3",
            "6af2f2af8c1445ac9d671319b0717183",
            "f4a6631be3fe49b09950108f37202c11",
            "25a0817bc9ef41adacdd203fe03bb449",
            "1459942261ad4da58c2fe95b6fd046e8",
            "c28c9aaaf644437d9fcfd5f940f3496e",
            "07bf4913951f4de794f26227126c5a2d",
            "4122bbde46b04c6da53ba0722816bbde",
            "da35ed95555544edac6203d5f7f42688",
            "a28796565f3e4aeea8f2383c27417225",
            "6cfefaeb38ed46a7bd0850a5976d054e",
            "6fd93803264048a29e129748e2095f29",
            "453b89a39aa24c73b6009d59daa9af97"
          ]
        },
        "id": "CSDOeo4JNP5p",
        "outputId": "de0385aa-74dc-4662-e77d-27e03c4fc2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터셋 다시 로드\n",
        "print(\"📁 데이터셋 로드 중...\")\n",
        "\n",
        "# 만약 이전에 사용했던 변수명을 기억한다면:\n",
        "try:\n",
        "    print(\"기존 데이터셋 확인 중...\")\n",
        "    print(\"사용 가능한 변수들:\")\n",
        "    # 사용 가능한 데이터셋 변수 확인\n",
        "    import builtins\n",
        "    dataset_vars = [name for name in dir() if 'dataset' in name.lower() or 'voices' in name.lower()]\n",
        "    print(dataset_vars)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. 간단한 테스트용 데이터로 평가\n",
        "print(\"\\n🔄 Hugging Face 모델 테스트...\")\n",
        "\n",
        "# 테스트 텍스트\n",
        "test_texts = [\n",
        "    \"안녕하세요\",\n",
        "    \"오늘 날씨가 좋네요\",\n",
        "    \"한국어 음성 인식 테스트입니다\"\n",
        "]\n",
        "\n",
        "# 3. 모델 테스트 (텍스트로)\n",
        "from transformers import pipeline\n",
        "\n",
        "asr_pipeline = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"coorinkie/whisper-small-korean-cer20\"\n",
        ")\n",
        "\n",
        "print(\"✅ 모델 로드 성공!\")\n",
        "print(f\"📊 모델 정보: {asr_pipeline.model.config}\")\n",
        "print(f\"🎯 모델 이름: coorinkie/whisper-small-korean-cer20\")\n",
        "print(f\"🔧 태스크: automatic-speech-recognition\")\n",
        "print(f\"🌏 언어: 한국어 (ko)\")\n",
        "\n",
        "# 4. 모델 상세 정보\n",
        "print(f\"\\n📋 모델 메타데이터:\")\n",
        "print(f\"  - Base model: openai/whisper-small\")\n",
        "print(f\"  - Fine-tuned on: Korean call voices (531 samples)\")\n",
        "print(f\"  - Training CER: 20.34%\")\n",
        "print(f\"  - Tags: korean, whisper, specaugment, low-resource\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90caa3d9436d4073ba72be5ea1c5fe94",
            "ddb37bbde07a4528b7491bb194dfc341",
            "e77cc1dd8fdb44109edc5610f44a1f4f",
            "2c04428bf91f4a7f89d8386c07a3a109",
            "8a04e094c03040f4bcde07efe32c560b",
            "212b3b7b008d4833b5ed54ce2c75c741",
            "9321d74d33a3477c96e2287d37e7fdeb",
            "af633aba27e3485ca9395bc953a7fff7",
            "bde95fb7174e432e80c559985a9066fb",
            "d52b0e2062804beb85ad58b2564cb0fb",
            "4f5a1050266d46f7a55404b6992716e9",
            "310628b4533542f3bec4c8c2858d87d4",
            "79d00ce91c274651ba0ac77c47d9dd8a",
            "ffb1e0197df74af491501d548ec70a3e",
            "d5502b59f6ad4cc0b71feb2be6317f52",
            "8e69238868864048be4a0e360eb8a5d5",
            "7dabac2cf7bd4f06b3a86c13024a7e68",
            "303267c66c184499b7f0ce9f6ea9e592",
            "37e5b188703a43d88532836feaf692ec",
            "6c1328f82cdd4ca99f3b59c9a6f3821e",
            "263595a23cd54fc7b25bf99f7b5caf20",
            "1a3bd9223c444018a7d54319155a7976",
            "465e1aec7c0e4cb0b6b441f47eb8e26e",
            "570f675cbd7c4a5481e126cc9a81ae74",
            "205bfb4781344d7292114ed83eb9d532",
            "712bb4c2f00f4a2c9e16d8d0c62dbc64",
            "c8f39d920e5f432a819b48c41ccd08a5",
            "335601e80d084201a45448dc6ece917b",
            "ee2db8410ccf4c79a627ae4dccd28e4b",
            "903cf12a1541449f9d547a478d66c345",
            "6300a21b26124ffa815001ee1144c909",
            "7cf57269e94b42f0b9e47d514fc742a9",
            "d330b3911ed947268cacd864b783b2ba",
            "a596a41dfbca4afd93ba50237cd332ba",
            "ba8dabbde9714ef8b0fea8ab5d4ca1c5",
            "18bccadb28d54825939510eccc530d4a",
            "4a880a792f2147eda9162858f5d6c578",
            "3dbd3ac633ba42ea8a847e4ad4882fab",
            "263e6a59924b499d905ab54b5904696e",
            "691a500522504b2fb019eabcbd7af121",
            "6189cb5487434c318dfefe015cddc284",
            "605cd4cb4759447bb72541e482691cda",
            "c7ae4dcfd216424599d3bffc54e39ca6",
            "12f9b83e6a414f3d99a51fff0f6d2643",
            "684b70c186374c2697d18dbba63b8af7",
            "a354f0ecb5674c1e92109758e88df58f",
            "0d19b84900094c719345c90559830ada",
            "018832acc4334a2988849e9b0808ef0a",
            "bfbe4b5df99c4394b4596c6a59d174fc",
            "9ba4e4f3e0d44b91825042db22ef69e5",
            "e5ae3f51681e45d489ac4948a12407e7",
            "c9528045e19642ab97f22263ddc0506f",
            "08b69db0bad54cea8d5aaca5206a0680",
            "4cd77415ff034a8a9882256fb9e5fc9b",
            "aed99f0545f04c739c4632c64ccd1d3a",
            "31cd8edb06b8440a8260a4a9a5886586",
            "bbbdd5b45cb643e686735359328ea3f1",
            "6277adfaa19441a79509d227ddeb65b9",
            "81848621f1cb4c13b1b174af41332983",
            "776eaf1544bd44d3abd683e490936227",
            "a8ab77c9275f4a2984f04d170812bc28",
            "b687a13fbcd84a289700b0d335cc0969",
            "37cbfb8d6b1240e9ab1f86f910acaabd",
            "d63358337ae64da68f5ac733276dd443",
            "27e24802decf4f568f041e1550c4ce61",
            "2fc8d2d93986456cb27e04e1ee94f40d",
            "42716207748c440092e3a6bec9c313e0",
            "435875435fc64eba801fc701392e8944",
            "65a4f0eb6a8349f5a67d51cfdacbca83",
            "2be62b5b38494fd6bfa8e02166a41dbc",
            "d3f5bf55e6c54b3097af004af41bdcdb",
            "c0e2ff3fd1c7481e9d27216f2b4d2723",
            "de79ee84ea664c439a7933fed65984cc",
            "a597fbdeb58f4b28a893c6ddc11c766c",
            "d97b50d53fb04973823f391b052117fd",
            "a23044090586448daa0cb82b9a80a7f4",
            "aa5921847ce34794a1ff9c3693eeb6ad",
            "4dc8d709b8e548d6934eb01a3a315541",
            "46bdb5f340c84b07b2f877c44746d40d",
            "1bcc7f315f684c589b0cefc5fabcca92",
            "2d7021a46a4f4c15a53505917262af33",
            "be1c113e1b934c7781b6b46afd5f4b36",
            "ddbe3948ec43485893be8b732d757075",
            "aa5ddb3b64e64386ad580565329104ff",
            "c780948a6d8844a1bad8bfafa672a6e4",
            "2029b841525c4cc5a1f78d7f7ce36801",
            "34aca3e8cd8e4a76a1b8da0e8ce8a320",
            "c805f02ae3eb45fc869966ed26dd562d",
            "bb7df25cc621405a9e02ad3c30bbf987",
            "e9328f7e094c49f7b4eb7469f7970e15",
            "5aafe588511e42d9aafd88e506915d96",
            "51cac753ef6e47d58e2ccfcb439e83fb",
            "c2a323266cd34cd48be9c42abab95fce",
            "be24c730b0924ac9ba7e367ae6383442",
            "e5736cd36e80421e9e38aa97fd09a70e",
            "ff49efaf660544d6a38520210c1b94e2",
            "4c2fbb26842f4568b84bcacff2e04643",
            "39d502b6feb6465ca62190f8690c0be9",
            "659b708a96c941ee8d3b7bb4ae9331f3",
            "1bf62f9c17794616857bf20751b2fcc8",
            "35987f83862641fb9bd5cdf562588bd3",
            "9da3dc63d5294dd5bf2818e213cb55a1",
            "41cabeda9d2b4551ae4a46f13ca420f5",
            "804cb1dc4fd044e984414a2f6b62fd78",
            "2cde9dc5375b47cc86eebd6d468a8c3e",
            "65b58cc4c9424e7bbc2f6db6934c168b",
            "fa2c54d17f8e4ab09b496a6edbde23ab",
            "8c1c611315714ba2bde96ddd3ab8cbbb",
            "10a2686b4442410495866a1b41185432",
            "9fc893d81962423da19c5d152166d0e4"
          ]
        },
        "id": "5vE2TutSNv2_",
        "outputId": "91deadb8-64f8-473c-ede2-b55f1624641f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 업로드 위젯\n",
        "from google.colab import files\n",
        "\n",
        "print(\"📁 오디오 파일을 업로드하세요:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일 이름 확인\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"업로드된 파일: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LWUYVCtQNv37",
        "outputId": "45f188e6-4d87-424b-8e22-545f824ecdc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 업로드된 오디오 파일로 테스트\n",
        "import librosa\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\n🎤 {filename} 음성 인식 중...\")\n",
        "\n",
        "    # 오디오 로드\n",
        "    audio, sr = librosa.load(filename, sr=16000)\n",
        "\n",
        "    # 음성 인식 실행\n",
        "    result = asr_pipeline(audio)\n",
        "\n",
        "    print(f\"🎯 인식 결과: {result['text']}\")\n",
        "    print(f\"📊 오디오 길이: {len(audio)/sr:.2f}초\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8onA5GZnOXPu",
        "outputId": "2724f208-4e77-4d12-cd53-dd6ff92c4107"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시: 모델 저장\n",
        "import torch\n",
        "\n",
        "# 모델 예시 (네가 만든 모델에 맞게 수정)\n",
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = torch.nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "tJnJq8SLogRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrok 설치\n",
        "!wget -q -c https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n"
      ],
      "metadata": {
        "id": "kXAsJ-ux0ZAv",
        "outputId": "9ece0492-a901-4b40-d6ea-f8f361e88eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 여기에 본인 ngrok 토큰을 붙여넣기\n",
        "!./ngrok authtoken '30r7kwynN4UGRHHLVTofTvKoTAz_7iYo1SyPdSzqSpS9DMZbg'\n"
      ],
      "metadata": {
        "id": "n7yD3u9j27vG",
        "outputId": "f535ec74-03d8-4f9c-a63f-dbc320493665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# 모델 정의\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# 모델 불러오기\n",
        "model = MyModel()\n",
        "model.load_state_dict(torch.load('model.pt', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Flask 앱 생성\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json['input']\n",
        "    input_tensor = torch.tensor([data], dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        prediction = model(input_tensor).item()\n",
        "    return jsonify({'prediction': prediction})\n",
        "\n",
        "# ngrok 실행 함수\n",
        "def start_ngrok():\n",
        "    from pyngrok import ngrok\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"🌐 Public URL: {public_url}\")\n",
        "    return public_url\n",
        "\n",
        "# Flask 앱 실행 함수\n",
        "def run_app():\n",
        "    app.run()\n",
        "\n",
        "# 서버 실행\n",
        "!pip install pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "threading.Thread(target=run_app).start()\n",
        "time.sleep(2)\n",
        "start_ngrok()\n"
      ],
      "metadata": {
        "id": "CrvoisKj3HIw",
        "outputId": "1d70be21-f6ea-4953-d50c-9e06f44745b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:5000\n"
      ],
      "metadata": {
        "id": "kkt6ZItuYKn7",
        "outputId": "8148f220-e67b-4ecc-c596-34677d85ff6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsof -t -i:5000 | xargs kill -9\n"
      ],
      "metadata": {
        "id": "fzjDghpqYZ9k",
        "outputId": "74eb5714-3216-4d4d-eb72-f484e3c7b39c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 5000"
      ],
      "metadata": {
        "id": "989DbG09YfIF",
        "outputId": "75334f4d-5a86-484b-b0da-f6a9f8b8d192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok\n"
      ],
      "metadata": {
        "id": "vbgPYOKeYwjj",
        "outputId": "e9418054-b4d0-4118-8b16-c07a5546832b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "_GMAEtRVY1Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 5000\n"
      ],
      "metadata": {
        "id": "l0JTBOtSY4jK",
        "outputId": "b158e5a0-dacb-4385-c5d7-fe327e87f113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 혹시 기존 ngrok 실행 중이면 종료\n",
        "!pkill -f ngrok\n",
        "\n",
        "# 2) ngrok를 백그라운드에서 실행\n",
        "get_ipython().system_raw('ngrok http 5000 &')\n",
        "\n",
        "# 3) ngrok 터널 정보 불러오기\n",
        "import requests\n",
        "import time\n",
        "\n",
        "time.sleep(2)  # ngrok가 켜질 시간 조금 기다리기\n",
        "tunnel_info = requests.get('http://localhost:4040/api/tunnels').json()\n",
        "public_url = tunnel_info['tunnels'][0]['public_url']\n",
        "print(\"🌐 Public URL:\", public_url)\n",
        "https://db3d8e570db5.ngrok-free.app/"
      ],
      "metadata": {
        "id": "vi19WjjIbStE",
        "outputId": "7806412f-6fc9-4fe9-aa9f-ea07ed76887d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors pyngrok\n"
      ],
      "metadata": {
        "id": "iS_YS56ciLnQ",
        "outputId": "7f0033e8-5402-42c1-aa2b-b55d7f55c2f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Flutter 연결 시 CORS 허용\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return jsonify({\"message\": \"서버 연결 성공!\"})\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    text = data.get(\"text\", \"\")\n",
        "    # 여기에 실제 모델 로직 넣으면 됨\n",
        "    return jsonify({\"result\": f\"'{text}'를 받았습니다.\"})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=5000)\n",
        "\n"
      ],
      "metadata": {
        "id": "wkUqzggxidpo",
        "outputId": "10c81710-6f91-4001-cd1e-2cf990fb4f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1o26pMZZ4ra",
        "outputId": "5ba0ad66-bb55-4cff-9a91-5af9303a45ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "6-ozEiTRbww3",
        "outputId": "9bad18c7-2709-4623-fcc7-b3aa4fa51408"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}