{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP_g2z7YB9QD",
        "outputId": "15d8c0c1-3565-4426-aae7-6cecc3160fd4"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBp5eQyiCZkU",
        "outputId": "6878621a-7614-49cf-847d-edaa07089238"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4a33aa7fe5ac4eeb8a0630c73d25c6cc",
            "d85adc18814e41569ff5538a626ea3ca",
            "80424380d5f84b67935d773305a330b1",
            "fad6c7773e8a4d7886d9d8fc3e1ee063",
            "231b78b9b9f44071aa54263169fba340",
            "1aedaae6bb044b1992d999062ad7652f",
            "3f7599d164a942a8a04c2d62893fb7c2",
            "5bc1e61ec6d74e3c83f1f23b52bd92b2",
            "dfb61e4479234bd385333b1921365a3b",
            "e089bae5a2a94ec9a6e77645c622e2f7",
            "329f74234c3c40eb94bbffb1ae1176a1",
            "f517d3a399b64b54b32a9b34a3a1f49c",
            "c0a90bfa20c7464484caa8bf5d00dfa0",
            "375c8b09151c4534978bc471b471a7fe",
            "9d362f15f3794277b6077e1e5f8f3dd5",
            "ed19ba0045f04fc69533cfa320c11b66",
            "bbe291d425694eb4b1fab0eb02e14eda",
            "8e8efe575a97442f931d199ae3964abb",
            "847e522d69e04d1da63452568b2b580d",
            "178618a2ba42487bb1b7c0762b2badae"
          ]
        },
        "id": "5W1SJQU2DIuA",
        "outputId": "fb425186-8126-432c-f4d8-023221dd4543"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrkip27DObs",
        "outputId": "c8da2b48-06de-4808-8859-33ed9724eb58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "7987bc84ce9340bf866b6fa441870dd7",
            "e7ea63f1cd3c4c34ac06103390c6c360",
            "11ea9665f0324511a52e93cd815c68bd",
            "f5e5d0b33b174e57ae17c77ca5b1fe0c",
            "79d5fe3dd01d4b22a21ca365a1fa1486",
            "50da05339c034073864ee718f9d4674d",
            "3766d05c205c4a2e8f43de62e7676ef3",
            "0500cc8b824442cc81c232f6445c414b",
            "a847e35b231d4c37a7809f2012ef8f1e",
            "dd0dacf1c2744851833a63508925cf35",
            "71b203ed8e66432a8bc18f9d4e033c0a"
          ]
        },
        "id": "E95lgvWsDOck",
        "outputId": "6692f936-d2f8-42ed-c627-4ea8b02eaaf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"Korean\", task=\"transcribe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "aa65eff317ad4076bd48694777f364f1",
            "c3395d1c5c23457fa1a98e292516a4ad",
            "727c694444274ac3aea92c5966f0deba",
            "9936b5d00c0a4e069e0d18ed3f8ffd17",
            "2c9630f962e041678d1e709b28311e8d",
            "72f07d4c42a947f1a9d24c15ee861a0e",
            "83e1f7b7fcd24085b8082d7d7508cd3c",
            "697f1e4d443141a2bfa78107da772649",
            "4efef97627d14b2b93df4a6814993fc5",
            "47e3c6083fa147359ddde496e7e5029e",
            "f40c25a06a73451cb8ea99d00089cea3",
            "cabb4afe3b994a2fa05805f929ac0c15",
            "1f98290d1e8a4f2d84e8c51aff85d73c",
            "a5b91ff6e2754527ba5cda3a8dc02e1c",
            "32143ff314654002a9b56bcbfcc35acd",
            "af69c75f8d7c49efb0a5e10724a9bf56",
            "c558da99a8614f93b1a8c34e61d2d6aa",
            "0f1fe81632b4498485c5e03512c3ebc4",
            "0b31c9f753a545588719bdd72c40f1d9",
            "a486c42c36f04f61a32d3970642acb6d",
            "490d4dea508e4ec983acf7e8e3d5b81e",
            "52eb76f9662143bbbdbc813a455261f5",
            "e1cec5a195cb4cd59076fc04083eb65a",
            "cb86c31550b94efeb5d60afc4b23aebb",
            "b39a1e61a34c4d7c8bb59481d9b22413",
            "074c7a1f5bdb4ad0a20f977602b791b7",
            "65e2d1b1772a48f0a947e0c6b83577a4",
            "4a5d50c36f2c4191a797842a3f4c8d2e",
            "fa139de97f09442fa6aba9bc98230ef4",
            "3881085ea76f426cab0c419e2be98468",
            "b990bd60e87440788167bf917a570126",
            "d5da70c4c70741038334db94a86893a2",
            "d890e858b83e43d4a281af3fc148f5f5",
            "f70cca9b846a403b91f258061cf273e9",
            "7b2c461c7834437ab1dc5f84c9e430b4",
            "4960ad1e6a034a339137e43c94a108c9",
            "cb5a80d2331a4d749fc8b00e2b0c3523",
            "5b4159be78ec4578a8d93900bd541e98",
            "838b6be594b947a6be822ec011ec12b7",
            "ae208968cd7448698bb95be945f7ad80",
            "abddd1b8d1dd4dbeb28e7651415c4fd7",
            "df2b4d735bf9432b9c6dc8bfff3ae8ac",
            "392a1ed133734395a3e2f6c96c780bdd",
            "03e6c0b65eab47cf8d10b1799104eecb",
            "48d0696cb57b4fce8172357af922ea0f",
            "0a59d6387d264de184805a35b828c01e",
            "036d57ccacb24e10a964e2ce345e6e41",
            "7743134a8daf4e0bb779ff9d0bc32108",
            "682e7e1128d64a3e858e3be39229c1d1",
            "e6698247e5454d759d203456e2b41a74",
            "1eeb8a87e42b44f189e9775abb4761c6",
            "6690d661561a48f8a494384fbde8ab79",
            "a261feb818774af188088aad121ef90d",
            "70ea70f69e59456aa4fe4ade1b98359e",
            "da24e16ad9614925b98cbaf64955c8cf",
            "e3ce15c12bb24176bdba6f431c3bc898",
            "9a404ee084ec4658ac8aae128a1f02cb",
            "c8a690949fee4ec0bb55ba479b7ff0e6",
            "cf725fda328b4554a4adeaaeaa0c9435",
            "ebce757f2f044c859409dce6af8d41b4",
            "8ad06e6a3d1742bda0dc7982e6405905",
            "7a111520cbfb4eb9b80b2dc05c9e8ece",
            "1a1b28a1b5ac4f6bbe22cb59e7d5ba8b",
            "f712629414474c07ad6a6f5268197d31",
            "d4121f5be81b4d7b84e3133035781936",
            "47c32114b8b14ecc82d1e158bdcdc798",
            "23bb6d0d9c454f86a82ada72d71a624d",
            "26269489d76a4621aff7e65d0a1b9ff1",
            "8fb4fc18640b4feab6a6b18dbad17bec",
            "9ff1a756ac05402195b92facd5b84eee",
            "ebe847996160438494215d85df8bc88c",
            "6307005bedac423abb0040698db9ef27",
            "83f13a33d1234359af3fa16a291cf371",
            "3c908183c7c445099c6c25364e0f3fcd",
            "d84788e7f5574659b06ce5ca349ccd63",
            "589ed62f1a2b4ca09b1c5b11b07bce55",
            "9cdda5e1de9643ecb15d59c9aa1e2f6b"
          ]
        },
        "id": "QMgP7XPaDfjb",
        "outputId": "0723107b-bd5e-47ee-fbe7-4028774bdaad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"Korean\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "Knuj0ERsDino"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì·¨í•©\n",
        "import glob\n",
        "\n",
        "path = \"/content/drive/MyDrive/speech_project/Impediment_dataset/*.wav\"\n",
        "raw_data_list = glob.glob(path)"
      ],
      "metadata": {
        "id": "6C2PjD-KDlMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"file_list : {raw_data_list[:10]}\")\n",
        "print(len(raw_data_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CePIcm9JDm1a",
        "outputId": "e5493a93-8c5e-495d-99eb-387cd3c29fff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import natsort\n",
        "\n",
        "# 2. í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ì·¨í•©\n",
        "path = \"/content/drive/MyDrive/speech_project/Impediment_dataset/*.txt\"\n",
        "labeled_data_list = glob.glob(path)\n",
        "# ìˆ«ìê°€ ë“¤ì–´ìˆëŠ” íŒŒì¼ëª…ì„ ì •í™•í•˜ê²Œ sorting í•´ì¤€ë‹¤\n",
        "labeled_data_list = natsort.natsorted(labeled_data_list,reverse=False)"
      ],
      "metadata": {
        "id": "ZSMdhEGHDuhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"file_list : {labeled_data_list[:10]}\")\n",
        "print(len(labeled_data_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDVOwZOqDx9M",
        "outputId": "64226166-f970-4bcd-9995-509e689ef580"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "transcript_list = []\n",
        "for labeled_data in tqdm(labeled_data_list):\n",
        "    with open(labeled_data, 'r', encoding='UTF8') as f:\n",
        "        line = f.readline()\n",
        "        transcript_list.append(line)\n",
        "\n",
        "df = pd.DataFrame(data=transcript_list, columns = [\"transcript\"])\n",
        "\n",
        "df[\"raw_data\"] = raw_data_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkIQF4zODz43",
        "outputId": "fe2ee20e-faed-452c-a203-7ed4fd64b418"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().values.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY-1ayrNEIIP",
        "outputId": "b6a38049-a67c-4203-bc80-17d344b795c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "laxTuUvWELUl",
        "outputId": "6a46523f-65c4-4b17-a1c4-c7f83c25d503"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import Audio\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "ZtgYI0K4EOVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = Dataset.from_dict({\"audio\": [path for path in df[\"raw_data\"]],\n",
        "                       \"transcripts\": [transcript for transcript in df[\"transcript\"]]}).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "train_testvalid = ds.train_test_split(test_size=0.1)\n",
        "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
        "datasets = DatasetDict({\n",
        "    \"train\": train_testvalid[\"train\"],\n",
        "    \"test\": test_valid[\"test\"],\n",
        "    \"valid\": test_valid[\"train\"]})\n",
        "\n",
        "datasets.push_to_hub(\"coorinkie/speechproject_audio_data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "44c6f7c4886249a6899c861ccf684341",
            "9bcc20ccfcc1447a94745f80547353d6",
            "a0c30c4e911144ae9c73227d577b7949",
            "986b9c698f134d2c8ec3da6c2a7402ce",
            "f9a3346326f949369a5e2954cd49eaa4",
            "bcaae1a31f4a4cd8980876202da36248",
            "166951bdede0411eae71cfb4670c2a75",
            "0d598b5da7774cf6b804ac4d2ec7708d",
            "405fc55a1e8b4e95b1c9f1588b12e936",
            "4e960aa01b164e4480e131141df92597",
            "1110a72a3d6c419f97ba6469b15b88c5",
            "b4eff4dc93ee4d5f898e041ebc97a265",
            "0fdc286e602049a8b1894b76fad51b0e",
            "7dfe8e3a70d94587b165e01190795fc5",
            "0e6785f6baad431c8757b0f3568a2af2",
            "7b183cbd1e84431b8868b5f4e257874a",
            "468f1419b34b47b2964f6cb37abe6782",
            "d83836f91d09499db768106d450e4938",
            "ec246df7bcdc4f1fbc89cfec2fb92ba1",
            "e6d0fb4ed2bf4363b554d4ce12a5f4eb",
            "e48b61e4e79a4ed2a43ef9e0aa62bbe5",
            "ac339ccc5ef34b5983c082e6620e3126",
            "2a6528b05e424ec29692a0a8461fed2c",
            "33d871e0e8cb48668c11e97551756902",
            "4dbaa33e6a554139bb1ff383cf2a5827",
            "9e420d4dbefc4161a0500600f7693418",
            "408f18addfb14455abdd0a2367534484",
            "c64d4722975a4adea8e4adaa4cd5292a",
            "656e331eba654e30be3d8ee549ed9078",
            "ba638766d55446ce961dd9fe19b5b470",
            "783d1c03cc7149d98f6e215717d683bb",
            "04c35f4f289f48d2aba3e40ea1d56673",
            "60c1811a437f40949724922e7be05c47",
            "67368ef4ff414351868938f6bd9b42c7",
            "637734418f714e209c03640e7da334bc",
            "5683dd5c45eb4b7f944df14e7bf8fda3",
            "9503a89582914bfa924a17d514ef0e2b",
            "9de3abed10124298a5fb031cc9026a4f",
            "b4c3f8a4eea9429ea570665ab4e3d2fb",
            "64130e4a1ed442c9811d75557f0fe93b",
            "46e2a3a5cdf14587a66b371df0cb8115",
            "3781306289cb4574a2eaf993731aa8c5",
            "9cec2ab342074f8da8fcf04d57d51a1e",
            "dc7dc684d7b7402482127c164104b048",
            "39d1cea83e314949bf0596aa3d712b20",
            "5e31525880344712877e27371f0028fc",
            "50fa72826ba142b9b1b7f23478061316",
            "e068730a345f47b1a3afe53704979940",
            "3e833860eb044e0ca1b99941507ec43a",
            "6db6f37e39b54ea1883747bcd04f0e3d",
            "743e77daf35141acb0f4d6635f459cff",
            "556f620b3a354d35b3bad708cced9ea4",
            "e8e1328a7c484ccc8ddf05f4c5649928",
            "c04a74372f0543a9b8f343c3dd28f132",
            "86e886de4ab54a569a707ef14b221507",
            "adcef11c970a47d7a2ad4a4ee081454c",
            "48bf501c7a1447618dce9558a8d4884f",
            "df6a2600f8f14dd98ce67702587747fa",
            "e794b5e5d0ed4e77b844a9dce68e1645",
            "2049acf0e5784c368623b8dcc55e83da",
            "c544461a900843cabc28dbe5056b9800",
            "d8caadf570854745a86f074b0d1ab93a",
            "f5707df94fc944f3a49eb039d5c2e06d",
            "07ab1d6822f74fa3a4620c790b31c558",
            "d327c8a7ca174e2db9bbc0252637aa55",
            "63b6a59f838a4867bc78ea19737f4896",
            "488e362153324f13bbcd303619949647",
            "745a455922024c2d94b64f1c9dd31e97",
            "996ef9a40cbc4755a2a175ad7c7fedec",
            "4c548f47b6a5433eb2c3ee3e7d2427bc",
            "c8128bcd7ad24dc586df3040a315111a",
            "9e14f172c92a4321919519a2ab1dd926",
            "61725d991bf7460c876538143b0816b0",
            "774fa2aeecc04465b48fdb659fa3abc0",
            "87c3e91dbcec418ea60a8bfb2fa81970",
            "e50be5fe0f9d403ab37288e81cf797e0",
            "d8475a4aadbc4afdad50364603299a10",
            "6e46df396cf34fecb079e4c48fab0283",
            "13f3bc26725b4509bad15d89aa95df2b",
            "04689bf2ad76439abc61dfb9bf4b090a",
            "acfc9bda1f914c06a9e265fa1c439698",
            "7a462c9f0f53479b9483b93905f2b8e1",
            "c3776089cb7840f79c14cc9b8d0c87a5",
            "f15bcee4321d47ae951b5456e8734ff1",
            "a43e96c5c8ab4e9881cda2f991c36a9b",
            "577d6a11ce3a4b87b200569b732c7fd4",
            "3ed7aa6e7c974b0196d1c7125e026b53",
            "4e0429742a844baf87b25014869bd6eb",
            "4f426139b1004899a4e31fcb7094cfd5",
            "1d3a4da64df942e4be4eb8777f79100f",
            "9ec160080c014508a612486771ac274e",
            "329b8c4689b74075aacd1c15bd7e68df",
            "476eb29527304ebaaf6e700fef340d77",
            "577dab3a0383409d9183d1e649b6a0de",
            "e3441ada415d47eea06baa9d380d6c71",
            "b94933a1ca8e4a4eba0fa0106c8f1e57",
            "235080ebc0e7434abf71aa624d30af56",
            "cf8f6219d586431da73b6bc59b26c8da",
            "3420350604964b419fd45dc8bff939b2",
            "dc8a04dc94614b6499d30c697b54079b",
            "c8051d45a27f43fca8ab1025b389a7ba",
            "e2d8262bd7ea4c16b1fdc95dd4acaee8",
            "3b412ec3d4b04d8bbf8a4694c2a2c6b6",
            "fffd67645f114cd6a277bb075209cb43",
            "d2804e4cfd9b445898e30edb02e54624",
            "6588c4fc410c4b42bcdc483e12e3b131",
            "cc0c9811b38c4b6f967beaf84fed49f6",
            "342e51ace63447e985988c6b8157e4aa",
            "c1dc6c1def8c47eb9e4a32855b0e8567",
            "169e1628d9f34badb0672284d1e8d981",
            "32b727cde5e34a1685bb05c162887b87",
            "3f7907712c584e2b8785c7a778d2839a",
            "6b122fdb80a44144981f5c243ceef61c",
            "c4e9155bcf8449f6bf96453fd14fed95",
            "e3f7bf1b72ad4f8488268f3b40303a1f",
            "58f8fc3cabba49b58e964a36119a5801",
            "c421c836e0484ad99d31ee7c17678734",
            "cbdc2461c3e84ca4bf0342d0b6cb4047",
            "ad17e1fe7d054da7b3486cd7165241cd",
            "308da9737f9f4fa9b61237984d859408",
            "6861914c35024e1d8412c9fa26d99413",
            "9352f6734b944208942ece7b682fc010",
            "ac9057fdc8f24b4299156a1abb2f6573",
            "f0b89549bf0f475c9bd07958acd14f13",
            "8f25b74caca6474ebe7fc8dbe7ac58d7",
            "3e16e21aa4b949e7a29daae4e705bc97",
            "28cfb8a253d141b9b311764b40d84d3e",
            "7a9a74829d624b988cdb4ceb572c1c90",
            "0dc6e4ed373848ad89f9147445b7346b",
            "175d17ae7a7f4d379287db702ac6d6ef",
            "cee13f0ed93c4bbcb8edc2ae0f77f854",
            "787fc0ab20ce473397e259e726ea50e9",
            "e9040d38a1eb4440ae0750bd1463fcd5",
            "bb17f31bff7c4640840e0e009b5574ac",
            "34df0a4120a84d13b598d8b8f95e1fbf",
            "25cdcec4a8284047b92e8b9a22c25c64",
            "faf709c4984347a2988baf50c395f55a",
            "d62ce8ee5be34c6bb2205dc5452ed4b6",
            "e900ea60171b46d087ca977d16d960b4",
            "188ab5ecbb5f43e99c21d06ab9cd73c8",
            "c34fa695d5c24a0894def0623169e919",
            "66a0e8bf8928431ca1e63bd3c62e0b11",
            "c1754f8b0be746a4b1b2db7dd68e9a01"
          ]
        },
        "id": "w7gwuFUbES2A",
        "outputId": "0c7b65ff-a594-4325-d12d-4690cd084905"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import natsort\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive ë§ˆìš´íŠ¸\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Driveê°€ ë§ˆìš´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "except:\n",
        "    print(\"Google Driveê°€ ì´ë¯¸ ë§ˆìš´íŠ¸ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸ ê¸°ëŠ¥\n",
        "def check_directory_contents(base_dir):\n",
        "    \"\"\"ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ í™•ì¸\"\"\"\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(f\"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_dir}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"\\n{base_dir} ë””ë ‰í† ë¦¬ ë‚´ìš©:\")\n",
        "    for item in os.listdir(base_dir):\n",
        "        item_path = os.path.join(base_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\" - ğŸ“ {item}\")\n",
        "        else:\n",
        "            print(f\" - ğŸ“„ {item}\")\n",
        "    return True\n",
        "\n",
        "# ìƒìœ„ ë””ë ‰í† ë¦¬ í™•ì¸\n",
        "my_drive_dir = \"/content/drive/MyDrive\"\n",
        "print(\"MyDrive ë””ë ‰í† ë¦¬ í™•ì¸ ì¤‘...\")\n",
        "check_directory_contents(my_drive_dir)\n",
        "\n",
        "# ì‚¬ìš©ì ì…ë ¥ ëŒ€ì‹  íŒŒì¼ì„ ì°¾ê¸° ìœ„í•œ ë¡œì§\n",
        "print(\"\\nê°€ëŠ¥í•œ ìŒì„± ë°ì´í„° í´ë” íƒìƒ‰ ì¤‘...\")\n",
        "possible_dirs = []\n",
        "for root, dirs, files in os.walk(my_drive_dir):\n",
        "    # ë„ˆë¬´ ê¹Šì€ íƒìƒ‰ ë°©ì§€\n",
        "    if root.count(os.sep) - my_drive_dir.count(os.sep) > 2:\n",
        "        continue\n",
        "\n",
        "    # ì˜¤ë””ì˜¤ íŒŒì¼ì´ë‚˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ í¬í•¨í•˜ëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì°¾ìŒ\n",
        "    wav_files = [f for f in files if f.endswith('.wav')]\n",
        "    txt_files = [f for f in files if f.endswith('.txt')]\n",
        "\n",
        "    if wav_files:\n",
        "        print(f\"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” í´ë” ë°œê²¬: {root} ({len(wav_files)}ê°œ .wav íŒŒì¼)\")\n",
        "        possible_dirs.append((root, 'audio', len(wav_files)))\n",
        "\n",
        "    if txt_files:\n",
        "        print(f\"í…ìŠ¤íŠ¸ íŒŒì¼ì´ ìˆëŠ” í´ë” ë°œê²¬: {root} ({len(txt_files)}ê°œ .txt íŒŒì¼)\")\n",
        "        possible_dirs.append((root, 'text', len(txt_files)))\n",
        "\n",
        "# ë°œê²¬ëœ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ê²½ë¡œë¥¼ ë¬¼ì–´ë´„\n",
        "if not possible_dirs:\n",
        "    print(\"ìë™ìœ¼ë¡œ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"ë‹¤ìŒ ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì‹¤ì œ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”:\")\n",
        "    print(\"text_dir = 'í…ìŠ¤íŠ¸ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ'\")\n",
        "    print(\"audio_dir = 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ'\")\n",
        "\n",
        "    # ì˜ˆì‹œ ê²½ë¡œ (ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•¨)\n",
        "    text_dir = \"/content/drive/MyDrive/speech_project/Impediment_dataset\"\n",
        "    audio_dir = \"/content/drive/MyDrive/speech_project/audio_data\"\n",
        "else:\n",
        "    # ë°œê²¬ëœ ë””ë ‰í† ë¦¬ ì¤‘ì—ì„œ ì„ íƒ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•  ìˆ˜ ìˆìŒ)\n",
        "    text_dirs = [d for d in possible_dirs if d[1] == 'text']\n",
        "    audio_dirs = [d for d in possible_dirs if d[1] == 'audio']\n",
        "\n",
        "    if text_dirs and audio_dirs:\n",
        "        # ê°€ì¥ ë§ì€ íŒŒì¼ì„ ê°€ì§„ ë””ë ‰í† ë¦¬ ì„ íƒ\n",
        "        text_dir = max(text_dirs, key=lambda x: x[2])[0]\n",
        "        audio_dir = max(audio_dirs, key=lambda x: x[2])[0]\n",
        "        print(f\"\\nìë™ìœ¼ë¡œ ì„ íƒëœ í…ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: {text_dir}\")\n",
        "        print(f\"ìë™ìœ¼ë¡œ ì„ íƒëœ ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬: {audio_dir}\")\n",
        "    else:\n",
        "        print(\"í…ìŠ¤íŠ¸ ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê°€ì§„ ë””ë ‰í† ë¦¬ë¥¼ ì¶©ë¶„íˆ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "        # ì˜ˆì‹œ ê²½ë¡œ (ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•¨)\n",
        "        text_dir = \"/content/drive/MyDrive/speech_project/Impediment_dataset\"\n",
        "        audio_dir = \"/content/drive/MyDrive/speech_project/audio_data\"\n",
        "        print(f\"\\nê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: \\ní…ìŠ¤íŠ¸: {text_dir}\\nì˜¤ë””ì˜¤: {audio_dir}\")\n",
        "        print(\"ì´ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ ì•Šë‹¤ë©´ ìˆ˜ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "\n",
        "# ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸\n",
        "print(\"\\nì„ íƒëœ ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸:\")\n",
        "check_directory_contents(text_dir)\n",
        "check_directory_contents(audio_dir)\n",
        "\n",
        "# íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
        "text_files = glob.glob(os.path.join(text_dir, \"*.txt\"))\n",
        "audio_files = glob.glob(os.path.join(audio_dir, \"*.wav\"))\n",
        "\n",
        "print(f\"\\ní…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(text_files)}\")\n",
        "print(f\"ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜: {len(audio_files)}\")\n",
        "\n",
        "# íŒŒì¼ì´ ì¶©ë¶„íˆ ìˆëŠ”ì§€ í™•ì¸\n",
        "if len(text_files) < 10 or len(audio_files) < 10:\n",
        "    print(\"ê²½ê³ : íŒŒì¼ ìˆ˜ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤. ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "    if len(text_files) < 10:\n",
        "        print(f\"ë°œê²¬ëœ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼: {text_files}\")\n",
        "    if len(audio_files) < 10:\n",
        "        print(f\"ë°œê²¬ëœ ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼: {audio_files}\")\n",
        "\n",
        "    raise ValueError(\"íŒŒì¼ì„ ì¶©ë¶„íˆ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ê²½ë¡œì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "# íŒŒì¼ ì •ë ¬\n",
        "text_files = natsort.natsorted(text_files)\n",
        "audio_files = natsort.natsorted(audio_files)\n",
        "\n",
        "# í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ\n",
        "print(\"\\ní…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì¤‘...\")\n",
        "transcripts = []\n",
        "for txt_file in tqdm(text_files):\n",
        "    try:\n",
        "        with open(txt_file, 'r', encoding='UTF8') as f:\n",
        "            line = f.readline().strip()\n",
        "            transcripts.append(line)\n",
        "    except Exception as e:\n",
        "        print(f\"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({txt_file}): {e}\")\n",
        "\n",
        "print(f\"ë¡œë“œëœ í…ìŠ¤íŠ¸ ìˆ˜: {len(transcripts)}\")\n",
        "\n",
        "# íŒŒì¼ ê²½ë¡œì™€ í…ìŠ¤íŠ¸ ëª©ë¡ì˜ ê¸¸ì´ ë§ì¶”ê¸°\n",
        "min_len = min(len(transcripts), len(audio_files))\n",
        "print(f\"ì‚¬ìš©í•  ë°ì´í„° ìˆ˜: {min_len}\")\n",
        "\n",
        "transcripts = transcripts[:min_len]\n",
        "audio_files = audio_files[:min_len]\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
        "print(\"\\në°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘...\")\n",
        "# ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¡œ ë°ì´í„°í”„ë ˆì„ ìƒì„±í•˜ì—¬ ê¸¸ì´ ë¶ˆì¼ì¹˜ ë¬¸ì œ ë°©ì§€\n",
        "data = {'transcript': transcripts, 'raw_data': audio_files}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(f\"ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ! í¬ê¸°: {len(df)}\")\n",
        "print(f\"ë°ì´í„°í”„ë ˆì„ ì²˜ìŒ 5í–‰:\\n{df.head()}\")\n",
        "\n",
        "# ë°ì´í„°ì…‹ ìƒì„±\n",
        "if len(df) > 0:\n",
        "    from datasets import Dataset, DatasetDict\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    print(\"\\në°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
        "\n",
        "    # ë°ì´í„° ë¶„í•  ì „ ì—´ ì´ë¦„ ë³€ê²½\n",
        "    df_renamed = df.rename(columns={'raw_data': 'audio', 'transcript': 'transcripts'})\n",
        "\n",
        "    # ë°ì´í„° ë¶„í• \n",
        "    train_df, temp_df = train_test_split(df_renamed, test_size=0.2, random_state=42)\n",
        "    test_df, val_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "    # ë¶„í• ëœ ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸\n",
        "    print(f\"í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_df)}\")\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í¬ê¸°: {len(test_df)}\")\n",
        "    print(f\"ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°: {len(val_df)}\")\n",
        "\n",
        "    # ë°ì´í„°í”„ë ˆì„ì„ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    test_dataset = Dataset.from_pandas(test_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ì‚¬ì „ ìƒì„±\n",
        "    dataset = DatasetDict({\n",
        "        'train': train_dataset,\n",
        "        'test': test_dataset,\n",
        "        'validation': val_dataset\n",
        "    })\n",
        "\n",
        "    print(\"\\në°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:\")\n",
        "    print(dataset)\n",
        "else:\n",
        "    print(\"ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆì–´ ë°ì´í„°ì…‹ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf3ByoMpEcLJ",
        "outputId": "49666cf9-469e-4298-f3ca-7c3bc8e33724"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í—ˆê¹…í˜ì´ìŠ¤ í† í° ì…ë ¥ ìš”ì²­\n",
        "print(\"í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ 'coorinkie/speechproject_audio_data'ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ì„œëŠ” ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "print(\"1. https://huggingface.co/settings/tokens ì—ì„œ í† í°ì„ ìƒì„±í•˜ì„¸ìš” (READ ê¶Œí•œ í•„ìš”)\")\n",
        "print(\"2. ìƒì„±ëœ í† í°ì„ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”\")\n",
        "\n",
        "# í† í° ì…ë ¥ ë°›ê¸°\n",
        "token = input(\"í—ˆê¹…í˜ì´ìŠ¤ í† í°ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "\n",
        "# í† í° ì„¤ì •\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = token\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (torchtuneì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ì„¤ì¹˜)\n",
        "print(\"\\ní•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\")\n",
        "!pip install -q huggingface_hub[cli] --upgrade\n",
        "!pip install -q datasets --upgrade\n",
        "\n",
        "# ìºì‹œ ì„¤ì •\n",
        "import os\n",
        "os.environ[\"HF_HOME\"] = \"/content/hf_home\"\n",
        "os.environ[\"HF_DATASETS_CACHE\"] = \"/content/hf_home/datasets\"\n",
        "\n",
        "# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(\"/content/hf_home\", exist_ok=True)\n",
        "os.makedirs(\"/content/hf_home/datasets\", exist_ok=True)\n",
        "\n",
        "# í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸\n",
        "from huggingface_hub import login\n",
        "try:\n",
        "    login(token=token)\n",
        "    print(\"í—ˆê¹…í˜ì´ìŠ¤ì— ë¡œê·¸ì¸ ì„±ê³µ!\")\n",
        "except Exception as e:\n",
        "    print(f\"í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ë¡œê·¸ì¸ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë¡œë“œ ì‹œë„ (ì„¸ ê°€ì§€ ë°©ë²•)\n",
        "print(\"\\ní—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ ë¡œë“œ ì‹œë„ ì¤‘...\")\n",
        "\n",
        "# ë°©ë²• 1: ì¸ì¦ì„ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ë¡œë“œ ì‹œë„\n",
        "try:\n",
        "    print(\"ë°©ë²• 1: ì¸ì¦ì„ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ë¡œë“œ ì‹œë„ ì¤‘...\")\n",
        "\n",
        "    # ë‹¤ì–‘í•œ ì˜µì…˜ ì‹œë„\n",
        "    try:\n",
        "        dataset = load_dataset(\"coorinkie/speechproject_audio_data\", use_auth_token=token)\n",
        "    except Exception as e1:\n",
        "        print(f\"ì²« ë²ˆì§¸ ì˜µì…˜ ì‹¤íŒ¨: {e1}\")\n",
        "        try:\n",
        "            dataset = load_dataset(\"coorinkie/speechproject_audio_data\", token=token)\n",
        "        except Exception as e2:\n",
        "            print(f\"ë‘ ë²ˆì§¸ ì˜µì…˜ ì‹¤íŒ¨: {e2}\")\n",
        "            # ì„¸ ë²ˆì§¸ ë°©ë²•\n",
        "            dataset = load_dataset(\"coorinkie/speechproject_audio_data\",\n",
        "                                   cache_dir=\"/content/hf_home/datasets\",\n",
        "                                   token=token,\n",
        "                                   download_mode=\"force_redownload\")\n",
        "\n",
        "    print(\"ë°©ë²• 1 ì„±ê³µ! ë°ì´í„°ì…‹ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(dataset)\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ìƒ˜í”Œ í™•ì¸\n",
        "    for split in dataset:\n",
        "        print(f\"\\n{split} ìƒ˜í”Œ:\")\n",
        "        print(dataset[split][0])\n",
        "\n",
        "    print(\"\\në°©ë²• 1 ë¡œë“œ ì„±ê³µ!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ë°©ë²• 1 ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "    # ë°©ë²• 2: íŒŒì¼ ë‹¤ìš´ë¡œë“œ í†µí•©\n",
        "    try:\n",
        "        print(\"\\në°©ë²• 2: ì§ì ‘ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° í†µí•© ë¡œë“œ ì‹œë„ ì¤‘...\")\n",
        "\n",
        "        import tempfile\n",
        "        import glob\n",
        "        from huggingface_hub import hf_hub_download, list_repo_files\n",
        "        import pandas as pd\n",
        "        import pyarrow.parquet as pq\n",
        "\n",
        "        # ë°ì´í„°ì…‹ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
        "        files = list_repo_files(\"coorinkie/speechproject_audio_data\", repo_type=\"dataset\", token=token)\n",
        "        print(f\"ë°ì´í„°ì…‹ íŒŒì¼ ëª©ë¡: {files}\")\n",
        "\n",
        "        # parquet íŒŒì¼ ì°¾ê¸°\n",
        "        parquet_files = [f for f in files if f.endswith('.parquet')]\n",
        "        print(f\"Parquet íŒŒì¼: {parquet_files}\")\n",
        "\n",
        "        if not parquet_files:\n",
        "            raise ValueError(\"Parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        # ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        download_dir = tempfile.mkdtemp()\n",
        "        print(f\"ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬: {download_dir}\")\n",
        "\n",
        "        # ë°ì´í„° ë¡œë“œ\n",
        "        data_dict = {}\n",
        "        for file in parquet_files:\n",
        "            try:\n",
        "                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "                local_file = hf_hub_download(\n",
        "                    repo_id=\"coorinkie/speechproject_audio_data\",\n",
        "                    filename=file,\n",
        "                    repo_type=\"dataset\",\n",
        "                    token=token,\n",
        "                    local_dir=download_dir\n",
        "                )\n",
        "                print(f\"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file} -> {local_file}\")\n",
        "\n",
        "                # ë¶„í•  ì´ë¦„ ì¶”ì¶œ (train/test/valid)\n",
        "                if \"train\" in file:\n",
        "                    split = \"train\"\n",
        "                elif \"test\" in file:\n",
        "                    split = \"test\"\n",
        "                elif \"valid\" in file:\n",
        "                    split = \"validation\"\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                # parquet íŒŒì¼ ë¡œë“œ\n",
        "                df = pq.read_table(local_file).to_pandas()\n",
        "                print(f\"{split} ë°ì´í„° ë¡œë“œ: {len(df)} í–‰, ì—´: {list(df.columns)}\")\n",
        "\n",
        "                # ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜\n",
        "                data_dict[split] = Dataset.from_pandas(df)\n",
        "\n",
        "            except Exception as inner_e:\n",
        "                print(f\"íŒŒì¼ {file} ë¡œë“œ ì‹¤íŒ¨: {inner_e}\")\n",
        "\n",
        "        # ë°ì´í„°ì…‹ ì‚¬ì „ ìƒì„±\n",
        "        if data_dict:\n",
        "            dataset = DatasetDict(data_dict)\n",
        "            print(\"\\në°©ë²• 2 ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ!\")\n",
        "            print(dataset)\n",
        "\n",
        "            # ë°ì´í„°ì…‹ ìƒ˜í”Œ í™•ì¸\n",
        "            for split in dataset:\n",
        "                print(f\"\\n{split} ìƒ˜í”Œ:\")\n",
        "                print(dataset[split][0])\n",
        "\n",
        "            print(\"\\në°©ë²• 2 ìµœì¢… ì„±ê³µ! í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
        "        else:\n",
        "            raise ValueError(\"ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨\")\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"\\në°©ë²• 2 ì‹¤íŒ¨: {e2}\")\n",
        "\n",
        "        # ë°©ë²• 3: huggingface-cli ì‚¬ìš© ì‹œë„\n",
        "        try:\n",
        "            print(\"\\në°©ë²• 3: huggingface-cli ì‚¬ìš© ì‹œë„ ì¤‘...\")\n",
        "\n",
        "            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "            import tempfile\n",
        "            temp_dir = tempfile.mkdtemp()\n",
        "            print(f\"ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±: {temp_dir}\")\n",
        "\n",
        "            # CLIë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "            !huggingface-cli download coorinkie/speechproject_audio_data --repo-type=dataset --local-dir={temp_dir} --token={token}\n",
        "\n",
        "            # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í™•ì¸\n",
        "            print(\"\\në‹¤ìš´ë¡œë“œëœ íŒŒì¼:\")\n",
        "            !find {temp_dir} -type f | sort\n",
        "\n",
        "            # parquet íŒŒì¼ ì°¾ê¸°\n",
        "            parquet_files = glob.glob(f\"{temp_dir}/**/*.parquet\", recursive=True)\n",
        "\n",
        "            if parquet_files:\n",
        "                print(f\"\\nParquet íŒŒì¼ ë°œê²¬: {len(parquet_files)}ê°œ\")\n",
        "\n",
        "                # ê° ë¶„í• ì— ëŒ€í•œ íŒŒì¼ ê·¸ë£¹í™”\n",
        "                train_files = [f for f in parquet_files if \"train\" in f]\n",
        "                test_files = [f for f in parquet_files if \"test\" in f]\n",
        "                valid_files = [f for f in parquet_files if \"valid\" in f]\n",
        "\n",
        "                print(f\"í›ˆë ¨ íŒŒì¼: {len(train_files)}ê°œ\")\n",
        "                print(f\"í…ŒìŠ¤íŠ¸ íŒŒì¼: {len(test_files)}ê°œ\")\n",
        "                print(f\"ê²€ì¦ íŒŒì¼: {len(valid_files)}ê°œ\")\n",
        "\n",
        "                # ë°ì´í„° íŒŒì¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
        "                data_files = {}\n",
        "                if train_files: data_files[\"train\"] = train_files\n",
        "                if test_files: data_files[\"test\"] = test_files\n",
        "                if valid_files: data_files[\"validation\"] = valid_files\n",
        "\n",
        "                # ë°ì´í„° ë¡œë“œ\n",
        "                data_dict = {}\n",
        "                for split, files_list in data_files.items():\n",
        "                    for file in files_list:\n",
        "                        try:\n",
        "                            # parquet íŒŒì¼ ë¡œë“œ\n",
        "                            df = pq.read_table(file).to_pandas()\n",
        "                            print(f\"{split} ë°ì´í„° ë¡œë“œ: {len(df)} í–‰, ì—´: {list(df.columns)}\")\n",
        "\n",
        "                            # ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜\n",
        "                            data_dict[split] = Dataset.from_pandas(df)\n",
        "                        except Exception as err:\n",
        "                            print(f\"íŒŒì¼ {file} ë¡œë“œ ì‹¤íŒ¨: {err}\")\n",
        "\n",
        "                # ë°ì´í„°ì…‹ ì‚¬ì „ ìƒì„±\n",
        "                if data_dict:\n",
        "                    dataset = DatasetDict(data_dict)\n",
        "                    print(\"\\në°©ë²• 3 ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ!\")\n",
        "                    print(dataset)\n",
        "\n",
        "                    # ë°ì´í„°ì…‹ ìƒ˜í”Œ í™•ì¸\n",
        "                    for split in dataset:\n",
        "                        print(f\"\\n{split} ìƒ˜í”Œ:\")\n",
        "                        print(dataset[split][0])\n",
        "\n",
        "                    print(\"\\në°©ë²• 3 ìµœì¢… ì„±ê³µ! í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
        "                else:\n",
        "                    raise ValueError(\"ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            else:\n",
        "                raise ValueError(\"ë‹¤ìš´ë¡œë“œëœ í´ë”ì—ì„œ Parquet íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        except Exception as final_e:\n",
        "            print(f\"\\nëª¨ë“  ì‹œë„ ì‹¤íŒ¨: {final_e}\")\n",
        "            print(\"\\n========== ì¤‘ìš” ì•ˆë‚´ ==========\")\n",
        "            print(\"í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ 'coorinkie/speechproject_audio_data'ëŠ” ë¹„ê³µê°œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\")\n",
        "            print(\"ì…ë ¥í•œ í† í°ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ì—†ê±°ë‚˜, ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "            print(\"1. í† í°ì´ ìœ íš¨í•œì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "            print(\"2. ë°ì´í„°ì…‹ ì†Œìœ ì(coorinkie)ì—ê²Œ ì ‘ê·¼ ê¶Œí•œì„ ìš”ì²­í•˜ì„¸ìš”.\")\n",
        "            print(\"3. í˜„ì¬ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” ì´ì „ì— ì„±ê³µì ìœ¼ë¡œ ë§Œë“  ë¡œì»¬ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.\")\n",
        "            print(\"ë¡œì»¬ ë°ì´í„°ì…‹ê³¼ í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ì€ ë‚´ìš©ê³¼ êµ¬ì¡°ê°€ ë™ì¼í•˜ë¯€ë¡œ ëª¨ë¸ í›ˆë ¨ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d328df9d37ad40ac9392414c9759213c",
            "3f6eedfb0ef44f9490714d1811382b42",
            "c339f39d9e124625a273c2a2f239f153",
            "d30d7d795c594ed882df7354081138de",
            "439e853afbae4279a55931230b245a37",
            "91c8cc87c6d647a892ee618c43e770c5",
            "179123768cad491a81c59565172f3442",
            "3e578f229d0742d8879d51a678b224c8",
            "768e9c9831a345218216cfe348712297",
            "9b369210bfc8477bb38e445d139a2c06",
            "87a4c70f38224f0298b9f4091c87e279",
            "b27e9d7b10a344c99d3641f265c3be21",
            "dde79847fc9b4c9ba91d2c49332490f8",
            "f74cead489f54903b9688e28ed5f6381",
            "ee61c7047de44048ab8d853d57ed2cde",
            "724dea93c3c4466691ebb49c3533f766",
            "6d252eb66268414884e84efe04fb65e7",
            "f99fb08be4d946459a2e87dad21f9e49",
            "f78621fdd55d4ae9b0f2f15a03fe73d0",
            "8af20e7b7fae4af291ce11d307b98462",
            "ea74bc9fc0734a0c8b917f3654bf3aec",
            "25f9931d06824151af04add4a9151f8b",
            "5b80867b4a8444c6b05a135f5c18d7f3",
            "0c3bac887341457e8843481560a1e894",
            "c7a01c759a104b16a18c1ce84ed44524",
            "6500477cec8b4c2194d1ca455bc4b78c",
            "efbeba6a895b4ce39ad8eedf2728710b",
            "50c0bd65c7094151abd22bd164cd4ca8",
            "7302e711adb54214b64b5a2616121e3a",
            "9f038fafd41c4e08a6b19bfdc38c3330",
            "b737e18956d049579f02005cf481975c",
            "f92c393690084a598232ab7cf9c42ec7",
            "1aca6a27b4b746d188e39368af95d7e6",
            "23606705f8614a58889ab08bc739fcf2",
            "0d770beb46f64992b42ac6fcd9e00868",
            "47ecdb212240499ca9a24711d581e4eb",
            "8c8a284f11bc472c86561ef00035a777",
            "7f41bb6fc3bd4d3e86b85e03b0df896a",
            "fbce72fef0004a5aa31bcfc78f404d41",
            "a8eb38e4359d4d5a9186b315c79046b5",
            "ca7737b09c624b11b6a0bf1a582d82af",
            "bdc11d2766344c7f8bc7ca31e1b0887c",
            "2411b40b46e845178f0dde437a80a3ce",
            "486e3de95fd446de9937e6c799e7db6f",
            "4da58a08df434028aa78de4ae222179a",
            "93eb5f32880c4eaa8ea2f8473767a974",
            "48daa5f19a484d8880be99c1e2aeb701",
            "2229149e457c4f9ba2e462e376748336",
            "5288d3b1456f43e193aa787b6b23c946",
            "5b7b9eaa0e774560b2c5927a05b4d203",
            "b733bf0a896e466fa70549df02a5ffb5",
            "d7a2fcb696c24ab69bcd33e86a2bf3ef",
            "5f7e1564fe444b299e3e065dbdeee854",
            "7ff96a5ce14e4ea7b56a739d6a5c7e52",
            "e6c882d3cacf4096a0728245fbdc7fba",
            "e938bfbe4f2449d896339a949533d4aa",
            "d0d6e8457ba2417b89e6300c5996cc74",
            "954b5de58bda4a0db03d96289464a6e1",
            "7226463fd2ee4b0793721dc34938d934",
            "df629243e93b44bdb77f7d65b72766d2",
            "c44aa6e9df364cb996c44fb6d5eddd2b",
            "0342fa5b4c994bdda5f46967c2070b2f",
            "6d73e6dd5ba64be88e7d179e2e586838",
            "fa619c9ee365459183df9bde412a5032",
            "67ff6d87fbe04d8c98a1289c3bd94d53",
            "e7b93b2805e24d4795be7bbf3019a868",
            "78b6cb53421e4708a771b24d5abed3e9",
            "39959a5ddc2945d9817ed8d4e69d8da8",
            "b22af43aed184324b02913b7ce0d4004",
            "d1652772c0074f30ac51565e022c55ca",
            "f0b57f68f9924af8b27f0a61d8c87d36",
            "53fb89a8521f4da7898d8c25e57147a1",
            "8594d1bddc744fb18247461c822c761f",
            "85f547c850b24b9b895dec5fe9b70702",
            "4a99975d8da24ddda60d5847efb7806d",
            "e4911b979db34a84abb1fe7546417e1a",
            "3b3fa16cb5f64bcc9ad3fa044b714fe6",
            "33913e142e724d809e4e5e937c5b6cd2",
            "6de2efd2a00f420f90c711b3fe6f1246",
            "2d5d5e5db1034a67abd309397acaad37",
            "c3d319efb2ae45ee85e190425147bf3b",
            "150a920f1a6646a5aa3a88e92a2958ec",
            "d81eb38ec09a45a3a744cb7a25ec1108",
            "3946d0ae653a434ca09b0bcdf394ed79",
            "e626dfe8873a4cf19899da7076b1ff3e",
            "9f87bfe0fb0b4578b99740117e15f097",
            "4919050ea1334fa59d9d71f69201a12e",
            "5ac5ff36c4304d65a0d94a4979812f5c",
            "0d3a0921aa7c4f908c128666e3a3e975",
            "8abd929bbfee46938625711285f34da7",
            "fed496a89c544b43bc782dba209bff78",
            "525912a71c9e43fdbf336ba2e053fe44",
            "c39b8827062f415c9d4c54b8168aad6b",
            "ab48b865222b419fbeb9ab2d10ff1e36",
            "25f1cc2c7c3c41d8aecc2383f010b5cf",
            "4d6bfba94a8649bb9ba8278c08873970",
            "291e8faa17af4607b112e439dd79402b",
            "6c4b61a7c5324062b6a80b0e249671a8",
            "d56d22d445ef44939c64c0da32b9690f",
            "31c67d8903da4c3c85b777e8f3df3106",
            "5bc4f10664db4ea288317ab70b78599c",
            "1e1e11e8166448c5bb56eac47ee42230",
            "77636c4330874fd09bc38f4219d0cbcd",
            "83781121781e46f5afd62ad38cf7ae90",
            "7d2137f0f0184aefaf647aa8f93b9617",
            "730989df4eb145eba1e91423796856d5",
            "a93de3f7dee94c4e8f6eebc0227f03fd",
            "b85c4fc7bcf24b938988aeec6ae0aaac",
            "6882a5476e204feaa5aa2bd05e7aed46",
            "99e8d9ab6f244bd08cc082e5a0a0b9c7",
            "8d9ecf844a6f453885ba5d51ea5d054c",
            "aefc6fb9aa93461f825dbaca2bf405a8",
            "9ca19c9473a841a48a690a7518ee38c3",
            "9927d4e9226a4c0186a050a73228e4ab",
            "704b296432c54822931f2b82d83366be",
            "94ab6449116f4322b06c4d4412c62e94",
            "29a037b612114bf0aa0fcf4c960b9ec7",
            "00f9a4e78a2d4c199b8809db2d2da043",
            "70170a10b4c7483d999cfa25b65a4e36",
            "180dfda3eb6148d597f58136d01ea0fa",
            "27b283fcd061444bbb33fc7c755750d3",
            "41e522b765a84ed58728c04e3b0cdc67",
            "e27a830e379f4ed29cae3f1ab54b7044",
            "c2f78a63858b498f8c4a4c8e1527566f",
            "ad6953a839454d069d209607e30d8a30",
            "92d4199b1aba4722a9ae94f47603edde",
            "41739b4cc8c840478a23e74bbca83725",
            "763b0fc20dfd4888a9791e8f49998444",
            "32bb7e1614a94f4f9fb11871edeef5fa",
            "90a5251e723f4dbd8f76ad67135d0137",
            "ce162084a5b54d27a8f0f0922bec1b96",
            "2a1bd437002847c690ab627ba28aa03d",
            "3d00251a87b74d6794f48c9de7f5ba9b",
            "7424e06c88b34b139557a3b44a3695f1",
            "08617a0ba4cf457f906c231a64fa4347",
            "c8cf3ad25ee2439a8ae28ad550312d69",
            "dae840afbf0a4ce3ba0bb2b0fe80535e",
            "17fd3a88a4d847459ff251cf203e6765",
            "327faa781b84403bade3a6a3faa2c858",
            "6603f5ea819d4922ae24595cc87144a7",
            "c691d200871d4e9b9b524d8b035b1cfb",
            "c4b0e7a076964bbea54d7ac915142e61",
            "3c2c23c1145c45cc96f960c6c4bd5ec3",
            "0b787c7ae0fa4086a8fa4eba7889ee33",
            "2e66dc3e37204e4d908e125ea2543eba",
            "43bb6babfdea40229a758fdfdb7ced1d",
            "d8b9e80c2da54ad7a65f0bef8cbadffc",
            "4671dcd9f3894ee283eee322c58302f1",
            "94912299b03b47149892d7756ed73db7",
            "ca682f7d73544d2a87e9dd6e60e08291",
            "9ce5dbe9f88d4518b8d6fce0ead3ea41",
            "6b5291494e5a4837ade2abed5416c8a8",
            "f6141e0f62db4d6191941acdc8b78767",
            "6e8da0bfb1884ac4804a6a7b7247f2bb",
            "bdf98993e9b14614959f9ea51d6d219b",
            "3b087fa8a5854aa4b853c33fafe3eb90",
            "b3aab0cc65c4424e8cdb855e0a46b6e3",
            "42cab0aa7f0d41798adae75ef6908793",
            "562c91b18d4d4fa2bc07ad8582d118e9",
            "cdb660e965b24a5db826fdfb5dff1085",
            "5193949496e74123aadd6b28fffe6a9c",
            "f2fad90f888948a990be836970567f83",
            "c69606df3a8140b7bcda4ca48546b85d",
            "d374dceabb1549c6b00b5b17f418d206",
            "fa6edfe9520e489c9721db264c1c8195",
            "284cf3cbe0e74af2bb874d1de27cb72f",
            "69947ccd535649c7b0734f07c6834c57",
            "972d4b8c99d143809b1256fc13157355",
            "ae088432dc754659841709d5a49ef22f",
            "d816f6391dbc401092cefabe577e5505",
            "60795ac1623d4f8ba24f238b9eae97ae",
            "49e8e8eed50847ffbbdab1dd7d0e78fc",
            "05ffd1c8d21e4b999543fd72e6ae8677",
            "27ef1c82a9ec41aa9e56b8794396fbf0",
            "ac61078b4e1e402ca97519fb6629110a",
            "15c6c746b32749b8b50f425b3ebe5676"
          ]
        },
        "id": "3FGUmsTfEgHD",
        "outputId": "d7854723-4b00-422e-b0c9-8d985b85fcf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„°ì…‹ í™•ì¸\n",
        "print(dataset)\n",
        "\n",
        "# í›ˆë ¨ ë°ì´í„° ì‚¬ìš©\n",
        "train_data = dataset['train']\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©\n",
        "test_data = dataset['test']\n",
        "\n",
        "# ê²€ì¦ ë°ì´í„° ì‚¬ìš©\n",
        "validation_data = dataset['validation']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKDBWDeuE7ZU",
        "outputId": "d674c71e-a108-47f9-ab2c-5d132d1525a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    # ì˜¤ë””ì˜¤ íŒŒì¼ì„ 16kHzë¡œ ë¡œë“œ\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # input audio arrayë¡œë¶€í„° log-Mel spectrogram ë³€í™˜\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # target textë¥¼ label idsë¡œ ë³€í™˜\n",
        "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
        "    return batch"
      ],
      "metadata": {
        "id": "IfV8BIEXE_MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”§ bytesì™€ pathë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜¬ë°”ë¥¸ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "\n",
        "import io\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    # ğŸµ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    try:\n",
        "        if \"bytes\" in audio and audio[\"bytes\"] is not None:\n",
        "            # bytes ë°ì´í„°ì—ì„œ ì˜¤ë””ì˜¤ ë¡œë“œ\n",
        "            audio_bytes = audio[\"bytes\"]\n",
        "\n",
        "            # bytesë¥¼ íŒŒì¼ ê°ì²´ë¡œ ë³€í™˜\n",
        "            audio_io = io.BytesIO(audio_bytes)\n",
        "\n",
        "            # soundfileë¡œ ì˜¤ë””ì˜¤ ì½ê¸°\n",
        "            audio_array, sample_rate = sf.read(audio_io)\n",
        "\n",
        "            # ìŠ¤í…Œë ˆì˜¤ë©´ ëª¨ë…¸ë¡œ ë³€í™˜\n",
        "            if len(audio_array.shape) > 1:\n",
        "                audio_array = np.mean(audio_array, axis=1)\n",
        "\n",
        "        elif \"path\" in audio and audio[\"path\"] is not None:\n",
        "            # íŒŒì¼ ê²½ë¡œì—ì„œ ì˜¤ë””ì˜¤ ë¡œë“œ\n",
        "            audio_array, sample_rate = sf.read(audio[\"path\"])\n",
        "\n",
        "            # ìŠ¤í…Œë ˆì˜¤ë©´ ëª¨ë…¸ë¡œ ë³€í™˜\n",
        "            if len(audio_array.shape) > 1:\n",
        "                audio_array = np.mean(audio_array, axis=1)\n",
        "        else:\n",
        "            # ë¹ˆ ì˜¤ë””ì˜¤\n",
        "            audio_array = np.zeros(16000)\n",
        "            sample_rate = 16000\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        # ë¹ˆ ì˜¤ë””ì˜¤ë¡œ ëŒ€ì²´\n",
        "        audio_array = np.zeros(16000)\n",
        "        sample_rate = 16000\n",
        "\n",
        "    # ğŸ¯ Whisperìš© ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬\n",
        "    # 16kHzë¡œ ë¦¬ìƒ˜í”Œë§ (í•„ìš”ì‹œ)\n",
        "    if sample_rate != 16000:\n",
        "        # librosa ì‚¬ìš©í•´ì„œ ë¦¬ìƒ˜í”Œë§\n",
        "        import librosa\n",
        "        audio_array = librosa.resample(audio_array, orig_sr=sample_rate, target_sr=16000)\n",
        "\n",
        "    # feature extractorë¡œ ë³€í™˜\n",
        "    batch[\"input_features\"] = feature_extractor(audio_array, sampling_rate=16000).input_features[0]\n",
        "\n",
        "    # ğŸ“ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "    text = batch[\"transcripts\"]\n",
        "    batch[\"labels\"] = tokenizer(text).input_ids\n",
        "\n",
        "    return batch\n",
        "\n",
        "print(\"ğŸ¯ bytes/path ì²˜ë¦¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ì´ì œ ë‹¤ì‹œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œë„í•´ë´…ì‹œë‹¤...\")\n",
        "\n",
        "# ğŸ§ª í•œ ê°œ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸\n",
        "try:\n",
        "    sample = dataset[\"train\"][0]\n",
        "    print(\"ğŸ” ì²« ë²ˆì§¸ ìƒ˜í”Œ bytes í™•ì¸:\")\n",
        "    audio = sample[\"audio\"]\n",
        "    print(f\"bytes í¬ê¸°: {len(audio['bytes']) if audio['bytes'] else 0} bytes\")\n",
        "    print(f\"path: {audio['path']}\")\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "    processed_sample = prepare_dataset(sample)\n",
        "    print(\"âœ… ìƒˆë¡œìš´ ì „ì²˜ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
        "    print(f\"input_features shape: {processed_sample['input_features'].shape}\")\n",
        "    print(f\"labels length: {len(processed_sample['labels'])}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ’¡ ì¶”ê°€ ë””ë²„ê¹…ì´ í•„ìš”í•©ë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqCOfCu1FAGi",
        "outputId": "8dae499d-6477-4cac-f9f5-13afa707fb6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ ì´ë¯¸ ì „ì²˜ë¦¬ëœ ë°ì´í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "low_call_voices = dataset  # ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„° ë°”ë¡œ ì‚¬ìš©!\n",
        "\n",
        "print(\"ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„° í™•ì¸:\")\n",
        "print(f\"Train: {len(low_call_voices['train'])}ê°œ\")\n",
        "print(f\"Validation: {len(low_call_voices['validation'])}ê°œ\")\n",
        "print(f\"Test: {len(low_call_voices['test'])}ê°œ\")\n",
        "print(f\"ì»¬ëŸ¼: {low_call_voices['train'].column_names}\")\n",
        "\n",
        "# ğŸ¤– ëª¨ë¸ ë¡œë“œ\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"Korean\", task=\"transcribe\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì´ì œ í›ˆë ¨ ì„¤ì •ìœ¼ë¡œ ë„˜ì–´ê°€ì„¸ìš”!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "b6121c5b613c4806a1cc96224813b76f",
            "0515c330e1ef4118bda034751d48f90e",
            "d0180f8baf8443b4b03390f57b9a3a77",
            "11148545808a4afb8e2aa68d0a1b790a",
            "9d4ff583a3fd4a77a2457efa549c2df8",
            "fb0a6355d46749ebb0cc4b7792504236",
            "2f466fd81be146588f4aafe0f24fdfdc",
            "cb93684c51824373bfd904f8cadbdc9f",
            "fef0d114570f4f109effc26284ddf094",
            "6050af0d451f43a1b757531b2bdb0f5e",
            "eafdf96619074c6da373bb6c9481f23e",
            "be1ad309cb144805aa12f09091cc08c4",
            "506d1d833db94b69b51f71036acf1a99",
            "16e2c6fa24ee46d2966b18bd7b02ce52",
            "4c990cba847a42519bf77b48cc37ee1a",
            "5b0a145532ce420eb5af26c5730076f8",
            "4ddda48972dc45788d82db90fc8b46ad",
            "2a56c494c467417e9659bcc19648b08d",
            "c172a7abeb874ad2835db0921e98fbc1",
            "8f585d2fbb154769a7b2908ad9192ab2",
            "b740f3d0bce34d8d83e3ca79e0b1e316",
            "e3bfc2ed02034a60ba3cee26c3ceae3d",
            "39d4850e6e2647acb676b403c571296e",
            "031348ca310d4f35b1112e7f80d2fb5d",
            "abe3cb74c6a44aecb14bc79fb23e2058",
            "21b93d35223e4a1a8da441f509142c34",
            "f40a90fb18404fa88112a1e7a7e64b2c",
            "f0f0850c9f0b4f38a8997353747fc73c",
            "f189a5be65a1436e9d9caca55e76447f",
            "979231ebfe5e4d04b4d6f71eea0fd07e",
            "91ed9840510c40c8aa728462d4cfc9e2",
            "b688f7b0345547f698132fc57c1904d7",
            "2c54f765fcd0499ea78e6b2c7cecba49"
          ]
        },
        "id": "eDOCm0IRFN9M",
        "outputId": "40a2d392-41ff-4666-d981-8647e12ce5ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper_overfitting_prevention\",   # ê³¼ì í•© ë°©ì§€ ì „ìš©\n",
        "\n",
        "    # ğŸ¯ ë°°ì¹˜ í¬ê¸°: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ì‘ê²Œ\n",
        "    per_device_train_batch_size=2,                   # 8â†’2 (ê³¼ì í•© ë°©ì§€)\n",
        "    gradient_accumulation_steps=8,                   # 2â†’8 (effective batch=16 ìœ ì§€)\n",
        "    per_device_eval_batch_size=4,                    # 8â†’4 (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "\n",
        "    # ğŸ“‰ í•™ìŠµë¥ : ë§¤ìš° ë³´ìˆ˜ì ìœ¼ë¡œ\n",
        "    learning_rate=5e-6,                              # 3e-5â†’5e-6 (ë§¤ìš° ë‚®ê²Œ)\n",
        "    warmup_steps=50,                                 # 40â†’50 (ì ë‹¹í•œ ì›Œë°ì—…)\n",
        "\n",
        "    # â±ï¸ í›ˆë ¨ ê¸¸ì´: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ì§§ê²Œ\n",
        "    max_steps=200,                                   # 400â†’200 (ì§§ì€ í›ˆë ¨)\n",
        "\n",
        "    # ğŸ›¡ï¸ ì •ê·œí™”: ë§¤ìš° ê°•í•˜ê²Œ\n",
        "    weight_decay=0.2,                                # 0.01â†’0.2 (ë§¤ìš° ê°•í•œ ì •ê·œí™”)\n",
        "    gradient_checkpointing=True,                     # True (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "\n",
        "    # ğŸ“Š ëª¨ë‹ˆí„°ë§: ë§¤ìš° ìì£¼ (ì¡°ê¸° ë°œê²¬)\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,                                   # 40â†’20 (ë§¤ìš° ìì£¼ í‰ê°€)\n",
        "    save_steps=40,                                   # 40 ìœ ì§€\n",
        "    logging_steps=5,                                 # 20â†’5 (ë§¤ìš° ìì£¼ ë¡œê¹…)\n",
        "\n",
        "    # ğŸ¯ ìƒì„± ì„¤ì •\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "\n",
        "    # ğŸ† ëª¨ë¸ ì„ íƒ: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_cer\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=2,                              # 2ê°œë§Œ ì €ì¥ (ê³µê°„ ì ˆì•½)\n",
        "\n",
        "    # âš¡ ì„±ëŠ¥ ìµœì í™”\n",
        "    fp16=True,\n",
        "\n",
        "    # ğŸš« ì™¸ë¶€ ì—°ê²° ë¹„í™œì„±í™”\n",
        "    report_to=[],\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "id": "1p-x_b5LFRVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # input_featuresë¥¼ ë°°ì¹˜ë¡œ ë¶„ë¦¬\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # labelsë¥¼ ë°°ì¹˜ë¡œ ë¶„ë¦¬ (í† í¬ë‚˜ì´ì € íŒ¨ë”©)\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # íŒ¨ë”© í† í°ì„ -100ìœ¼ë¡œ êµì²´ (loss ê³„ì‚°ì—ì„œ ë¬´ì‹œë¨)\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "# ë°ì´í„° ì½œë ˆì´í„° ìƒì„±\n",
        "data_collator_fixed = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "KELJfnv2FWnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    try:\n",
        "        pred_ids = pred.predictions\n",
        "        label_ids = pred.label_ids\n",
        "\n",
        "        # -100ì„ íŒ¨ë”© í† í°ìœ¼ë¡œ ëŒ€ì²´\n",
        "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "        # ë””ì½”ë”©\n",
        "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "        # ì •ë¦¬\n",
        "        pred_str = [p.strip() if p.strip() else \"empty\" for p in pred_str]\n",
        "        label_str = [l.strip() if l.strip() else \"empty\" for l in label_str]\n",
        "\n",
        "        # CER ê³„ì‚°\n",
        "        cer_metric = evaluate.load(\"cer\")\n",
        "        cer = cer_metric.compute(predictions=pred_str, references=label_str) * 100\n",
        "\n",
        "        print(f\"ğŸ¯ í˜„ì¬ CER: {cer:.2f}%\")\n",
        "\n",
        "        return {\"cer\": cer}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜: {e}\")\n",
        "        return {\"cer\": 100.0}"
      ],
      "metadata": {
        "id": "KYrXiYS-FXfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validationì€ ì´ë¯¸ ì²˜ë¦¬ë˜ì–´ ìˆìœ¼ë‹ˆ trainê³¼ testë§Œ ì²˜ë¦¬\n",
        "print(\"ğŸ”„ train ë°ì´í„° ì˜¤ë””ì˜¤ í˜•ì‹ ë³€í™˜ ì¤‘...\")\n",
        "low_call_voices[\"train\"] = low_call_voices[\"train\"].cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"ğŸ”„ test ë°ì´í„° ì˜¤ë””ì˜¤ í˜•ì‹ ë³€í™˜ ì¤‘...\")\n",
        "low_call_voices[\"test\"] = low_call_voices[\"test\"].cast_column(\"audio\", Audio(sampling_rate=16000))\n",
        "\n",
        "print(\"ğŸµ ì˜¤ë””ì˜¤ í˜•ì‹ ë³€í™˜ ì™„ë£Œ!\")\n",
        "\n",
        "# ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "# trainê³¼ testë§Œ ì „ì²˜ë¦¬\n",
        "print(\"ğŸ”„ train ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
        "low_call_voices[\"train\"] = low_call_voices[\"train\"].map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=[\"audio\", \"transcripts\"],\n",
        "    num_proc=1\n",
        ")\n",
        "\n",
        "print(\"ğŸ”„ test ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
        "low_call_voices[\"test\"] = low_call_voices[\"test\"].map(\n",
        "    prepare_dataset,\n",
        "    remove_columns=[\"audio\", \"transcripts\"],\n",
        "    num_proc=1\n",
        ")\n",
        "\n",
        "print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "print(low_call_voices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "ee2b857abed941af972d3178b405c918",
            "96ee67a7da3e40969ece0a83fe94f42a",
            "6fe7b30a875b41b0ba6fc501970d2b13",
            "2c62bf71e85446bc9fe05a405315e4dd",
            "acfe07db8f304c00bc97a4d742d70380",
            "ff213f2245b24cd588c315ea3d0f12be",
            "aa7fea789e354876a6c62e2300a32618",
            "636fd309ae37449eae971b5b7ee6314c",
            "2259740aa65e4588aad47a339b6c13a8",
            "e77bb4239b2e40aeb83d9311935d2f7f",
            "839c296659b541c5b2de7d1af6b0a555",
            "7b9c2d48558940d5966ac9cdeac8757a",
            "f98cb2dc1c2d476fb389c0245f1fbcbc",
            "798fd4fa84094c16850a54210cd9fb05",
            "66c6ff4f2b354e0f934df97745b10f61",
            "409027120e6349599f09018e4b870f76",
            "3518146535994100959dc321536d90a0",
            "be9885963e0947f7afb7d506d8cc6de6",
            "185a0d76327a49d7b59f2f5f7461115c",
            "b77218e24a1149e3b44b6d16af6ff5be",
            "99c7e87f01a042ca9998b843dda48927",
            "f33be5d4e2e24b8dab878850e43e3b82"
          ]
        },
        "id": "S875a6vIFbRz",
        "outputId": "189cfa30-fb82-400f-f45f-051f9201e0a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¡œì»¬ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ê°œì„ ëœ ë°©ë²•)\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "import os\n",
        "import torch\n",
        "\n",
        "checkpoint_path = \"./whisper_simple/checkpoint-50\"\n",
        "\n",
        "try:\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}\")\n",
        "\n",
        "    print(\"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸ ì¤‘...\")\n",
        "    files = os.listdir(checkpoint_path)\n",
        "    print(f\"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤: {files}\")\n",
        "\n",
        "    # ë¡œì»¬ ê²½ë¡œì—ì„œ ì§ì ‘ ë¡œë“œ (local_files_only=True ì¶”ê°€)\n",
        "    print(\"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        checkpoint_path,\n",
        "        local_files_only=True\n",
        "    )\n",
        "\n",
        "    # í”„ë¡œì„¸ì„œë„ ê°™ì€ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ ì‹œë„, ì‹¤íŒ¨í•˜ë©´ ë² ì´ìŠ¤ ëª¨ë¸ì—ì„œ ë¡œë“œ\n",
        "    try:\n",
        "        processor = WhisperProcessor.from_pretrained(checkpoint_path, local_files_only=True)\n",
        "        print(\"âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
        "    except:\n",
        "        print(\"âš ï¸  ì²´í¬í¬ì¸íŠ¸ì—ì„œ í”„ë¡œì„¸ì„œ ë¡œë“œ ì‹¤íŒ¨, ë² ì´ìŠ¤ ëª¨ë¸ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤\")\n",
        "        processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "    print(\"âœ… Step 50 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
        "    print(\"ğŸ¯ ì´ì œ ì´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ”„ ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ëŒ€ì²´ ì‹œë„ ì¤‘...\")\n",
        "\n",
        "    # ëŒ€ì²´ ë°©ë²•: ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ í›„ ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ\n",
        "    try:\n",
        "        model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "        processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "        state_dict_path = os.path.join(checkpoint_path, \"pytorch_model.bin\")\n",
        "        if os.path.exists(state_dict_path):\n",
        "            state_dict = torch.load(state_dict_path, map_location=\"cpu\")\n",
        "            model.load_state_dict(state_dict)\n",
        "            print(\"âœ… ë² ì´ìŠ¤ ëª¨ë¸ + ì²´í¬í¬ì¸íŠ¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ!\")\n",
        "        else:\n",
        "            print(\"âš ï¸  pytorch_model.binì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ë² ì´ìŠ¤ ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
        "\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ ëŒ€ì²´ ë°©ë²•ë„ ì‹¤íŒ¨: {e2}\")\n",
        "        exit(1)\n",
        "\n",
        "# ê°œì„ ëœ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
        "\n",
        "    Returns:\n",
        "        str: ë³€í™˜ëœ í…ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import librosa\n",
        "\n",
        "        print(f\"ğŸµ ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘: {audio_path}\")\n",
        "        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)\n",
        "        audio, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "        print(\"ğŸ”„ ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘...\")\n",
        "        # ì˜¤ë””ì˜¤ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "        input_features = processor(\n",
        "            audio,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\"\n",
        "        ).input_features\n",
        "\n",
        "        # GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        input_features = input_features.to(device)\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ìƒì„±\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = model.generate(\n",
        "                input_features,\n",
        "                max_length=448,  # ìµœëŒ€ ê¸¸ì´ ì œí•œ\n",
        "                num_beams=5,     # ë¹” ì„œì¹˜ ì‚¬ìš©\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
        "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "        print(\"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ!\")\n",
        "        return transcription[0].strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}\")\n",
        "        return None\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜\n",
        "def test_model():\n",
        "    \"\"\"ëª¨ë¸ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜\"\"\"\n",
        "    print(\"\\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸:\")\n",
        "    print(\"transcribe_audio('your_audio_file.wav') í˜•íƒœë¡œ ì‚¬ìš©í•˜ì„¸ìš”\")\n",
        "    print(\"ì˜ˆ: result = transcribe_audio('sample.wav')\")\n",
        "\n",
        "print(\"ğŸ¤ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "print(\"ğŸ“– ì‚¬ìš©ë²•:\")\n",
        "print(\"  - transcribe_audio('ì˜¤ë””ì˜¤íŒŒì¼ê²½ë¡œ.wav') í•¨ìˆ˜ë¡œ ì‚¬ìš©í•˜ì„¸ìš”\")\n",
        "print(\"  - test_model() í•¨ìˆ˜ë¡œ ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494,
          "referenced_widgets": [
            "b8d97c88b54d4fb785087a82ce0d5261",
            "fa45882cca484374af82243a6924e1eb",
            "14c7ffa8655a4364b68931c54d7322b9",
            "f859148d7b2f4cb1b838d19df69d21c0",
            "ca6f1ec272394adba52f7b2cf2398f20",
            "f2c6b9de4d4f42968a4fe3525a3e4d92",
            "db084835d56d41debd191e09121773b3",
            "000fb395f92a44b2ab4012f644adc3bd",
            "e99b3ae624f547dea8e3949dcbb5567f",
            "3be91c19400b4cc29ea35d3dd0e5e8ab",
            "d6543f1646be48ceae7082a45030782f",
            "efbe41c0954849aaa99ec2c61ed8c95d",
            "e6c29463f3e94a5b9a54b17850ff93d2",
            "574427461b7a44e7a51c7cff243cbecb",
            "d904a87fde21483c8a3b5f44d16d3302",
            "e9dceb0f049a49b9af3844e49666c1ae",
            "3be08212182e41fb82043360e769b299",
            "3062bb60f5234cb89653020adb6a9269",
            "870ef7398e914e98be8857845c42a476",
            "98c45e85e65349499c602aed21571ebf",
            "0497583be4614e7fbffee3a287ef6852",
            "61ba84cba5134872866263aa18d6f2e1",
            "4e355978f0c443b8ad42e959da34b8aa",
            "b3a0501fd5424b539664b486c9a09118",
            "6bf7fc652f89409a93780202984e92a8",
            "b0e8d4157f484192bb5a52dab57c63e9",
            "fe513ade81b64b9db215c580fdb0ccce",
            "240011a1ddba4374b6edcf556dac5231",
            "377b2f15cde8452e8de73f1a114da34a",
            "485f23ebac7b4d9bb3a712cb3697c09e",
            "a32fd306922e435fb392c73e32c55ade",
            "25510fbfd81f4c4db356047a4acc05ae",
            "da0b9f48e6e34d97b49d43e0da5f798d",
            "dbed36140a09414f808f57d7fd7a8cac",
            "c3e0a24e4b5146ed88fe908286ec564c",
            "a2cc4fd4bdf54e7c8f329b681e2571c1",
            "9fafd4e49748411e8593d833ed077dc6",
            "8f3d08fe01e84bbc8a92b5746e1142db",
            "be85f0cd4dd948539c21c68ca55a3cc9",
            "22d83a0e7599407286966295b1146e3f",
            "02eba598577a4ccfb2511ba221c8288a",
            "027e27800d5b4961aadc101f00a3fb17",
            "47ed38dcca64444090e408328c29aa7f",
            "60b5cf5d27114954803b4aedd6812264",
            "e5a53075beee4b5596838973c62181a9",
            "42ad0d5221c745b1bad8cebcdc8555e4",
            "61fad89530df48f79886412ab54c77c8",
            "afb8cb8c4bea4c95bc2f48686c204f23",
            "a8bbaae4f8774c0dafd74e3c6a6ccdce",
            "a874e1bbd0304a7d84ea2b479510eeb7",
            "5c3c981cbafe472197f7511445f2ad98",
            "aa38b237c73e4297bc91383ce5d62f37",
            "6b1be198fcb349f6a2b1693ae74f0ac4",
            "c557e61158ca466e8ffc47ab1819c94f",
            "67f6735573ae4ecabebbf7f74ce9d378",
            "b8c09f41eb164593b455d005e0002005",
            "2b47f1cfc15d419eb032d35f8f03f1ee",
            "6fb50b9b740d430db1f3df23b3a0960b",
            "ff30f0fd2a3f43cfa4925254fbf03d66",
            "e8003e5972df4de8a74c46f3487c4ef2",
            "0f5cf9c958c740698054cf3a50510d89",
            "853fb5b98cb24c638ae748b1e06ee48f",
            "8cbf165d06844387a0737f887d4c110a",
            "74ad4eb2c9504b56ba6fbb9767702fc7",
            "089ccfad5db44b17b5e49ef6ba0dfb78",
            "de4472cd3401422c919b14ff2de011e0",
            "6b7cb77b594b4b72a0712816e365a845",
            "536ebd171f844a92b602ee530433c364",
            "04046d57a1c34caca0e99f1243224297",
            "a289903ee0d743e7a71d4832632c14a7",
            "35f54a6b7ba64634834b1061ff1115d9",
            "88d1a8d2ac304512afbbdb9f5ee50615",
            "e4ba9b9950774a17a895c2b96e2ec89d",
            "76b33330c22b4f908fe200627093e672",
            "273576a0339243eca388463fd415e090",
            "c92f8cbf92fe46bc81054d0a9a9ab786",
            "a803971c8cce467584db9ccb8d5a9597",
            "dcbef34235f04c4bb9d4c775f87cdc16",
            "5923161a796545579e50a675c0c1ed55",
            "789e1d8e0281450e8f9b9449e3d10bb1",
            "377a39f59a7b4890bbe456f7e865da4e",
            "826a33fa9508468da78a75fc58bc915e",
            "fbd07158fb44437e8a6417c633bed220",
            "504bf18ccfc84b1e92ec96e088bfe051",
            "6d8bcabf3e5e47118b58b9d88607ec5b",
            "e71d69c08a80475da0b35661f368c1ab",
            "3642bf6bf45c4ceca437a404d0b106e8",
            "c905ec6c3d7a47c5b86b403d225ab308",
            "077ab48415184e5a80701990a6712f76",
            "7d94a2770fc44b2fbf36bb24b0dd9a89",
            "6a18716080204ae1a21ca9b407b553b8",
            "3307e51283ab4543be649e4ed8f029ec",
            "6e5b0ff6dea94c14ad1bcb8b01f81b7a",
            "1c559b14b7fd4a4396d1bcf6e47265d9",
            "891b9727888945c8bc1b314cd33eb172",
            "7d8041116ee44f22a55e3ad027f7463c",
            "99d2dfccd1d147d7aa528fd955dd0afa",
            "06d6500f4b13465087b01c42b7cfff93",
            "03b0819480ab4a84bbeb016f4cf326ba",
            "a0bac921ac00488a9b8c09936cccbf7d",
            "7243ccf758ef42859c1dfaf6932796ec",
            "f9c88f579a2547b4918cbccd40e9cf88",
            "a40585d94bfc429bb28783684d04a6b9",
            "86fc57cdb75b41bc81dda54b14eb24f5",
            "9b0c08a950ae41548222f6bf6434de27",
            "a331ed38bab24f35b7755858bf9ce2dd",
            "7abd64d0e0be43b29828bcde3091ca5f",
            "04e6161798e6478a898d8c47080ec2d4",
            "a2faef44fae04f259575c4c263de29eb",
            "e79306ff5e8b409398fb2b992e2b489e",
            "9802daf399e949e893cc32924acea329",
            "fddc227fd1734f2485599a97ce824639",
            "9439d0ba93964bf38615406d805e7460",
            "7e7f9436ebaf485098cfe3c2ded38f24",
            "0dba457f3589411085cadfe3842e4b12",
            "41c756617487471c876e7a42b29c74e1",
            "8e46054a95794e388aa06c336c4f2aba",
            "52874e91563e402c9a816aa6a035aefb",
            "c43bddd7b52a4d4da50d2835c646e194",
            "c9428772a8ce487983dd8ee71c76544a",
            "af0eaa18c40948dbad348402fba18b12"
          ]
        },
        "id": "NMCKjxfVF1W-",
        "outputId": "ddaccce0-fb58-4387-806d-e51f1fff1f3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "from transformers import (\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperProcessor,\n",
        "    WhisperTokenizer,\n",
        "    WhisperForConditionalGeneration,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")\n",
        "import torch\n",
        "import evaluate\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "# SpecAugmentë¥¼ ì‚¬ìš©í•œ ê°•ë ¥í•œ ë°ì´í„° ì¦ê°•\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
        "    \"openai/whisper-small\",\n",
        "    # ë§¤ìš° ê°•í•œ ë°ì´í„° ì¦ê°•\n",
        "    do_specaugment=True,\n",
        "    specaugment_freq_mask_param=25,        # ê¸°ë³¸ 15 â†’ 25\n",
        "    specaugment_time_mask_param=50,        # ê¸°ë³¸ 35 â†’ 50\n",
        "    specaugment_num_freq_masks=3,          # ê¸°ë³¸ 2 â†’ 3\n",
        "    specaugment_num_time_masks=3,          # ê¸°ë³¸ 2 â†’ 3\n",
        ")\n",
        "\n",
        "processor = WhisperProcessor(\n",
        "    feature_extractor=feature_extractor,\n",
        "    tokenizer=WhisperTokenizer.from_pretrained(\"openai/whisper-small\")\n",
        ")\n",
        "\n",
        "# Small ëª¨ë¸ + ê°•ë ¥í•œ SpecAugment\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# í•œêµ­ì–´ì— íŠ¹í™”ëœ ì„¤ì •\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []\n",
        "\n",
        "# Whisper ì „ìš© ë°ì´í„° ì½œë ˆì´í„° ì •ì˜\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # ì…ë ¥ íŠ¹ì§•ë“¤ì„ ë¶„ë¦¬\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        labels = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "        # ì…ë ¥ íŠ¹ì§•ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # ë¼ë²¨ë“¤ì„ íŒ¨ë”©\n",
        "        labels_batch = self.processor.tokenizer.pad(labels, return_tensors=\"pt\")\n",
        "\n",
        "        # -100ìœ¼ë¡œ íŒ¨ë”©ëœ í† í°ì„ êµì²´ (ì†ì‹¤ ê³„ì‚°ì—ì„œ ë¬´ì‹œë¨)\n",
        "        if \"attention_mask\" in labels_batch:\n",
        "            labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        else:\n",
        "            labels = labels_batch[\"input_ids\"]\n",
        "\n",
        "        # ì‹œì‘ í† í°ì´ ìˆë‹¤ë©´ ì œê±° (ë””ì½”ë” ì…ë ¥ì—ì„œëŠ” í•„ìš” ì—†ìŒ)\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "# ë°ì´í„° ì½œë ˆì´í„° ì´ˆê¸°í™”\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "\n",
        "# ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜\n",
        "def compute_metrics(pred):\n",
        "    cer_metric = evaluate.load(\"cer\")\n",
        "    wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # -100ì„ íŒ¨ë”© í† í°ìœ¼ë¡œ ëŒ€ì²´\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
        "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # ê³µë°± ì œê±°\n",
        "    pred_str = [text.strip() for text in pred_str]\n",
        "    label_str = [text.strip() for text in label_str]\n",
        "\n",
        "    # CERê³¼ WER ê³„ì‚° í›„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\n",
        "        \"cer\": cer * 100,\n",
        "        \"wer\": wer * 100\n",
        "    }\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ì„¤ì • ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P-cfiACH-BK",
        "outputId": "abe705b5-8927-4b79-e69e-8a1bdadbc235"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í›ˆë ¨ ì„¤ì •\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper_small_strong_augment\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=2,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=100,\n",
        "    max_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    logging_steps=20,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_cer\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=False,\n",
        "    report_to=[],\n",
        "    push_to_hub=False,\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "# íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=low_call_voices[\"train\"],\n",
        "    eval_dataset=low_call_voices[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=processor,\n",
        ")\n",
        "\n",
        "print(\"ğŸš€ ê°•ë ¥í•œ SpecAugment + Small ëª¨ë¸!\")\n",
        "print(\"ğŸ¯ ëª©í‘œ: CER 30% ì´í•˜\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "6f9943acac194e8384ae29daa40c57bf",
            "8a3fd4a15f664f729c209234a84de3ee",
            "8d4658a3f57a4c39b9bdb807af03f01e",
            "f22af5b7beb148e79fcfa1e89350a787",
            "db9ace553e2f423186bf2a1b468836db",
            "e1852eacef934b72989c6d833ce62e37",
            "fa2a3b6dbab147dcbda2aeffc6b80944",
            "d5c3aeeb43e846818282e8202adb5337",
            "495ee2d023a44ee2bdd432e06f5f9d01",
            "f34629b9cf3e4719a37b2e8466e6fc68",
            "813c7b7359f342e0b094f8a9482be88c",
            "f7f348ab5e9043139bbadf6dd3a20da3",
            "43af6a1393274e56b9c96d69d7867f84",
            "229a51fd48594ede8977f5aaf56cfecb",
            "bddd1866ca5c4bf9a7cae9368f3caf45",
            "e979bc01860544218082003cfa4bddfb",
            "22685dfcaf9d42169b1474314d03c857",
            "d63656ea4a354843acebb8b237a33fbb",
            "e60c2f7d4e9246bc8caa67c47670ed1b",
            "362b01f413d24e1fb121ef98f29d3bfa",
            "fa7976b1edbb411d9ffbd06ecd9664d7",
            "d3bca1016b2a47eea04c7b9e0ec33cbc"
          ]
        },
        "id": "pYk1MkD2IBA9",
        "outputId": "61010e1d-2c88-47b9-918e-6ae318a3fe3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê³¼ì í•© ë°©ì§€ ì¤‘ì‹¬ì˜ í›ˆë ¨ ì„¤ì •\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper_small_regularized\",\n",
        "    per_device_train_batch_size=2,        # ì›ë˜ í¬ê¸° ìœ ì§€\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=2,\n",
        "    learning_rate=1e-5,                   # ì›ë˜ í•™ìŠµë¥  ìœ ì§€\n",
        "    warmup_steps=150,\n",
        "    max_steps=800,                        # ì ë‹¹íˆ ì¦ê°€ (500 â†’ 800)\n",
        "    weight_decay=0.15,                    # ê°€ì¤‘ì¹˜ ê°ì†Œ ì¦ê°€ (0.1 â†’ 0.15)\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    logging_steps=20,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    load_best_model_at_end=True,          # í•œ ë²ˆë§Œ!\n",
        "    metric_for_best_model=\"eval_cer\",\n",
        "    greater_is_better=False,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=False,\n",
        "    report_to=[],\n",
        "    push_to_hub=False,\n",
        "    remove_unused_columns=False,\n",
        "\n",
        "    # ğŸ”¥ ê³¼ì í•© ë°©ì§€ ì„¤ì •ë“¤\n",
        "    lr_scheduler_type=\"linear\",           # ì„ í˜• ê°ì†Œ (ë” ì•ˆì •ì )\n",
        "    dataloader_drop_last=True,            # ë°°ì¹˜ í¬ê¸° ì¼ê´€ì„±\n",
        "    eval_accumulation_steps=4,            # í‰ê°€ ì‹œ ë©”ëª¨ë¦¬ ì•ˆì •ì„±\n",
        ")\n",
        "\n",
        "# ë” ê°•í•œ ì •ê·œí™”ë¥¼ ìœ„í•œ SpecAugment ì„¤ì •\n",
        "feature_extractor_stronger = WhisperFeatureExtractor.from_pretrained(\n",
        "    \"openai/whisper-small\",\n",
        "    # ğŸµ í›¨ì”¬ ë” ê°•í•œ ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
        "    do_specaugment=True,\n",
        "    specaugment_freq_mask_param=35,       # 25 â†’ 35\n",
        "    specaugment_time_mask_param=70,       # 50 â†’ 70\n",
        "    specaugment_num_freq_masks=4,         # 3 â†’ 4\n",
        "    specaugment_num_time_masks=4,         # 3 â†’ 4\n",
        ")\n",
        "\n",
        "processor_stronger = WhisperProcessor(\n",
        "    feature_extractor=feature_extractor_stronger,\n",
        "    tokenizer=WhisperTokenizer.from_pretrained(\"openai/whisper-small\")\n",
        ")\n",
        "\n",
        "# ë°ì´í„° ì½œë ˆì´í„° ì—…ë°ì´íŠ¸\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor_stronger)\n",
        "\n",
        "# íŠ¸ë ˆì´ë„ˆ ì¬ì´ˆê¸°í™” (ë” ê°•í•œ ì •ê·œí™” ì ìš©)\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=low_call_voices[\"train\"],\n",
        "    eval_dataset=low_call_voices[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=processor_stronger,  # ë” ê°•í•œ SpecAugment\n",
        ")\n",
        "\n",
        "print(\"ğŸ›¡ï¸ ê³¼ì í•© ë°©ì§€ ì¤‘ì‹¬ í›ˆë ¨!\")\n",
        "print(\"ğŸ¯ ëª©í‘œ: CER 15% + ê±´ê°•í•œ ì¼ë°˜í™”\")\n",
        "print(\"ğŸ“Š ê³¼ì í•© ë°©ì§€ ì „ëµ:\")\n",
        "print(\"   - ë” ê°•í•œ SpecAugment (35, 70, 4, 4)\")\n",
        "print(\"   - ê°€ì¤‘ì¹˜ ê°ì†Œ ì¦ê°€ (0.1 â†’ 0.15)\")\n",
        "print(\"   - ì ë‹¹í•œ í›ˆë ¨ ë‹¨ê³„ (500 â†’ 800)\")\n",
        "print(\"   - ì¡°ê¸° ì¢…ë£Œë¡œ ìµœì  ëª¨ë¸ ì„ íƒ\")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "f-q_GuFNVvrl",
        "outputId": "93a6f435-12ba-401c-be09-0eb4f985f440"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"custom_korean_speech\",              # ì‚¬ìš©ì ë°ì´í„°ì…‹\n",
        "    \"dataset\": \"low_call_voices\",                        # ì‹¤ì œ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ ì´ë¦„\n",
        "    \"dataset_args\": \"config: ko, split: train+validation\", # í•œêµ­ì–´, train+validation\n",
        "    \"language\": \"ko\",                                    # í•œêµ­ì–´\n",
        "    \"model_name\": \"Whisper_Small_Korean_CER20\",          # CER 24% ë‹¬ì„± ëª¨ë¸\n",
        "    \"finetuned_from\": \"openai/whisper-small\",            # Small ëª¨ë¸ ê¸°ë°˜\n",
        "    \"tasks\": \"automatic-speech-recognition\",             # ASR ì‘ì—…\n",
        "    \"tags\": [\"hf-asr-leaderboard\", \"korean\", \"whisper\", \"specaugment\", \"low-resource\"], # ì¶”ê°€ íƒœê·¸\n",
        "    \"model_description\": \"Korean Whisper model fine-tuned on 531 samples with SpecAugment, achieving 24.47% CER\"}"
      ],
      "metadata": {
        "id": "xXdM1YX5LT_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# í˜„ì¬ ë””ë ‰í„°ë¦¬ì˜ ëª¨ë“  í´ë” í™•ì¸\n",
        "print(\"ğŸ“ í˜„ì¬ ë””ë ‰í„°ë¦¬ì˜ í´ë”ë“¤:\")\n",
        "folders = [f for f in os.listdir('.') if os.path.isdir(f)]\n",
        "for folder in folders:\n",
        "    print(f\"  - {folder}\")\n",
        "\n",
        "# whisper ê´€ë ¨ í´ë”ë“¤ ì°¾ê¸°\n",
        "whisper_folders = [f for f in folders if 'whisper' in f.lower()]\n",
        "print(f\"\\nğŸ” whisper ê´€ë ¨ í´ë”ë“¤: {whisper_folders}\")\n",
        "\n",
        "# ê° whisper í´ë” ì•ˆì˜ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
        "for folder in whisper_folders:\n",
        "    if os.path.exists(folder):\n",
        "        contents = os.listdir(folder)\n",
        "        checkpoints = [c for c in contents if c.startswith('checkpoint')]\n",
        "        print(f\"\\nğŸ“‚ {folder}:\")\n",
        "        print(f\"  ì²´í¬í¬ì¸íŠ¸ë“¤: {checkpoints}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYSJtP9BLf15",
        "outputId": "fa9c34ce-f227-49a6-fe11-1f34fc8f4d32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Hugging Face ë‹¤ì‹œ ë¡œê·¸ì¸\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "print(\"ğŸ” Hugging Face ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "c5255881e726435cbcd4167a9c356f79",
            "5b9510b4511545bf822b557d2cbecb3f",
            "cacb20d116b1425fb80b81481afd09b2",
            "e2f3e4a5f33a456393173bd1ed6a13fe",
            "16d9688820474f1ab6076d1da54f9b5f",
            "bcc041d6e7f7474c894046acb6cfd36e",
            "5270e3d49ac64439a79f048a99cdd6c3",
            "d884d40e1e3c43deb6e3919a9365b8f3",
            "a9701f3ce4434e86bca2881554ce5a2c",
            "39a3bd7112d74ffe8e60cbd7af75982a",
            "93cfd19d038d49339bd9f830788a286c",
            "c3dd2abaf8304afdb1a82864efc236b8",
            "0b0cfda511014760b12e62e44a2c941e",
            "12fdb987e50c49a49d6ccda29211ff83",
            "41eb481beb3544489b18dd6a89349309",
            "7f26675897db4b238003b47c5100828f",
            "4a9b349290c148fa8164bd2522b1749f",
            "16e1b48279f84fa2a35dc88572d29642",
            "28e097ae85a24adf9099d43303c59471",
            "72d4f5147fac44298f16441dae9a6ca8"
          ]
        },
        "id": "7783UGzGLjml",
        "outputId": "9d30850d-9052-412d-c1b9-9bb95db4eb93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "\n",
        "# 1. í˜„ì¬ ë©”ëª¨ë¦¬ì— ìˆëŠ” ëª¨ë¸ í™•ì¸\n",
        "try:\n",
        "    # í˜¹ì‹œ trainerê°€ ì•„ì§ ë©”ëª¨ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸\n",
        "    print(\"trainer ëª¨ë¸:\", trainer.model)\n",
        "    current_model = trainer.model\n",
        "except:\n",
        "    print(\"trainerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    # ìƒˆë¡œ Small ëª¨ë¸ ë¡œë“œ\n",
        "    current_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 2. processor ì„¤ì •\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 3. kwargs ì„¤ì •\n",
        "kwargs = {\n",
        "    \"dataset_tags\": \"korean_call_voices\",\n",
        "    \"dataset\": \"low_call_voices\",\n",
        "    \"dataset_args\": \"Korean low-call voices, 531 train + 29 validation samples\",\n",
        "    \"language\": \"ko\",\n",
        "    \"model_name\": \"Whisper_Small_Korean_CER20\",\n",
        "    \"finetuned_from\": \"openai/whisper-small\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": [\"korean\", \"whisper\", \"specaugment\", \"low-resource\"],\n",
        "    \"model_description\": \"Korean Whisper model fine-tuned on 531 samples with SpecAugment, achieving 24.47% CER\"\n",
        "}\n",
        "\n",
        "# 4. ì—…ë¡œë“œ\n",
        "model_repo_name = \"coorinkie/whisper-small-korean-cer20\"\n",
        "current_model.push_to_hub(model_repo_name, **kwargs)\n",
        "processor.push_to_hub(model_repo_name)\n",
        "\n",
        "print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ: https://huggingface.co/{model_repo_name}\")"
      ],
      "metadata": {
        "id": "3G5aa1PJNMIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "\n",
        "# 1. í˜„ì¬ ë©”ëª¨ë¦¬ì— ìˆëŠ” ëª¨ë¸ í™•ì¸\n",
        "try:\n",
        "    # í˜¹ì‹œ trainerê°€ ì•„ì§ ë©”ëª¨ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸\n",
        "    print(\"trainer ëª¨ë¸:\", trainer.model)\n",
        "    current_model = trainer.model\n",
        "except:\n",
        "    print(\"trainerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    # ìƒˆë¡œ Small ëª¨ë¸ ë¡œë“œ\n",
        "    current_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 2. processor ì„¤ì •\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 3. kwargs ì„¤ì •\n",
        "kwargs = {\n",
        "    \"dataset_tags\": \"korean_call_voices\",\n",
        "    \"dataset\": \"low_call_voices\",\n",
        "    \"dataset_args\": \"Korean low-call voices, 531 train + 29 validation samples\",\n",
        "    \"language\": \"ko\",\n",
        "    \"model_name\": \"Whisper_Small_Korean_CER20\",\n",
        "    \"finetuned_from\": \"openai/whisper-small\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": [\"korean\", \"whisper\", \"specaugment\", \"low-resource\"],\n",
        "    \"model_description\": \"Korean Whisper model fine-tuned on 531 samples with SpecAugment, achieving 20.34% CER\"\n",
        "}\n",
        "\n",
        "# 4. ì—…ë¡œë“œ\n",
        "model_repo_name = \"coorinkie/whisper-small-korean-cer20\"\n",
        "current_model.push_to_hub(model_repo_name, **kwargs)\n",
        "processor.push_to_hub(model_repo_name)\n",
        "\n",
        "print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ: https://huggingface.co/{model_repo_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "019d87ead6904c429c44dca767fec081",
            "29afa194fdd94f00ae82acf519207c45",
            "369b330e9b1a4b838fb00c6898a2bb9b",
            "2983e34905304feda5a902046e69dbf3",
            "3535577abeaf4df688dcc9e881fadc6c",
            "f8e803efce594633af28677b5a835868",
            "1179405bebb44c25acf3d66c41a305e8",
            "a7e99c16940b4822a0854bdb3e7a5b47",
            "76939a5e2f344168b6e67f210b6f2b44",
            "1cfcc093a0d74b38860fd350bbafa2e3",
            "6af2f2af8c1445ac9d671319b0717183",
            "f4a6631be3fe49b09950108f37202c11",
            "25a0817bc9ef41adacdd203fe03bb449",
            "1459942261ad4da58c2fe95b6fd046e8",
            "c28c9aaaf644437d9fcfd5f940f3496e",
            "07bf4913951f4de794f26227126c5a2d",
            "4122bbde46b04c6da53ba0722816bbde",
            "da35ed95555544edac6203d5f7f42688",
            "a28796565f3e4aeea8f2383c27417225",
            "6cfefaeb38ed46a7bd0850a5976d054e",
            "6fd93803264048a29e129748e2095f29",
            "453b89a39aa24c73b6009d59daa9af97"
          ]
        },
        "id": "CSDOeo4JNP5p",
        "outputId": "de0385aa-74dc-4662-e77d-27e03c4fc2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ë°ì´í„°ì…‹ ë‹¤ì‹œ ë¡œë“œ\n",
        "print(\"ğŸ“ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ë§Œì•½ ì´ì „ì— ì‚¬ìš©í–ˆë˜ ë³€ìˆ˜ëª…ì„ ê¸°ì–µí•œë‹¤ë©´:\n",
        "try:\n",
        "    print(\"ê¸°ì¡´ ë°ì´í„°ì…‹ í™•ì¸ ì¤‘...\")\n",
        "    print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤:\")\n",
        "    # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ë³€ìˆ˜ í™•ì¸\n",
        "    import builtins\n",
        "    dataset_vars = [name for name in dir() if 'dataset' in name.lower() or 'voices' in name.lower()]\n",
        "    print(dataset_vars)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ í‰ê°€\n",
        "print(\"\\nğŸ”„ Hugging Face ëª¨ë¸ í…ŒìŠ¤íŠ¸...\")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
        "test_texts = [\n",
        "    \"ì•ˆë…•í•˜ì„¸ìš”\",\n",
        "    \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”\",\n",
        "    \"í•œêµ­ì–´ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤\"\n",
        "]\n",
        "\n",
        "# 3. ëª¨ë¸ í…ŒìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ë¡œ)\n",
        "from transformers import pipeline\n",
        "\n",
        "asr_pipeline = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"coorinkie/whisper-small-korean-cer20\"\n",
        ")\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
        "print(f\"ğŸ“Š ëª¨ë¸ ì •ë³´: {asr_pipeline.model.config}\")\n",
        "print(f\"ğŸ¯ ëª¨ë¸ ì´ë¦„: coorinkie/whisper-small-korean-cer20\")\n",
        "print(f\"ğŸ”§ íƒœìŠ¤í¬: automatic-speech-recognition\")\n",
        "print(f\"ğŸŒ ì–¸ì–´: í•œêµ­ì–´ (ko)\")\n",
        "\n",
        "# 4. ëª¨ë¸ ìƒì„¸ ì •ë³´\n",
        "print(f\"\\nğŸ“‹ ëª¨ë¸ ë©”íƒ€ë°ì´í„°:\")\n",
        "print(f\"  - Base model: openai/whisper-small\")\n",
        "print(f\"  - Fine-tuned on: Korean call voices (531 samples)\")\n",
        "print(f\"  - Training CER: 20.34%\")\n",
        "print(f\"  - Tags: korean, whisper, specaugment, low-resource\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90caa3d9436d4073ba72be5ea1c5fe94",
            "ddb37bbde07a4528b7491bb194dfc341",
            "e77cc1dd8fdb44109edc5610f44a1f4f",
            "2c04428bf91f4a7f89d8386c07a3a109",
            "8a04e094c03040f4bcde07efe32c560b",
            "212b3b7b008d4833b5ed54ce2c75c741",
            "9321d74d33a3477c96e2287d37e7fdeb",
            "af633aba27e3485ca9395bc953a7fff7",
            "bde95fb7174e432e80c559985a9066fb",
            "d52b0e2062804beb85ad58b2564cb0fb",
            "4f5a1050266d46f7a55404b6992716e9",
            "310628b4533542f3bec4c8c2858d87d4",
            "79d00ce91c274651ba0ac77c47d9dd8a",
            "ffb1e0197df74af491501d548ec70a3e",
            "d5502b59f6ad4cc0b71feb2be6317f52",
            "8e69238868864048be4a0e360eb8a5d5",
            "7dabac2cf7bd4f06b3a86c13024a7e68",
            "303267c66c184499b7f0ce9f6ea9e592",
            "37e5b188703a43d88532836feaf692ec",
            "6c1328f82cdd4ca99f3b59c9a6f3821e",
            "263595a23cd54fc7b25bf99f7b5caf20",
            "1a3bd9223c444018a7d54319155a7976",
            "465e1aec7c0e4cb0b6b441f47eb8e26e",
            "570f675cbd7c4a5481e126cc9a81ae74",
            "205bfb4781344d7292114ed83eb9d532",
            "712bb4c2f00f4a2c9e16d8d0c62dbc64",
            "c8f39d920e5f432a819b48c41ccd08a5",
            "335601e80d084201a45448dc6ece917b",
            "ee2db8410ccf4c79a627ae4dccd28e4b",
            "903cf12a1541449f9d547a478d66c345",
            "6300a21b26124ffa815001ee1144c909",
            "7cf57269e94b42f0b9e47d514fc742a9",
            "d330b3911ed947268cacd864b783b2ba",
            "a596a41dfbca4afd93ba50237cd332ba",
            "ba8dabbde9714ef8b0fea8ab5d4ca1c5",
            "18bccadb28d54825939510eccc530d4a",
            "4a880a792f2147eda9162858f5d6c578",
            "3dbd3ac633ba42ea8a847e4ad4882fab",
            "263e6a59924b499d905ab54b5904696e",
            "691a500522504b2fb019eabcbd7af121",
            "6189cb5487434c318dfefe015cddc284",
            "605cd4cb4759447bb72541e482691cda",
            "c7ae4dcfd216424599d3bffc54e39ca6",
            "12f9b83e6a414f3d99a51fff0f6d2643",
            "684b70c186374c2697d18dbba63b8af7",
            "a354f0ecb5674c1e92109758e88df58f",
            "0d19b84900094c719345c90559830ada",
            "018832acc4334a2988849e9b0808ef0a",
            "bfbe4b5df99c4394b4596c6a59d174fc",
            "9ba4e4f3e0d44b91825042db22ef69e5",
            "e5ae3f51681e45d489ac4948a12407e7",
            "c9528045e19642ab97f22263ddc0506f",
            "08b69db0bad54cea8d5aaca5206a0680",
            "4cd77415ff034a8a9882256fb9e5fc9b",
            "aed99f0545f04c739c4632c64ccd1d3a",
            "31cd8edb06b8440a8260a4a9a5886586",
            "bbbdd5b45cb643e686735359328ea3f1",
            "6277adfaa19441a79509d227ddeb65b9",
            "81848621f1cb4c13b1b174af41332983",
            "776eaf1544bd44d3abd683e490936227",
            "a8ab77c9275f4a2984f04d170812bc28",
            "b687a13fbcd84a289700b0d335cc0969",
            "37cbfb8d6b1240e9ab1f86f910acaabd",
            "d63358337ae64da68f5ac733276dd443",
            "27e24802decf4f568f041e1550c4ce61",
            "2fc8d2d93986456cb27e04e1ee94f40d",
            "42716207748c440092e3a6bec9c313e0",
            "435875435fc64eba801fc701392e8944",
            "65a4f0eb6a8349f5a67d51cfdacbca83",
            "2be62b5b38494fd6bfa8e02166a41dbc",
            "d3f5bf55e6c54b3097af004af41bdcdb",
            "c0e2ff3fd1c7481e9d27216f2b4d2723",
            "de79ee84ea664c439a7933fed65984cc",
            "a597fbdeb58f4b28a893c6ddc11c766c",
            "d97b50d53fb04973823f391b052117fd",
            "a23044090586448daa0cb82b9a80a7f4",
            "aa5921847ce34794a1ff9c3693eeb6ad",
            "4dc8d709b8e548d6934eb01a3a315541",
            "46bdb5f340c84b07b2f877c44746d40d",
            "1bcc7f315f684c589b0cefc5fabcca92",
            "2d7021a46a4f4c15a53505917262af33",
            "be1c113e1b934c7781b6b46afd5f4b36",
            "ddbe3948ec43485893be8b732d757075",
            "aa5ddb3b64e64386ad580565329104ff",
            "c780948a6d8844a1bad8bfafa672a6e4",
            "2029b841525c4cc5a1f78d7f7ce36801",
            "34aca3e8cd8e4a76a1b8da0e8ce8a320",
            "c805f02ae3eb45fc869966ed26dd562d",
            "bb7df25cc621405a9e02ad3c30bbf987",
            "e9328f7e094c49f7b4eb7469f7970e15",
            "5aafe588511e42d9aafd88e506915d96",
            "51cac753ef6e47d58e2ccfcb439e83fb",
            "c2a323266cd34cd48be9c42abab95fce",
            "be24c730b0924ac9ba7e367ae6383442",
            "e5736cd36e80421e9e38aa97fd09a70e",
            "ff49efaf660544d6a38520210c1b94e2",
            "4c2fbb26842f4568b84bcacff2e04643",
            "39d502b6feb6465ca62190f8690c0be9",
            "659b708a96c941ee8d3b7bb4ae9331f3",
            "1bf62f9c17794616857bf20751b2fcc8",
            "35987f83862641fb9bd5cdf562588bd3",
            "9da3dc63d5294dd5bf2818e213cb55a1",
            "41cabeda9d2b4551ae4a46f13ca420f5",
            "804cb1dc4fd044e984414a2f6b62fd78",
            "2cde9dc5375b47cc86eebd6d468a8c3e",
            "65b58cc4c9424e7bbc2f6db6934c168b",
            "fa2c54d17f8e4ab09b496a6edbde23ab",
            "8c1c611315714ba2bde96ddd3ab8cbbb",
            "10a2686b4442410495866a1b41185432",
            "9fc893d81962423da19c5d152166d0e4"
          ]
        },
        "id": "5vE2TutSNv2_",
        "outputId": "91deadb8-64f8-473c-ede2-b55f1624641f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯\n",
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ì—…ë¡œë“œëœ íŒŒì¼ ì´ë¦„ í™•ì¸\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"ì—…ë¡œë“œëœ íŒŒì¼: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LWUYVCtQNv37",
        "outputId": "45f188e6-4d87-424b-8e22-545f824ecdc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸\n",
        "import librosa\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nğŸ¤ {filename} ìŒì„± ì¸ì‹ ì¤‘...\")\n",
        "\n",
        "    # ì˜¤ë””ì˜¤ ë¡œë“œ\n",
        "    audio, sr = librosa.load(filename, sr=16000)\n",
        "\n",
        "    # ìŒì„± ì¸ì‹ ì‹¤í–‰\n",
        "    result = asr_pipeline(audio)\n",
        "\n",
        "    print(f\"ğŸ¯ ì¸ì‹ ê²°ê³¼: {result['text']}\")\n",
        "    print(f\"ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: {len(audio)/sr:.2f}ì´ˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8onA5GZnOXPu",
        "outputId": "2724f208-4e77-4d12-cd53-dd6ff92c4107"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ: ëª¨ë¸ ì €ì¥\n",
        "import torch\n",
        "\n",
        "# ëª¨ë¸ ì˜ˆì‹œ (ë„¤ê°€ ë§Œë“  ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •)\n",
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = torch.nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "tJnJq8SLogRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrok ì„¤ì¹˜\n",
        "!wget -q -c https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n"
      ],
      "metadata": {
        "id": "kXAsJ-ux0ZAv",
        "outputId": "9ece0492-a901-4b40-d6ea-f8f361e88eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—¬ê¸°ì— ë³¸ì¸ ngrok í† í°ì„ ë¶™ì—¬ë„£ê¸°\n",
        "!./ngrok authtoken '30r7kwynN4UGRHHLVTofTvKoTAz_7iYo1SyPdSzqSpS9DMZbg'\n"
      ],
      "metadata": {
        "id": "n7yD3u9j27vG",
        "outputId": "f535ec74-03d8-4f9c-a63f-dbc320493665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = MyModel()\n",
        "model.load_state_dict(torch.load('model.pt', map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Flask ì•± ìƒì„±\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json['input']\n",
        "    input_tensor = torch.tensor([data], dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        prediction = model(input_tensor).item()\n",
        "    return jsonify({'prediction': prediction})\n",
        "\n",
        "# ngrok ì‹¤í–‰ í•¨ìˆ˜\n",
        "def start_ngrok():\n",
        "    from pyngrok import ngrok\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"ğŸŒ Public URL: {public_url}\")\n",
        "    return public_url\n",
        "\n",
        "# Flask ì•± ì‹¤í–‰ í•¨ìˆ˜\n",
        "def run_app():\n",
        "    app.run()\n",
        "\n",
        "# ì„œë²„ ì‹¤í–‰\n",
        "!pip install pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "threading.Thread(target=run_app).start()\n",
        "time.sleep(2)\n",
        "start_ngrok()\n"
      ],
      "metadata": {
        "id": "CrvoisKj3HIw",
        "outputId": "1d70be21-f6ea-4953-d50c-9e06f44745b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i:5000\n"
      ],
      "metadata": {
        "id": "kkt6ZItuYKn7",
        "outputId": "8148f220-e67b-4ecc-c596-34677d85ff6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsof -t -i:5000 | xargs kill -9\n"
      ],
      "metadata": {
        "id": "fzjDghpqYZ9k",
        "outputId": "74eb5714-3216-4d4d-eb72-f484e3c7b39c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 5000"
      ],
      "metadata": {
        "id": "989DbG09YfIF",
        "outputId": "75334f4d-5a86-484b-b0da-f6a9f8b8d192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok\n"
      ],
      "metadata": {
        "id": "vbgPYOKeYwjj",
        "outputId": "e9418054-b4d0-4118-8b16-c07a5546832b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "_GMAEtRVY1Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http 5000\n"
      ],
      "metadata": {
        "id": "l0JTBOtSY4jK",
        "outputId": "b158e5a0-dacb-4385-c5d7-fe327e87f113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) í˜¹ì‹œ ê¸°ì¡´ ngrok ì‹¤í–‰ ì¤‘ì´ë©´ ì¢…ë£Œ\n",
        "!pkill -f ngrok\n",
        "\n",
        "# 2) ngrokë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰\n",
        "get_ipython().system_raw('ngrok http 5000 &')\n",
        "\n",
        "# 3) ngrok í„°ë„ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import requests\n",
        "import time\n",
        "\n",
        "time.sleep(2)  # ngrokê°€ ì¼œì§ˆ ì‹œê°„ ì¡°ê¸ˆ ê¸°ë‹¤ë¦¬ê¸°\n",
        "tunnel_info = requests.get('http://localhost:4040/api/tunnels').json()\n",
        "public_url = tunnel_info['tunnels'][0]['public_url']\n",
        "print(\"ğŸŒ Public URL:\", public_url)\n",
        "https://db3d8e570db5.ngrok-free.app/"
      ],
      "metadata": {
        "id": "vi19WjjIbStE",
        "outputId": "7806412f-6fc9-4fe9-aa9f-ea07ed76887d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors pyngrok\n"
      ],
      "metadata": {
        "id": "iS_YS56ciLnQ",
        "outputId": "7f0033e8-5402-42c1-aa2b-b55d7f55c2f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Flutter ì—°ê²° ì‹œ CORS í—ˆìš©\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return jsonify({\"message\": \"ì„œë²„ ì—°ê²° ì„±ê³µ!\"})\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    text = data.get(\"text\", \"\")\n",
        "    # ì—¬ê¸°ì— ì‹¤ì œ ëª¨ë¸ ë¡œì§ ë„£ìœ¼ë©´ ë¨\n",
        "    return jsonify({\"result\": f\"'{text}'ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\"})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=5000)\n",
        "\n"
      ],
      "metadata": {
        "id": "wkUqzggxidpo",
        "outputId": "10c81710-6f91-4001-cd1e-2cf990fb4f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1o26pMZZ4ra",
        "outputId": "5ba0ad66-bb55-4cff-9a91-5af9303a45ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "6-ozEiTRbww3",
        "outputId": "9bad18c7-2709-4623-fcc7-b3aa4fa51408"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}